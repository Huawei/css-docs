[{"body":"Symptom When huawei-csi-controller and huawei-csi-node are created, only the Deployment and DaemonSet resources are successfully created, and no Pod is created for the controller and node.\nRoot Cause Analysis The service account used for creating resources does not have the “use” permission of the PSP policy.\nSolution or Workaround Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the vi psp-use.yaml command to create a file named psp-use.yaml\nvi psp-use.yaml Configure the psp-use.yaml file.\napiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: huawei-csi-psp-role rules: - apiGroups: ['policy'] resources: ['podsecuritypolicies'] verbs: ['use'] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: huawei-csi-psp-role-cfg roleRef: kind: ClusterRole name: huawei-csi-psp-role apiGroup: rbac.authorization.k8s.io subjects: - kind: Group apiGroup: rbac.authorization.k8s.io name: system:serviceaccounts:huawei-csi - kind: Group apiGroup: rbac.authorization.k8s.io name: system:serviceaccounts:default Run the following command to create the PSP permission.\nkubectl create -f psp-use.yaml ","categories":"","description":"","excerpt":"Symptom When huawei-csi-controller and huawei-csi-node are created, …","ref":"/css-docs/en/docs/troubleshooting/common-problems-and-solutions-for-interconnecting-with-the-tanzu-kubernetes-cluster/a-pod-cannot-be-created-because-the-psp-permission-is-not-created/","tags":"","title":"A Pod Cannot Be Created Because the PSP Permission Is Not Created"},{"body":"Symptom After the webhook configuration is changed, for example, the value of the webhookPort parameter is changed, an error is reported indicating that a webhook fails to be called when the oceanctl tool is used to manage backends, as shown in the following figure.\nRoot Cause Analysis After the webhook configuration changes, the validatingwebhookconfiguration resource becomes invalid.\nSolution or Workaround Run the following command to delete the validatingwebhookconfiguration resource.\nkubectl delete validatingwebhookconfiguration storage-backend-controller.xuanwu.huawei.io Run the following command to restart CSI Controller. Run the –replicas=* command to set the number of CSI Controller copies to be restored. In the following example, the number of copies to be restored is 1. Change it based on site requirements.\nkubectl scale deployment huawei-csi-controller -n huawei-csi --replicas=0 kubectl scale deployment huawei-csi-controller -n huawei-csi --replicas=1 Run the following command to check whether CSI Controller is successfully started.\nkubectl get pod -n huawei-csi The following is an example of the command output. If the Pod status is Running, Controller is successfully started.\nNAME READY STATUS RESTARTS AGE huawei-csi-controller-58d5b6b978-s2dsq 9/9 Running 0 19s huawei-csi-node-dt6nd 3/3 Running 0 77m ","categories":"","description":"","excerpt":"Symptom After the webhook configuration is changed, for example, the …","ref":"/css-docs/en/docs/troubleshooting/storage-backend-issues/a-webhook-fails-to-be-called-when-the-oceanctl-tool-is-used-to-manage-backends/","tags":"","title":"A webhook Fails to Be Called When the oceanctl Tool Is Used to Manage Backends"},{"body":"Intended Audience This document is intended for:\nTechnical support engineers O\u0026M engineers Engineers with basic knowledge of storage and Kubernetes Symbol Conventions The symbols that may be found in this document are defined as follows.\nSymbol\nDescription\nIndicates a hazard with a high level of risk which, if not avoided, will result in death or serious injury.\nIndicates a hazard with a medium level of risk which, if not avoided, could result in death or serious injury.\nIndicates a hazard with a low level of risk which, if not avoided, could result in minor or moderate injury.\nIndicates a potentially hazardous situation which, if not avoided, could result in equipment damage, data loss, performance deterioration, or unanticipated results.\nNOTICE is used to address practices not related to personal injury.\nSupplements the important information in the main text.\nNOTE is used to address information not related to personal injury, equipment damage, and environment deterioration.\n","categories":"","description":"","excerpt":"Intended Audience This document is intended for:\nTechnical support …","ref":"/css-docs/en/docs/about-this-document/","tags":"","title":"About This Document"},{"body":"Symptom A Pod is running on worker node A, and an external block device is mounted to the Pod through CSI. After worker node A is powered off abnormally, the Kubernetes platform detects that the node is faulty and switches the Pod to worker node B. After worker node A recovers, the drive letters on worker node A change from normal to faulty.\nEnvironment Configuration Kubernetes version: 1.18 or later\nStorage type: block storage\nRoot Cause Analysis After worker node A recovers, Kubernetes initiates an unmapping operation on the storage, but does not initiate a drive letter removal operation on the host. After Kubernetes completes the unmapping, residual drive letters exist on worker node A.\nSolution or Workaround Currently, you can only manually clear the residual drive letters on the host. Alternatively, restart the host again and use the disk scanning mechanism during the host restart to clear the residual drive letters. The specific method is as follows:\nCheck the residual drive letters on the host.\nRun the following command to check whether a DM multipathing device with abnormal multipathing status exists.\nmultipath -ll The following is an example of the command output. The path status is failed faulty running, the corresponding DM multipathing device is dm-12, and the associated SCSI disks are sdi and sdj. If multiple paths are configured, multiple SCSI disks exist. Record these SCSI disks.\nmpathb (3618cf24100f8f457014a764c000001f6) dm-12 HUAWEI ,XSG1 size=100G features='0' hwhandler='0' wp=rw `-+- policy='service-time 0' prio=-1 status=active |- 39:0:0:1 sdi 8:48 failed faulty running `- 38:0:0:1 sdj 8:64 failed faulty running If yes, go to step 1.2. If no, no further action is required. Run the following command to check whether the residual DM multipathing device is readable.\ndd if=/dev/dm-12 of=/dev/null count=1 bs=1M iflag=direct The following is an example of the command output. If the returned result is Input/output error and the read data is 0 bytes (0 B) copied, the device is unreadable. dm-xx indicates the device ID obtained in step 1.1.\ndd: error reading '/dev/dm-12': Input/output error 0+0 records in 0+0 records out 0 bytes (0 B) copied, 0.0236862 s, 0.0 kB/s If yes, record the residual dm-xx device and associated disk IDs (for details, see step 1.1) and perform the clearing operation. If the command execution is suspended, go to step 1.3. If other cases, contact technical support engineers. Log in to the node again in another window.\nRun the following command to view the suspended process.\nps -ef | grep dm-12 | grep -w dd The following is an example of the command output.\nroot 21725 9748 0 10:33 pts/10 00:00:00 dd if=/dev/dm-12 of=/dev/null count=1 bs=10M iflag=direct Kill the pid.\nkill -9 pid Record the residual dm-xx device and associated disk IDs (for details, see step 1.1) and perform the clearing operation.\nClear the residual drive letters on the host.\nRun the following command to delete residual multipathing aggregation device information according to the DM multipathing device obtained in step 1.\nmultipath -f /dev/dm-12 If an error is reported, contact technical support engineers.\nRun the following command to clear the residual SCSI disks according to the drive letters of the residual disks obtained in step 1.\necho 1 \u003e /sys/block/xxxx/device/delete When multiple paths are configured, clear the residual disks based on the drive letters. The residual paths are sdi and sdj.\necho 1 \u003e /sys/block/sdi/device/delete echo 1 \u003e /sys/block/sdj/device/delete If an error is reported, contact technical support engineers.\nCheck whether the DM multipathing device and SCSI disk information has been cleared.\nRun the following commands in sequence to query the multipathing and disk information. If the residual dm-12 device and SCSI disks sdi and sdj are cleared, the clearing is complete.\nView multipathing information.\nmultipath -ll The following is an example of the command output. The residual dm-12 device is cleared.\nmpathb (3618cf24100f8f457014a764c000001f6) dm-3 HUAWEI ,XSG1 size=100G features='0' hwhandler='0' wp=rw `-+- policy='service-time 0' prio=-1 status=active |- 39:0:0:1 sdd 8:48 active ready running `- 38:0:0:1 sde 8:64 active ready running mpathn (3618cf24100f8f457315a764c000001f6) dm-5 HUAWEI ,XSG1 size=100G features='0' hwhandler='0' wp=rw `-+- policy='service-time 0' prio=-1 status=active |- 39:0:0:2 sdc 8:32 active ready running `- 38:0:0:2 sdb 8:16 active ready running View device information.\nls -l /sys/block/ The following is an example of the command output. SCSI disks sdi and sdj are cleared.\ntotal 0 lrwxrwxrwx 1 root root 0 Aug 11 19:56 dm-0 -\u003e ../devices/virtual/block/dm-0 lrwxrwxrwx 1 root root 0 Aug 11 19:56 dm-1 -\u003e ../devices/virtual/block/dm-1 lrwxrwxrwx 1 root root 0 Aug 11 19:56 dm-2 -\u003e ../devices/virtual/block/dm-2 lrwxrwxrwx 1 root root 0 Aug 11 19:56 dm-3 -\u003e ../devices/virtual/block/dm-3 lrwxrwxrwx 1 root root 0 Aug 11 19:56 sdb -\u003e ../devices/platform/host35/session2/target35:0:0/35:0:0:1/block/sdb lrwxrwxrwx 1 root root 0 Aug 11 19:56 sdc -\u003e ../devices/platform/host34/target34:65535:5692/34:65535:5692:0/block/sdc lrwxrwxrwx 1 root root 0 Aug 11 19:56 sdd -\u003e ../devices/platform/host39/session6/target39:0:0/39:0:0:1/block/sdd lrwxrwxrwx 1 root root 0 Aug 11 19:56 sde -\u003e ../devices/platform/host38/session5/target38:0:0/38:0:0:1/block/sde lrwxrwxrwx 1 root root 0 Aug 11 19:56 sdh -\u003e ../devices/platform/host39/session6/target39:0:0/39:0:0:3/block/sdh lrwxrwxrwx 1 root root 0 Aug 11 19:56 sdi -\u003e ../devices/platform/host38/session5/target38:0:0/38:0:0:3/block/sdi View disk information.\nls -l /dev/disk/by-id/ The following is an example of the command output. SCSI disks sdi and sdj are cleared.\ntotal 0 lrwxrwxrwx 1 root root 10 Aug 11 19:57 dm-name-mpathb -\u003e ../../dm-3 lrwxrwxrwx 1 root root 10 Aug 11 19:58 dm-name-mpathn -\u003e ../../dm-5 lrwxrwxrwx 1 root root 10 Aug 11 19:57 dm-uuid-mpath-3618cf24100f8f457014a764c000001f6 -\u003e ../../dm-3 lrwxrwxrwx 1 root root 10 Aug 11 19:58 dm-uuid-mpath-3618cf24100f8f457315a764c000001f6 -\u003e ../../dm-5 lrwxrwxrwx 1 root root 9 Aug 11 19:57 scsi-3618cf24100f8f457014a764c000001f6 -\u003e ../../sdd lrwxrwxrwx 1 root root 9 Aug 11 19:57 scsi-3618cf24100f8f45712345678000103e8 -\u003e ../../sdi lrwxrwxrwx 1 root root 9 Aug 3 15:17 scsi-3648435a10058805278654321ffffffff -\u003e ../../sdb lrwxrwxrwx 1 root root 9 Aug 2 14:49 scsi-368886030000020aff44cc0d060c987f1 -\u003e ../../sdc lrwxrwxrwx 1 root root 9 Aug 11 19:57 wwn-0x618cf24100f8f457014a764c000001f6 -\u003e ../../sdd lrwxrwxrwx 1 root root 9 Aug 11 19:57 wwn-0x618cf24100f8f45712345678000103e8 -\u003e ../../sdi lrwxrwxrwx 1 root root 9 Aug 3 15:17 wwn-0x648435a10058805278654321ffffffff -\u003e ../../sdb lrwxrwxrwx 1 root root 9 Aug 2 14:49 wwn-0x68886030000020aff44cc0d060c987f1 -\u003e ../../sdc ","categories":"","description":"","excerpt":"Symptom A Pod is running on worker node A, and an external block …","ref":"/css-docs/en/docs/troubleshooting/pod-issues/after-a-worker-node-in-the-cluster-breaks-down-and-recovers-pod-failover-is-complete-but-the-source/","tags":"","title":"After a Worker Node in the Cluster Breaks Down and Recovers, Pod Failover Is Complete but the Source Host Where the Pod Resides Has Residual Drive Letters"},{"body":"If you need to use volume snapshots and features associated with volume snapshots in the container environment, perform the operations in Checking Volume Snapshot-Dependent Components to check whether volume snapshot-dependent components have been deployed in your environment and check the api-versions information about volume snapshots.\n","categories":"","description":"","excerpt":"If you need to use volume snapshots and features associated with …","ref":"/css-docs/en/docs/using-huawei-csi/creating-a-volumesnapshot/checking-information-about-volume-snapshot-dependent-components/","tags":"","title":"Checking Information About Volume Snapshot-dependent Components"},{"body":"Asymmetric Logical Unit Access (ALUA) is a model that supports access to multiple target ports. In the multipathing state, ALUA presents active/passive volumes to the host and provides a port access status switchover interface to switch over the working controllers for volumes. For example, when a volume of a controller fails, you can set the status of ports on the controller to Unavailable. After the host multipathing software that supports ALUA detects the status, it switches subsequent I/Os from the failed controller to the peer controller.\n","categories":"","description":"","excerpt":"Asymmetric Logical Unit Access (ALUA) is a model that supports access …","ref":"/css-docs/en/docs/advanced-features/configuring-alua/","tags":"","title":"Configuring ALUA"},{"body":"For details about how to configure ALUA for Huawei enterprise storage, see the host connectivity guide of the corresponding product.\nThe ALUA configuration may vary according to the OS. Visit Huawei Technical Support, enter Host Connectivity Guide in the search box, and click the search button. In the search result, select the host connectivity guide for the desired OS. Configure ALUA according to the actual situation and the description in the guide. Huawei CSI will apply the configuration items you set to the initiator of the host on Huawei storage.\nA node with a Pod provisioned does not proactively change ALUA information. The host ALUA configuration changes only after a Pod is provisioned again to the node.\nALUA Parameters for OceanStor V5 and OceanStor Dorado V3 Series Table 1 lists the ALUA parameters supported by Huawei CSI for OceanStor V5 and OceanStor Dorado V3 series.\nTable 1 ALUA parameters supported by Huawei CSI for OceanStor V5 and OceanStor Dorado V3 series\nParameter\nDescription\nRemarks\nHostName\nHost name rule. This parameter is mandatory. You can use a regular expression.\nThe host name can be obtained by running the cat /etc/hostname command. It can be matched by using regular expressions. When HostName is set to *, the configuration takes effect on hosts with any name. For details, see Regular expression.\nIf the host name of a compute node matches multiple ALUA configuration options, they will be sorted based on the matching accuracy and the first ALUA configuration option will be used. For details about the sorting rules, see Rules for Matching ALUA Configuration Items with Host Names.\nMULTIPATHTYPE\nMultipathing type. This parameter is mandatory. The value can be:\n0: Third-party multipathing is not used.1: Third-party multipathing is used. --\nFAILOVERMODE\nInitiator switchover mode. This parameter is conditionally mandatory. The value can be:\n0: early-version ALUA1: common ALUA2: ALUA not used3: special ALUA This parameter needs to be specified only when third-party multipathing is used. Configure the initiator switchover mode by referring to the connectivity guide.\nSPECIALMODETYPE\nSpecial mode type of the initiator. This parameter is conditionally mandatory. The value can be:\n0: special mode 01: special mode 12: special mode 23: special mode 3 This parameter needs to be specified only when the initiator switchover mode is special ALUA. Configure the special mode type of the initiator by referring to the connectivity guide.\nPATHTYPE\nInitiator path type. This parameter is conditionally mandatory. The value can be:\n0: preferred path1: non-preferred path This parameter needs to be specified only when third-party multipathing is used. Configure the initiator path type by referring to the connectivity guide.\nThe following uses OceanStor 18500 V5 as an example to describe how to connect to Red Hat. For details about the host connectivity guide, see Huawei SAN Storage Host Connectivity Guide for Red Hat.\nThe following ALUA configuration example is recommended in the OceanStor 18500 V5 host connectivity guide for Red Hat in non-HyperMetro storage scenarios. In this example, the OS on compute node myhost01 in the Kubernetes cluster is RHEL 5.x, and that on other compute nodes is RHEL 7.x. According to the recommendation, the switchover mode of RHEL 5.x should be “ALUA not used”, and that of RHEL 7.x should be “common ALUA”.\nstorage: oceanstor-san name: oceanstor-iscsi-155 urls: - https://192.168.129.155:8088 - https://192.168.129.156:8088 pools: - StoragePool001 parameters: protocol: iscsi portals: - 192.168.128.120 - 192.168.128.121 ALUA: ^myhost01$: MULTIPATHTYPE: 1 FAILOVERMODE: 2 PATHTYPE: 0 \"*\": MULTIPATHTYPE: 1 FAILOVERMODE: 1 PATHTYPE: 0 ALUA Parameters for OceanStor and OceanStor Dorado Series Table 2 lists the ALUA parameters supported by Huawei CSI for OceanStor and OceanStor Dorado series.\nBy default, the initiator host access mode of OceanStor and OceanStor Dorado series storage is “balanced mode”. Therefore, you are advised not to configure ALUA parameters for OceanStor and OceanStor Dorado series storage.\nTable 2 ALUA parameters for OceanStor and OceanStor Dorado series\nParameter\nDescription\nRemarks\nHostName\nHost name rule. This parameter is mandatory. You can use a regular expression.\nThe host name can be obtained by running the cat /etc/hostname command. It can be matched by using regular expressions. When HostName is set to *, the configuration takes effect on hosts with any name. For details, see Regular expression.\nIf the host name of a compute node matches multiple ALUA configuration options, they will be sorted based on the matching accuracy and the first ALUA configuration option will be used. For details about the sorting rules, see Rules for Matching ALUA Configuration Items with Host Names.\naccessMode\nHost access mode. This parameter is mandatory. The value can be:\n0: balanced mode1: asymmetric mode The balanced mode is recommended in non-HyperMetro scenarios. Currently, Huawei CSI does not support SAN HyperMetro scenarios. Exercise caution when using the asymmetric mode.\nhyperMetroPathOptimized\nWhether the path of the host on the current storage array is preferred in HyperMetro scenarios. The value can be:\n1: yes0: no This parameter needs to be specified only when the host access mode is set to asymmetric.\nCurrently, Huawei CSI does not support SAN HyperMetro scenarios. Exercise caution when using the asymmetric mode.\nThe following uses OceanStor Dorado 18000 as an example to describe how to connect to Red Hat. For details about the host connectivity guide, see OceanStor Dorado and OceanStor Host Connectivity Guide for Red Hat.\nThe following ALUA configuration example is recommended in the OceanStor Dorado 18000 host connectivity guide for Red Hat in non-HyperMetro storage scenarios.\nstorage: \"oceanstor-san\" name: \"dorado-iscsi-155\" urls: - \"https://192.168.129.155:8088\" - \"https://192.168.129.156:8088\" pools: - \"StoragePool001\" parameters: protocol: \"iscsi\" portals: - \"192.168.128.120\" - \"192.168.128.121\" ALUA: \"*\": accessMode: 0 Rules for Matching ALUA Configuration Items with Host Names If the configured host name rule exactly matches the host name of the service node, the ALUA configuration item corresponding to the host name rule is used.\nFor example, the host name rule in configuration item 1 is * and that in configuration item 2 is ^myhost01$. If the host name of a compute node is myhost01, it exactly matches configuration item 2. In this case, Huawei CSI will apply the configuration information in configuration item 2 to the storage side.\nIf the configured host name rule does not exactly match the host name of the service node, the first ALUA configuration item matched by regular expressions is used.\nFor example, the host name rule in configuration item 1 is myhost0[0-9] and that in configuration item 2 is myhost0[5-9]. In this case, configuration item 1 has a higher priority than configuration item 2. If the host name of a compute node is myhost06, both configuration items can be matched. In this case, Huawei CSI will apply the configuration information in configuration item 1 to the storage side.\n","categories":"","description":"","excerpt":"For details about how to configure ALUA for Huawei enterprise storage, …","ref":"/css-docs/en/docs/advanced-features/configuring-alua/configuring-alua-using-helm/configuring-alua-parameters-for-a-huawei-enterprise-storage-backend/","tags":"","title":"Configuring ALUA Parameters for a Huawei Enterprise Storage Backend"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/en/docs/advanced-features/configuring-alua/configuring-alua-using-helm/","tags":"","title":"Configuring ALUA Using Helm"},{"body":"Procedure Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nGo to the directory where the Helm project is located. If the previous Helm project cannot be found, copy the helm directory in the component package to any directory on the master node. For details about the component package path, see Table 1.\nGo to the backend service configuration directory /examples/backend/ and back up the backend.yaml file.\ncp backend.yaml backend.yaml.bak Run the **vi **backend.yaml command to open the file and configure topology awareness as required. The following is an example. After the modification is complete, press Esc and enter :wq! to save the modification.\nstorage: \"oceanstor-san\" name: \"dorado-iscsi-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" pools: - \"StoragePool001\" parameters: protocol: \"iscsi\" portals: - \"10.10.30.20\" - \"10.10.30.21\" supportedTopologies: - { \"topology.kubernetes.io/region\": \"China-west\", \"topology.kubernetes.io/zone\": \"ChengDu\" } - { \"topology.kubernetes.io/region\": \"China-south\",\"topology.kubernetes.io/zone\": \"ShenZhen\" } maxClientThreads: \"30\" Run the following command to delete the storage backend to be modified. In the command, dorado-iscsi-155 indicates the storage backend name.\noceanctl delete backend dorado-iscsi-155 -n huawei-csi Run the following command to create a storage backend.\noceanctl create backend -f ../examples/backend/backend.yaml -i yaml Enter the storage user name and password as prompted.\nPlease enter this backend user name:admin Please enter this backend password: Run the vi StorageClass.yaml command to modify the .yaml file. Press I or Insert to enter the insert mode and add related parameters in the .yaml file. For details about the parameters, see Table 1. After the modification is complete, press Esc and enter :wq! to save the modification.\nAdd the following configuration items to the StorageClass.yaml file.\nExample 1: Configure zone and region information in the StorageClass.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: example-storageclass provisioner: csi.huawei.com parameters: volumeType: lun allocType: thin volumeBindingMode: WaitForFirstConsumer allowedTopologies: - matchLabelExpressions: - key: topology.kubernetes.io/zone values: - ChengDu - key: topology.kubernetes.io/region values: - China-west Example 2: Configure protocol information in the StorageClass.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: protocol-example-storageclass provisioner: csi.huawei.com parameters: volumeType: lun allocType: thin volumeBindingMode: WaitForFirstConsumer allowedTopologies: - matchLabelExpressions: - key: topology.kubernetes.io/protocol.iscsi values: - csi.huawei.com Table 1 Parameter description\nParameter\nDescription\nRemarks\nvolumeBindingMode\nPersistentVolume binding mode, used to control the time when PersistentVolume resources are dynamically allocated and bound.\nYou can set this parameter to WaitForFirstConsumer or Immediate.\nWaitForFirstConsumer: indicates that the binding and allocation of the PersistentVolume are delayed until a Pod that uses the PVC is created.\nImmediate: The PersistentVolume is bound and allocated immediately after a PVC is created.\nallowedTopologies.matchLabelExpressions\nTopology information label, which is used to filter CSI backends and Kubernetes nodes. If the matching fails, PVCs or Pods cannot be created.\nBoth key and value must be configured in a fixed format.\nkey: This parameter can be set to topology.kubernetes.io/zone or topology.kubernetes.io/region.\ntopology.kubernetes.io/protocol.\u003cprotocol\u003e: \u003cprotocol\u003e indicates the protocol type and can be iscsi, fc, or nfs.\nvalue:\nIf key is topology.kubernetes.io/zone or topology.kubernetes.io/region, value must be the same as the topology label set in the prerequisites.\nIf key is topology.kubernetes.io/protocol.\u003cprotocol\u003e, value is fixed at csi.huawei.com.\nRun the following command to create a StorageClass based on the .yaml file.\nkubectl create -f StorgeClass.yaml Use the StorageClass to create a PVC with the topology capability. For details, see PVC Parameters for Dynamic Volume Provisioning.\n","categories":"","description":"","excerpt":"Procedure Use a remote access tool, such as PuTTY, to log in to any …","ref":"/css-docs/en/docs/advanced-features/configuring-storage-topology-awareness/configuring-storage-topology-awareness-using-helm/","tags":"","title":"Configuring Storage Topology Awareness Using Helm"},{"body":"Prerequisites A certificate has been created. Take OceanStor Dorado as an example. For details about how to create a certificate, click here.\nExample of Creating a Certificate Prepare a certificate file in advance, for example, cert.crt.\nRun the following command to obtain information about a storage backend.\noceanctl get backend The following is an example of the command output.\nNAMESPACE NAME PROTOCOL STORAGETYPE SN STATUS ONLINE URL huawei-csi backend-1 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.157:8088 huawei-csi backend-2 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.158:8088 Run the following command to create a certificate for the specified storage backend.\noceanctl create cert cert-1 -b backend-1 -f /path/to/cert.crt Check the certificate creation result.\noceanctl get cert -b backend-1 The following is an example of the command output.\nNAMESPACE NAME BOUNDBACKEND huawei-csi cert-1 backend-1 ","categories":"","description":"","excerpt":"Prerequisites A certificate has been created. Take OceanStor Dorado as …","ref":"/css-docs/en/docs/storage-backend-management/optional-adding-a-certificate-to-a-storage-backend/creating-a-certificate-for-a-storage-backend/","tags":"","title":"Creating a Certificate for a Storage Backend"},{"body":"Huawei CSI allows storage resources (LUNs or file systems) to be created on Huawei storage and provided for containers based on user settings. For details about the supported features, see Table 2 or Table 2.\nA PVC can be created in dynamic volume provisioning or static volume provisioning mode.\nDynamic volume provisioning does not require a PV to be created in advance. Huawei CSI automatically creates resources required by a PV on storage devices based on a StorageClass. In addition, you can create a PV when creating a PVC. Static volume provisioning requires the administrator to create required resources on a storage device in advance and use existing resources by creating a PV. In addition, you can specify the associated PV when creating a PVC. ","categories":"","description":"","excerpt":"Huawei CSI allows storage resources (LUNs or file systems) to be …","ref":"/css-docs/en/docs/using-huawei-csi/managing-a-pvc/creating-a-pvc/","tags":"","title":"Creating a PVC"},{"body":"Prerequisites The storage backends associated with the PVC to be changed are HyperMetro storage backends. If they are not HyperMetro storage backends, configure them by following the instructions in Manually Updating a Storage Backend.\n","categories":"","description":"","excerpt":"Prerequisites The storage backends associated with the PVC to be …","ref":"/css-docs/en/docs/advanced-features/pvc-change/configuring-pvc-changes/creating-a-pvc-change/","tags":"","title":"Creating a PVC Change"},{"body":" When oceanctl is used to create a storage backend, the entered account and key information is stored in the Secret object. It is recommended that the customer container platform encrypt the Secret object based on the suggestions of the supplier or K8s community. For details about how to encrypt the Secret object in the K8s community, see Enable Encryption at Rest. When a backend is created using a .json file, the backend name of an earlier version may contain uppercase letters or underscores (_). In this case, the old name is remapped to a new name. The mapping process automatically occurs and does not affect the original functions. For example, ABC_123 is mapped to abc-123-fd68e. The mapping rules are as follows: Uppercase letters are converted to lowercase letters. An underscore (_) is converted to a hyphen (-). A 5-digit hash code is added to the end. If a storage backend is connected to a vStore, the vStore name cannot be changed after the storage backend is created. Procedure Prepare the backend configuration file, for example, backend.yaml. For details, see Examples of Storage Backend Configuration Files in Typical Scenarios. To create multiple backends, separate them with —.\nstorage: \"oceanstor-san\" name: \"backend-1\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.157:8088\" pools: - \"StoragePool001\" parameters: protocol: \"roce\" portals: - \"10.10.30.20\" - \"10.10.30.21\" maxClientThreads: \"30\" --- storage: \"oceanstor-san\" name: \"backend-2\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.158:8088\" pools: - \"StoragePool001\" parameters: protocol: \"roce\" portals: - \"10.10.30.20\" - \"10.10.30.21\" maxClientThreads: \"30\" Run the following command to create a storage backend.\noceanctl create backend -f /path/to/backend.yaml -i yaml The following is an example of the command output.\nNUMBER CONFIGURED NAME STORAGE URLS 1 false backend-1 oceanstor-san https://192.168.129.157:8088 2 false backend-2 oceanstor-san https://192.168.129.158:8088 Please enter the backend number to configure (Enter 'exit' to exit): Enter the serial number of the backend to be created and enter the account and password.\nPlease enter the backend number to configure (Enter 'exit' to exit):1 Please enter this backend user name:admin Please enter this backend password: Backend backend-1 is configured NUMBER CONFIGURED NAME STORAGE URLS 1 true backend-1 oceanstor-san https://192.168.129.157:8088 2 false backend-2 oceanstor-san https://192.168.129.158:8088 Please enter the backend number to configure (Enter 'exit' to exit): Check the storage backend creation result.\noceanctl get backend The following is an example of the command output. If the backend status is Bound, the creation is successful.\nNAMESPACE NAME PROTOCOL STORAGETYPE SN STATUS ONLINE URL huawei-csi backend-1 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.157:8088 huawei-csi backend-2 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.158:8088 ","categories":"","description":"","excerpt":" When oceanctl is used to create a storage backend, the entered …","ref":"/css-docs/en/docs/storage-backend-management/managing-storage-backends/creating-a-storage-backend/","tags":"","title":"Creating a Storage Backend"},{"body":"This section describes how to download the software package and the component structure of the software package.\nOpen a browser and enter https://github.com/Huawei/eSDK_K8S_Plugin/releases in the address box.\nDownload the software package of the 4.5.0 version based on the CPU architecture.\nSoftware package naming rule: Plug-in name (eSDK_Huawei_Storage_Kubernetes_CSI_Plugin) + Version number + CPU architecture\nDecompress the downloaded software package. The following table shows the component structure of the software package.\nTable 1 Component description\nComponent\nDescription\nimage/huawei-csi-v4.5.0-arch.tar\nhuawei-csi-driver image. arch is X86 or ARM.\nimage/storage-backend-controller-v4.5.0-arch.tar\nBack-end management controller image. arch is X86 or ARM.\nimage/storage-backend-sidecar-v4.5.0-arch.tar\nBack-end management sidecar image. arch is X86 or ARM.\nimage/huawei-csi-extender-v4.5.0-arch.tar\nhuawei-csi-extender image. arch is X86 or ARM.\nbin/\nBinary file used by an image provided by Huawei.\nbin/oceanctl\nCommand line tool provided by Huawei, which can be used to manage storage backends.\nhelm/\nHelm project used to deploy Huawei CSI.\nmanual/\nUsed to manually install and deploy Huawei CSI.\nexamples/\n.yaml sample file used during CSI use.\nexamples/backend\n.yaml sample file used to create a storage backend.\n","categories":"","description":"","excerpt":"This section describes how to download the software package and the …","ref":"/css-docs/en/docs/installation-and-deployment/installation-preparations/downloading-the-huawei-csi-software-package/","tags":"","title":"Downloading the Huawei CSI Software Package"},{"body":"Dynamic volume provisioning allows storage volumes to be created on demand. Dynamic volume provisioning depends on the StorageClass objects. The cluster administrator can define multiple StorageClass objects as required and specify a StorageClass that meets service requirements when declaring a PV or PVC. When applying for resources from Huawei storage devices, Huawei CSI creates storage resources that meet service requirements based on the preset StorageClass.\nTo implement dynamic volume provisioning, perform the following steps:\nConfiguring a StorageClass Configuring a PVC Configuring a StorageClass Create a StorageClass configuration file, for example, mysc.yaml, based on service requirements by referring to StorageClass Configuration Examples in Typical Dynamic Volume Provisioning Scenarios and StorageClass Parameters for Dynamic Volume Provisioning.\nRun the following command to create a StorageClass using the configuration file.\nkubectl apply -f mysc.yaml Run the following command to view the information about the created StorageClass.\nkubectl get sc mysc The following is an example of the command output.\nNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE mysc csi.huawei.com Delete Immediate true 8s Configuring a PVC Based on service requirements, modify specific parameters by referring to the description in this section and the PVC configuration file example to generate the PVC configuration file to be created, for example, the mypvc.yaml file in this example.\nkind: PersistentVolumeClaim apiVersion: v1 metadata: name: mypvc spec: accessModes: - ReadWriteOnce volumeMode: Filesystem storageClassName: mysc resources: requests: storage: 100Gi Run the following command to create a PVC using the configuration file.\nkubectl create -f mypvc.yaml After a period of time, run the following command to view the information about the created PVC.\nkubectl get pvc mypvc The following is an example of the command output. If the PVC status is Bound, the PVC has been created and can be used by a Pod.\nNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE mypvc Bound pvc-840054d3-1d5b-4153-b73f-826f980abf9e 100Gi RWO mysc 12s After the PVC is created, if the PVC is in the Pending state after a long time (for example, one minute), refer to When a PVC Is Created, the PVC Is in the Pending State. You are advised to create or delete a maximum of 100 PVCs in a batch. Using a PVC After a PVC is created, you can use the PVC to create a Pod. The following is a simple example of using a PVC. In this example, the created Pod uses the newly created mypvc.\napiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: selector: matchLabels: app: nginx replicas: 2 template: metadata: labels: app: nginx spec: containers: - image: nginx:alpine name: container-0 volumeMounts: - mountPath: /tmp name: pvc-mypvc restartPolicy: Always volumes: - name: pvc-mypvc persistentVolumeClaim: claimName: mypvc # name of PVC ","categories":"","description":"","excerpt":"Dynamic volume provisioning allows storage volumes to be created on …","ref":"/css-docs/en/docs/using-huawei-csi/managing-a-pvc/creating-a-pvc/dynamic-volume-provisioning/","tags":"","title":"Dynamic Volume Provisioning"},{"body":"The PVC change feature is disabled by default during Huawei CSI installation. To use this feature, perform the following steps.\n","categories":"","description":"","excerpt":"The PVC change feature is disabled by default during Huawei CSI …","ref":"/css-docs/en/docs/advanced-features/pvc-change/enabling-the-pvc-change-feature/","tags":"","title":"Enabling the PVC Change Feature"},{"body":"Prerequisites You have installed Huawei CSI using Helm. Huawei CSI v4.5.0 or later is used. Procedure Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to check whether the PVC change feature is enabled.\nhelm-huawei-csi indicates the Helm chart name specified during installation, and huawei-csi indicates the Helm chart namespace specified during installation. For details about the component package path, see Table 1.\nhelm get values helm-huawei-csi -n huawei-csi -a | grep volumeModify -A 1 The following is an example of the command output.\nIf enabled: true is displayed in the command output, the feature is enabled. In this case, skip the following steps. If enabled: false is displayed in the command output, perform the following steps to enable the PVC change feature. volumeModify: enabled: false Go to the /helm/esdk directory and run the following command to configure the volume change CRD.\n# kubectl apply -f ./crds/volume-modify/ customresourcedefinition.apiextensions.k8s.io/volumemodifyclaims.xuanwu.huawei.io configured customresourcedefinition.apiextensions.k8s.io/volumemodifycontents.xuanwu.huawei.io configured If the command output contains Warning: resource customresourcedefinitions/volumemodifycontents.xuanwu.huawei.io is missing the kubectl.kubernetes.io/last-applied-configuration…, you can ignore it. This message is displayed because the kubectl create command instead of the kubectl apply command is used for installation by Helm.\nRun the following command to obtain the original service configuration file.\nhelm get values helm-huawei-csi -n huawei-csi -a \u003e ./update-values.yaml Run the vi update-values.yaml command to open the file obtained in 4 and modify the following configuration. After the modification is complete, press Esc and enter :wq! to save the modification.\ncsiExtender: volumeModify: enabled: true Run the following command to update Huawei CSI services.\nhelm upgrade helm-huawei-csi ./ -n huawei-csi -f ./update-values.yaml Run the following command to check whether the services are started.\nkubectl get pod -n huawei-csi The following is an example of the command output. In the preceding command, huawei-csi indicates the namespace for deploying Huawei CSI.\nNAME READY STATUS RESTARTS AGE huawei-csi-controller-6dfcc4b79f-9vjtq 10/10 Running 0 24m huawei-csi-node-tqs87 3/3 Running 0 20m ","categories":"","description":"","excerpt":"Prerequisites You have installed Huawei CSI using Helm. Huawei CSI …","ref":"/css-docs/en/docs/advanced-features/pvc-change/enabling-the-pvc-change-feature/enabling-the-pvc-change-feature-using-helm/","tags":"","title":"Enabling the PVC Change Feature Using Helm"},{"body":"Example 1: The configuration file content is as follows:\nparameters: ALUA: \"*\": MULTIPATHTYPE: 1 FAILOVERMODE: 3 SPECIALMODETYPE: 0 PATHTYPE: 0 node1: MULTIPATHTYPE: 1 FAILOVERMODE: 3 SPECIALMODETYPE: 0 PATHTYPE: 1 If the host name is node1, both of the preceding ALUA configuration sections can be used to configure initiators. According to the configuration policy rules in Configuring ALUA Parameters for a Huawei Enterprise Storage Backend, the priority of the second configuration section (where HostName is node1) is higher than that of the first configuration section (where HostName is *).\nExample 2: The configuration file content is as follows:\nparameters: ALUA: node[0-9]: MULTIPATHTYPE: 1 FAILOVERMODE: 3 SPECIALMODETYPE: 0 PATHTYPE: 0 node[5-7]: MULTIPATHTYPE: 1 FAILOVERMODE: 3 SPECIALMODETYPE: 0 PATHTYPE: 1 If the host name is node6, both of the preceding ALUA configuration sections can be used to configure initiators. According to the configuration policy rules in Configuring ALUA Parameters for a Huawei Enterprise Storage Backend, select the first ALUA configuration section to configure initiators.\nExample 3: The configuration file content is as follows:\nparameters: ALUA: node$: MULTIPATHTYPE: 1 FAILOVERMODE: 3 SPECIALMODETYPE: 0 PATHTYPE: 0 node10$: MULTIPATHTYPE: 1 FAILOVERMODE: 3 SPECIALMODETYPE: 0 PATHTYPE: 1 According to the configuration policy rules in Configuring ALUA Parameters for a Huawei Enterprise Storage Backend: For host node1, select the first ALUA configuration section to configure initiators. For host node10, select the second ALUA configuration section to configure initiators. ^ matches the beginning of a character string, and $ matches the end of a character string.\n","categories":"","description":"","excerpt":"Example 1: The configuration file content is as follows:\nparameters: …","ref":"/css-docs/en/docs/appendix/example-alua-configuration-policy-of-oceanstor-v5-and-oceanstor-dorado-v3/","tags":"","title":"Example ALUA Configuration Policy of OceanStor V5 and OceanStor Dorado V3"},{"body":"For details about the backend configuration in typical scenarios, see the following examples. For details about the parameter configuration, see Storage Backend Parameters.\nConfiguring a Storage Backend of the iSCSI Type Configuring a Storage Backend of the FC Type Configuring a Storage Backend of the NVMe over RoCE Type Configuring a Storage Backend of the NVMe over FC Type Configuring a Storage Backend of the NFS Type Configuring a Storage Backend of the SCSI Type Configuring a Storage Backend of the DPC Type Configuring Storage Backends of the Dtree Type Configuring Storage Backends of the HyperMetro Type Configuring a Storage Backend of the iSCSI Type If you want to use the iSCSI protocol, ensure that the iSCSI client has been installed on the host before installing Huawei CSI. You can check whether the client has been installed on the host by referring to Checking the Status of Host-Dependent Software. If the iSCSI client is not installed, restart the huawei-csi-node service after installing the iSCSI client. During the restart, do not use Huawei CSI to create new resources or mount or unmount an existing PVC. The following command is used as an example:\nkubectl delete pods -n huawei-csi -l app=huawei-csi-node The following is an example of the backend configuration file of the iSCSI type for enterprise storage:\nstorage: \"oceanstor-san\" name: \"dorado-iscsi-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" - \"https://192.168.129.156:8088\" pools: - \"StoragePool001\" parameters: protocol: \"iscsi\" portals: - \"192.168.128.120\" - \"192.168.128.121\" maxClientThreads: \"30\" The following is an example of the backend configuration file of the iSCSI type for distributed storage:\nstorage: \"fusionstorage-san\" name: \"pacific-iscsi-125\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.125:8088\" - \"https://192.168.129.126:8088\" pools: - \"StoragePool001\" parameters: protocol: \"iscsi\" portals: - \"192.168.128.122\" - \"192.168.128.123\" maxClientThreads: \"30\" Configuring a Storage Backend of the FC Type If you want to use the FC protocol, ensure that the FC network between the host and the storage device is connected before installing Huawei CSI. If the FC network is not connected, connect the FC network and then restart the huawei-csi-node service. During the restart, do not use Huawei CSI to create new resources or mount or unmount an existing PVC. The following command is used as an example:\nkubectl delete pods -n huawei-csi -l app=huawei-csi-node The following is an example of the backend configuration file of the FC type for enterprise storage:\nstorage: \"oceanstor-san\" name: \"fc-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" - \"https://192.168.129.156:8088\" pools: - \"StoragePool001\" parameters: protocol: \"fc\" maxClientThreads: \"30\" Configuring a Storage Backend of the NVMe over RoCE Type If you want to use the NVMe over RoCE protocol, ensure that the NVMe over RoCE network between the host and the storage device is connected before installing Huawei CSI. If the NVMe over RoCE network is not connected, connect the NVMe over RoCE network and then restart the huawei-csi-node service. During the restart, do not use Huawei CSI to create new resources or mount or unmount an existing PVC. The following command is used as an example:\nkubectl delete pods -n huawei-csi -l app=huawei-csi-node The following is an example of the backend configuration file of the NVMe over RoCE type for enterprise storage:\nstorage: \"oceanstor-san\" name: \"roce-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" - \"https://192.168.129.156:8088\" pools: - \"StoragePool001\" parameters: protocol: \"roce\" portals: - \"192.168.128.120\" - \"192.168.128.121\" maxClientThreads: \"30\" Configuring a Storage Backend of the NVMe over FC Type The following is an example of the backend configuration file of the NVMe over FC type for enterprise storage:\nstorage: \"oceanstor-san\" name: \"fc-nvme-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" - \"https://192.168.129.156:8088\" pools: - \"StoragePool001\" parameters: protocol: \"fc-nvme\" maxClientThreads: \"30\" Configuring a Storage Backend of the NFS Type The following is an example of the backend configuration file of the NFS type for enterprise storage:\nstorage: \"oceanstor-nas\" name: \"nfs-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" - \"https://192.168.129.156:8088\" pools: - \"StoragePool001\" parameters: protocol: \"nfs\" portals: - \"192.168.128.155\" maxClientThreads: \"30\" The following is an example of the backend configuration file of the NFS type for distributed storage:\nstorage: \"fusionstorage-nas\" name: \"nfs-126\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.125:8088\" - \"https://192.168.129.126:8088\" pools: - \"StoragePool001\" parameters: protocol: \"nfs\" portals: - \"192.168.128.123\" maxClientThreads: \"30\" Configuring a Storage Backend of the SCSI Type The following is an example of the backend configuration file of the SCSI type for distributed storage:\nstorage: \"fusionstorage-san\" name: \"scsi-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" pools: - \"StoragePool001\" parameters: protocol: \"scsi\" portals: - {\"hostname01\": \"192.168.125.21\",\"hostname02\": \"192.168.125.22\"} maxClientThreads: \"30\" Configuring a Storage Backend of the DPC Type The following is an example of the backend configuration file of the DPC type for distributed storage:\nstorage: \"fusionstorage-nas\" name: \"dpc-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" - \"https://192.168.129.156:8088\" pools: - \"StoragePool001\" parameters: protocol: \"dpc\" maxClientThreads: \"30\" Configuring Storage Backends of the Dtree Type The following is an example of the backend configuration file of the Dtree type for enterprise storage:\nstorage: \"oceanstor-dtree\" name: \"nfs-dtree\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" parameters: protocol: \"nfs\" parentname: \"parent-filesystem\" portals: - \"192.168.128.155\" maxClientThreads: \"30\" Configuring Storage Backends of the HyperMetro Type Before configuring NAS HyperMetro, you need to configure the HyperMetro relationship between two storage devices, including the remote device, HyperMetro domain, and the like. The HyperMetro domain of the file system can only work in HyperMetro active-active (AA) mode. For details about the configuration operation, see the product documentation of the corresponding storage model. The accounts for connecting to NAS HyperMetro backends must be the administrator accounts of the storage vStores. Except NAS HyperMetro backends, the management URLs of other backends cannot be the URL of a logical management port of a vStore that has established the HyperMetro relationship. When a HyperMetro storage backend is used, do not provision common file systems. Otherwise, services may be interrupted in logical port failover scenarios. CSI allows you to connect to OceanStor or OceanStor Dorado and provision HyperMetro volumes of the NFS type on the storage side. You need to configure storage backends that work in HyperMetro mode. The procedure is as follows: Create two configuration files and create backends one by one.\nThis example shows how to configure backends of the HyperMetro type for Huawei OceanStor or OceanStor Dorado. First, create local storage backend configuration file nfs-hypermetro-155.yaml.\nstorage: \"oceanstor-nas\" name: \"nfs-hypermetro-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" - \"https://192.168.129.156:8088\" pools: - \"StoragePool001\" metrovStorePairID: \"f09838237b93c000\" metroBackend: \"nfs-hypermetro-157\" parameters: protocol: \"nfs\" portals: - \"192.168.129.155\" maxClientThreads: \"30\" After the local backend is created, create remote storage backend configuration file nfs-hypermetro-157.yaml.\nstorage: \"oceanstor-nas\" name: \"nfs-hypermetro-157\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.157:8088\" - \"https://192.168.129.158:8088\" pools: - \"StoragePool001\" metrovStorePairID: \"f09838237b93c000\" metroBackend: \"nfs-hypermetro-155\" parameters: protocol: \"nfs\" portals: - \"192.168.129.157\" maxClientThreads: \"30\" ","categories":"","description":"","excerpt":"For details about the backend configuration in typical scenarios, see …","ref":"/css-docs/en/docs/storage-backend-management/managing-storage-backends/creating-a-storage-backend/examples-of-storage-backend-configuration-files-in-typical-scenarios/","tags":"","title":"Examples of Storage Backend Configuration Files in Typical Scenarios"},{"body":"Symptom The huawei-csi-node service cannot be started. When you run the kubectl describe daemonset huawei-csi-node -n huawei-csi command, error message “/var/lib/iscsi is not a directory” is reported.\nRoot Cause Analysis The /var/lib/iscsi directory does not exist in the huawei-csi-node container.\nSolution or Workaround Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nGo to the directory where the Helm project is located. If the previous Helm project cannot be found, copy the helm directory in the component package to any directory on the master node. For details about the component package path, see Table 1.\nGo to the templates directory and find the huawei-csi-node.yaml file.\ncd /templates Run the following command to set path in huawei-csi-node.yaml \u003e volumes \u003e iscsi-dir \u003e hostPath to /var/lib/iscsi, save the file, and exit.\nvi huawei-csi-node.yaml Run the following command to upgrade the Helm chart. The upgrade command will update the Deployment, DaemonSet, and RBAC resources. In the preceding command, helm-huawei-csi indicates the custom chart name and huawei-csi indicates the custom namespace.\nhelm upgrade helm-huawei-csi ./ -n huawei-csi -f values.yaml The following is an example of the command output.\nRelease \"helm-huawei-csi\" has been upgraded. Happy Helming! NAME: helm-huawei-csi LAST DEPLOYED: Thu Jun 9 07:58:15 2022 NAMESPACE: huawei-csi STATUS: deployed REVISION: 2 TEST SUITE: None ","categories":"","description":"","excerpt":"Symptom The huawei-csi-node service cannot be started. When you run …","ref":"/css-docs/en/docs/troubleshooting/huawei-csi-service-issues/failed-to-start-the-huawei-csi-node-service-with-error-message-var-lib-iscsi-is-not-a-directory-repo/","tags":"","title":"Failed to Start the huawei-csi-node Service with Error Message /var/lib/iscsi is not a directory Reported"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%B8%E8%BD%BD%E5%8D%8E%E4%B8%BAcsi/helm%E5%8D%B8%E8%BD%BD%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"Helm卸载华为CSI"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/en/docs/troubleshooting/huawei-csi-service-issues/","tags":"","title":"Huawei CSI Service Issues"},{"body":"This chapter describes the preparations for the installation.\nPrerequisites Before performing the operations described in this chapter, ensure that the following conditions are met:\nA container management platform has been deployed and is running properly, and its compatibility meets the requirements described in Kubernetes and OS Compatibility. (Mandatory for enterprise storage) Initial configuration for interconnecting with Huawei enterprise storage has been completed, including storage pool division and port configuration. The version of the storage product meets the requirements in Compatibility with Huawei Enterprise Storage. (Mandatory for distributed storage) Initial configuration for interconnecting with Huawei distributed storage has been completed, including storage pool division and port configuration. The version of the storage product meets the requirements in Compatibility with Huawei Distributed Storage. The connectivity between Huawei storage and the container platform host has been configured. For example, the worker node running huawei-csi-controller communicates properly with the management IP address of the storage device to be connected, and the worker node running huawei-csi-node communicates properly with the service IP address of the storage device to be connected. In iSCSI scenarios, the ping command can be used to verify the connectivity. Ensure that the language of the operating system is English. Ensure that storage resource names, such as storage pool names and tenant names, are in English. ","categories":"","description":"","excerpt":"This chapter describes the preparations for the installation. …","ref":"/css-docs/en/docs/installation-and-deployment/installation-preparations/","tags":"","title":"Installation Preparations"},{"body":"This section describes how to install Helm 3.\nFor details, see https://helm.sh/docs/intro/install/.\nPrerequisites Ensure that the master node in the Kubernetes cluster can access the Internet.\nProcedure Run the following command to download the Helm 3 installation script.\ncurl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 Run the following command to modify the permission on the Helm 3 installation script.\nchmod 700 get_helm.sh Determine the Helm version to be installed based on the version mapping between Helm and Kubernetes. For details about the version mapping, see Helm Version Support Policy. Then run the following command to change the DESIRED_VERSION environment variable to the Helm version to be installed and run the installation command.\nDESIRED_VERSION=v3.9.0 ./get_helm.sh Run the following command to check whether Helm 3 of the specified version is successfully installed.\nhelm version If the following information is displayed, the installation is successful.\nversion.BuildInfo{Version:\"v3.9.0\", GitCommit:\"7ceeda6c585217a19a1131663d8cd1f7d641b2a7\", GitTreeState:\"clean\", GoVersion:\"go1.17.5\"} ","categories":"","description":"","excerpt":"This section describes how to install Helm 3.\nFor details, see …","ref":"/css-docs/en/docs/common-operations/installing-helm-3/","tags":"","title":"Installing Helm 3"},{"body":"Installation Procedure Use a remote access tool, such as PuTTY, to log in to any master node in the cluster through the management IP address.\nCopy the helm directory in the Kubernetes CSI component package to any directory on the master node. For details about the Helm tool path, see Table 1.\nGo to the helm/esdk working directory.\ncd helm/esdk Prepare the values.yaml file. Huawei CSI provides the values.yaml template file in the helm/esdk directory of the software package. You can also modify parameters according to Parameters in the values.yaml File of Helm to customize Huawei CSI.\nPerform the following configuration before the installation:\nIf the container platform is Kubernetes, skip this step. If the container platform is OpenShift, perform the configuration in Installation and Configuration on the OpenShift Platform. If the container platform is Tanzu, perform the configuration in Installation and Configuration on the Tanzu Platform. Run the following command to update the storage backend CRD.\nkubectl apply -f ./crds/backend/ (Optional) Check snapshot-dependent components by following the instructions provided in Checking Volume Snapshot-Dependent Components. After confirming that the components are correct, run the following command to update the snapshot CRD. If controller.snapshot.enabled is set to false or the Kubernetes version is earlier than v1.17, you can skip this step. For details, see Table 2.\nkubectl apply -f ./crds/snapshot-crds/ --validate=false Run the following command to install Huawei CSI. In the preceding command, helm-huawei-csi indicates the custom Helm chart name, ./ indicates that the Helm project in the current directory is used, and huawei-csi indicates the custom Helm chart namespace.\nhelm install helm-huawei-csi ./ -n huawei-csi --create-namespace The following is an example of the command output.\nNAME: helm-huawei-csi LAST DEPLOYED: Wed Jun 8 11:50:28 2022 NAMESPACE: huawei-csi STATUS: deployed REVISION: 1 TEST SUITE: None After the huawei-csi service is deployed, run the following command to check whether the service is started.\nkubectl get pod -n huawei-csi The following is an example of the command output. If the Pod status is Running, the installation is successful.\nNAME READY STATUS RESTARTS AGE huawei-csi-controller-6dfcc4b79f-9vjtq 9/9 Running 0 24m huawei-csi-controller-6dfcc4b79f-csphc 9/9 Running 0 24m huawei-csi-node-g6f4k 3/3 Running 0 20m huawei-csi-node-tqs87 3/3 Running 0 20m Installation and Configuration on the OpenShift Platform For the OpenShift platform, run the following commands to create the SecurityContextConstraints resource.\nRun the following command to edit the helm_scc.yaml file.\nvi helm_scc.yaml Modify the helm_scc.yaml file. In the following command output, huawei-csi indicates the created namespace. Replace it based on the actual situation.\napiVersion: security.openshift.io/v1 kind: SecurityContextConstraints metadata: name: helm-scc allowHostDirVolumePlugin: true allowHostIPC: true allowHostNetwork: true allowHostPID: true allowHostPorts: true allowPrivilegeEscalation: true allowPrivilegedContainer: true defaultAddCapabilities: - SYS_ADMIN runAsUser: type: RunAsAny seLinuxContext: type: RunAsAny fsGroup: type: RunAsAny users: - system:serviceaccount:huawei-csi:huawei-csi-controller - system:serviceaccount:huawei-csi:huawei-csi-node Run the following command to create a SecurityContextConstraints file.\noc create -f helm_scc.yaml Installation and Configuration on the Tanzu Platform On the Tanzu platform, run the following command to configure the kubelet installation directory.\nGo to the helm/esdk directory in the installation package, run the following command to open the configuration file, modify the file, and save the file. For details about the installation package directory, see Table 1.\nvi values.yaml Modify the kubeletConfigDir parameter as follows:\n# Specify kubelet config dir path. # kubernetes and openshift is usually /var/lib/kubelet # Tanzu is usually /var/vcap/data/kubelet # CCE is usually /mnt/paas/kubernetes/kubelet kubeletConfigDir: /var/vcap/data/kubelet For TKGI 1.16 or earlier of the Tanzu platform, run the following commands to configure the RBAC permission.\nRun the following command to create a file named rbac.yaml.\nvi rbac.yaml Copy the following content to the rbac.yaml file, save the file, and exit.\napiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: huawei-csi-psp-role rules: - apiGroups: ['policy'] resources: ['podsecuritypolicies'] verbs: ['use'] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: huawei-csi-psp-role-cfg roleRef: kind: ClusterRole name: huawei-csi-psp-role apiGroup: rbac.authorization.k8s.io subjects: - kind: Group apiGroup: rbac.authorization.k8s.io name: system:serviceaccounts:huawei-csi - kind: Group apiGroup: rbac.authorization.k8s.io name: system:serviceaccounts:default Run the following command to create the RBAC permission.\nkubectl create -f rbac.yaml ","categories":"","description":"","excerpt":"Installation Procedure Use a remote access tool, such as PuTTY, to log …","ref":"/css-docs/en/docs/installation-and-deployment/installing-huawei-csi/installing-huawei-csi-using-helm/installing-huawei-csi-on-kubernetes-openshift-and-tanzu/","tags":"","title":"Installing Huawei CSI on Kubernetes, OpenShift, and Tanzu"},{"body":"Helm Installation Description This section describes how to install Huawei CSI using Helm 3.\nHuawei CSI can be installed as the root user or a non-root user. When installing Huawei CSI as a non-root user, ensure that the current user can access the API Server of the Kubernetes cluster. For details about how to configure access to the Kubernetes cluster as a non-root user, see Configuring Access to the Kubernetes Cluster as a Non-root User. Huawei CSI must be run as the root user. Helm is a software package management tool in the Kubernetes ecosystem. Similar to Ubuntu APT, CentOS YUM, or Python pip, Helm manages Kubernetes application resources.\nYou can use Helm to package, distribute, install, upgrade, and roll back Kubernetes applications in a unified manner.\nFor details about how to obtain and install Helm, see https://helm.sh/docs/intro/install/. For details about the mapping between Helm and Kubernetes versions, see https://helm.sh/docs/topics/version_skew/. When installing huawei-csi-controller, Helm deploys the following components in the workloads of the Deployment type in the specified namespace:\nhuawei-csi-driver: Huawei CSI driver. storage-backend-controller: Huawei backend management controller, used to manage storageBackendClaim resources. storage-backend-sidecar: used to manage storageBackendContent resources. Kubernetes External Provisioner: used to provide or delete volumes. Kubernetes External Attacher: used to attach or detach volumes. Kubernetes External Resizer: used to expand the capacity of volumes. Kubernetes External liveness-probe: used to determine the health status of a Pod. (Optional) huawei-csi-extender: Huawei CSI extender. (Optional) Kubernetes External Snapshotter: used to provide snapshot support (installed as CRD). (Optional) Kubernetes External Snapshot Controller: used to control volume snapshots. When installing huawei-csi-node, Helm deploys the following components in the workloads of the DaemonSet type in the specified namespace:\nhuawei-csi-driver: Huawei CSI driver. Kubernetes Node Registrar: used to process driver registration. liveness-probe: used to determine the health status of a Pod. ","categories":"","description":"","excerpt":"Helm Installation Description This section describes how to install …","ref":"/css-docs/en/docs/installation-and-deployment/installing-huawei-csi/installing-huawei-csi-using-helm/","tags":"","title":"Installing Huawei CSI Using Helm"},{"body":"Huawei CSI plug-in supports the following container management platforms.\nTable 1 Supported container management platforms\nContainer Management Platform\nVersion\nKubernetes\n1.16 to 1.30\nRed Hat OpenShift Container Platform\n4.6 EUS, 4.7, 4.8, 4.9, 4.10, 4.11, 4.12, 4.13, 4.14, 4.15\nTanzu Kubernetes\nTKGI 1.14.1, TKGI 1.15, TKGI 1.16, TKGI 1.17, TKGI 1.18\nCCE Agile\n22.3.2\nCCE\n22.9.5\nThe connection between Huawei CSI and Tanzu Kubernetes supports only the centralized storage NAS scenario. For the related FAQ, see Common Problems and Solutions for Interconnecting with the Tanzu Kubernetes Cluster. The connection between Huawei CSI and CCE or CCE Agile supports only centralized storage. The following table lists the OSs and multipathing software supported by the Huawei CSI plug-in.\nTable 2 Supported host OSs and multipathing software versions\nOS Name\nOS Version\nNative DM-Multipath Version\nHuawei UltraPath Version\nCentOS x86_64\n7.6, 7.7, 7.9\nDelivered with the OS, supporting FC/iSCSI\nUltraPath 31.1.0, supporting FC/iSCSI\nCentOS x86_64\n8.2, 8.4\nDelivered with the OS, supporting FC/iSCSI\nUltraPath 31.1.0, supporting FC/iSCSI\nUltraPath-NVMe 31.1.RC8, supporting NVMe over RoCE/NVMe over FC\nCentOS ARM\n7.6\nDelivered with the OS, supporting FC/iSCSI\nNot supported\nRocky Linux x86_64\n8.6\nDelivered with the OS, supporting FC/iSCSI\nUltraPath 31.2.1, supporting NVMe over RoCE\nSUSE 15 x86_64\nSP2, SP3\nDelivered with the OS, supporting FC/iSCSI\nUltraPath 31.1.0, supporting FC/iSCSI\nUltraPath-NVMe 31.1.RC8, supporting NVMe over RoCE/NVMe over FC\nRed Hat CoreOS x86_64\n4.6, 4.7, 4.8, 4.9, 4.10, 4.11, 4.12, 4.13, 4.14, 4.15\nDelivered with the OS, supporting FC/iSCSI\nNot supported\nUbuntu x86_64\n18.04, 20.04, 22.04\nDelivered with the OS, supporting FC/iSCSI\nNot supported\nUbuntu ARM\n22.04\nDelivered with the OS, supporting FC/iSCSI\nNot supported\nKylin x86_64\n7.6, V10 SP1, V10 SP2, V10 SP3\nDelivered with the OS, supporting FC/iSCSI\nUltraPath 31.2.0, supporting FC/iSCSI1\nKylin ARM\nV10 SP1, V10 SP2, V10 SP3\nDelivered with the OS, supporting FC/iSCSI\nUltraPath 31.3.0, supporting iSCSI2\nDebian x86_64\n9, 11, 12\nDelivered with the OS, supporting FC/iSCSI\nNot supported\nEulerOS x86_64\nV2R9, V2R10, V2R11, V2R12\nDelivered with the OS, supporting FC/iSCSI\nNot supported\nEulerOS ARM\nV2R10, V2R12\nDelivered with the OS, supporting FC/iSCSI\nNot supported\nUOS x86_64\nV20\nDelivered with the OS, supporting FC/iSCSI\nNot supported\nBC-Linux ARM\n21.10\nDelivered with the OS, supporting FC/iSCSI\nNot supported\nAnolis OS3\n8.8\nDelivered with the OS, supporting iSCSI\nNot supported\nOpenEuler x86_64\n22.03 LTS SP1\nDelivered with the OS, supporting iSCSI\nNot supported\nNote 1: Only Kylin x86_64 V10 SP2 supports UltraPath 31.2.0.\nNote 2: Only Kylin ARM V10 SP3 supports UltraPath 31.3.0.\nNote 3: Anolis OS supports only OceanStor Pacific storage.\nFor DM-Multipath 0.7, some virtual devices may not be displayed in the command output after the multipathd show maps command is executed. Therefore, you are advised to use version 0.8 or later. You can query the DM-Multipath version in either of the following ways:\nIf the rpm package is used, run the rpm -qa | grep multipath or rpm -qa | grep device-mapper command. If the deb package is used, run the dpkg -l | grep multipath command. ","categories":"","description":"","excerpt":"Huawei CSI plug-in supports the following container management …","ref":"/css-docs/en/docs/compatibility-and-features/kubernetes-and-os-compatibility/","tags":"","title":"Kubernetes and OS Compatibility"},{"body":"安装步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录集群的任意master节点。\n将Kubernetes CSI组件包中的\"helm\"目录拷贝到master节点的任意目录下。Helm工具路径请参见表 软件包组件描述。\n进入到helm/esdk的工作目录下。\ncd helm/esdk 准备values.yaml文件，华为CSI已经在软件包的helm/esdk目录下提供了values.yaml模板文件，您也可以根据Helm values.yaml参数说明修改参数对华为CSI进行定制。\n安装前配置：\n若容器平台为Kubernetes，可跳过该步骤。 若容器平台为Openshift，请根据OpenShift平台安装配置进行配置。 若容器平台为Tanzu，请根据Tanzu平台安装配置进行配置。 执行命令，更新存储后端CRD\nkubectl apply -f ./crds/backend/ （可选） 请务必按照检查卷快照依赖组件章节检查快照依赖组件，确认无误后执行执行命令更新快照CRD，如果controller.snapshot.enabled参数设置为false或Kubernetes版本低于v1.17，可跳过本步骤，详情请参考表 controller配置项说明。\nkubectl apply -f ./crds/snapshot-crds/ --validate=false 执行如下命令安装华为CSI。其中，helm-huawei-csi为自定义的Helm Chart名称，./表示使用当前目录下的Helm工程，huawei-csi为自定义的Helm Chart命名空间。\nhelm install helm-huawei-csi ./ -n huawei-csi --create-namespace 命令执行结果如下：\nNAME: helm-huawei-csi LAST DEPLOYED: Wed Jun 8 11:50:28 2022 NAMESPACE: huawei-csi STATUS: deployed REVISION: 1 TEST SUITE: None 完成huawei-csi服务部署后，可执行如下命令检查服务是否启动：\nkubectl get pod -n huawei-csi 命令结果示例如下，Pod状态为“Running“则安装成功。\nNAME READY STATUS RESTARTS AGE huawei-csi-controller-6dfcc4b79f-9vjtq 9/9 Running 0 24m huawei-csi-controller-6dfcc4b79f-csphc 9/9 Running 0 24m huawei-csi-node-g6f4k 3/3 Running 0 20m huawei-csi-node-tqs87 3/3 Running 0 20m OpenShift平台安装配置 OpenShift平台请根据以下命令创建SecurityContextConstraints资源。\n执行命令，编辑helm_scc.yaml文件。\nvi helm_scc.yaml 修改helm_scc.yaml文件。其中，下列回显中huawei-csi是指创建的命名空间，请根据实际情况填写。\napiVersion: security.openshift.io/v1 kind: SecurityContextConstraints metadata: name: helm-scc allowHostDirVolumePlugin: true allowHostIPC: true allowHostNetwork: true allowHostPID: true allowHostPorts: true allowPrivilegeEscalation: true allowPrivilegedContainer: true defaultAddCapabilities: - SYS_ADMIN runAsUser: type: RunAsAny seLinuxContext: type: RunAsAny fsGroup: type: RunAsAny users: - system:serviceaccount:huawei-csi:huawei-csi-controller - system:serviceaccount:huawei-csi:huawei-csi-node 执行命令，创建SecurityContextConstraints。\noc create -f helm_scc.yaml Tanzu平台安装配置 Tanzu平台请执行以下命令配置kubelet安装目录。\n进入到安装包的helm/esdk目录下，执行命令打开配置文件，修改后保存。安装包目录请参见表 软件包组件描述。\nvi values.yaml 修改kubeletConfigDir参数如下：\n# Specify kubelet config dir path. # kubernetes and openshift is usually /var/lib/kubelet # Tanzu is usually /var/vcap/data/kubelet # CCE is usually /mnt/paas/kubernetes/kubelet kubeletConfigDir: /var/vcap/data/kubelet Tanzu平台TKGI 1.16版本及以下请执行以下命令配置RBAC权限\n执行命令， 创建rbac.yaml文件。\nvi rbac.yaml 粘贴如下内容至rbac.yaml，保存并退出：\napiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: huawei-csi-psp-role rules: - apiGroups: ['policy'] resources: ['podsecuritypolicies'] verbs: ['use'] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: huawei-csi-psp-role-cfg roleRef: kind: ClusterRole name: huawei-csi-psp-role apiGroup: rbac.authorization.k8s.io subjects: - kind: Group apiGroup: rbac.authorization.k8s.io name: system:serviceaccounts:huawei-csi - kind: Group apiGroup: rbac.authorization.k8s.io name: system:serviceaccounts:default 执行命令，创建RBAC权限。\nkubectl create -f rbac.yaml ","categories":"","description":"","excerpt":"安装步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录集群的任意master节点。\n将Kubernetes CSI组件包中 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%AE%89%E8%A3%85%E5%8D%8E%E4%B8%BAcsi/%E4%BD%BF%E7%94%A8helm%E5%AE%89%E8%A3%85%E5%8D%8E%E4%B8%BAcsi/kubernetes-openshift-tanzu%E5%AE%89%E8%A3%85%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"Kubernetes、OpenShift、Tanzu安装华为CSI"},{"body":"前提条件 已使用Helm 3完成CSI的更新。 操作步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n进入到helm/esdk的工作目录下，目录路径请参见表 软件包组件描述。\ncd helm/esdk 执行命令，查看Helm部署CSI服务的历史版本。\nhelm history helm-huawei-csi -n huawei-csi 命令结果示例如下。\nREVISION UPDATED STATUS CHART APP VERSION DESCRIPTION 1 Mon Jan 8 04:15:40 2024\tsuperseded\tesdk-4.4.0\t4.4.0 Install complete 2 Mon Jan 8 04:16:12 2024\tdeployed esdk-4.5.0\t4.5.0 Upgrade complete 执行命令，回退CSI服务到指定版本。\n其中，revision-number为3查询到的版本号。例如版本为：1。\nhelm rollback helm-huawei-csi -n huawei-csi 1 命令结果示例如下，回显中有Rollback was a success，则表示回退CSI服务到指定版本成功。\nRollback was a success! Happy Helming! ","categories":"","description":"","excerpt":"前提条件 已使用Helm 3完成CSI的更新。 操作步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E4%BD%BF%E7%94%A8helm%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/kubernetes-openshift-tanzu%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"Kubernetes、OpenShift、Tanzu回退华为CSI"},{"body":"本章节介绍如何在Kubernetes、OpenShift、Tanzu平台卸载华为CSI。\n操作步骤 卸载huawei-csi-host-info对象使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令卸载华为CSI，helm-huawei-csi 是自定义的Helm Chart名称，huawei-csi 是该Helm Chart所在的命名空间。该卸载命令将会卸载华为CSI的huawei-csi-controller、huawei-csi-node和RBAC资源。\nhelm uninstall helm-huawei-csi -n huawei-csi 卸载命令执行后，还需要检查卸载是否成功。其中，huawei-csi 为chart所在的命名空间。\nhelm list -n huawei-csi 命令结果示例如下，如果回显为空，则表示服务卸载成功。\nNAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION 卸载huawei-csi-host-info对象，请参考卸载huawei-csi-host-info对象进行操作。\n卸载webhook资源，请参考卸载Webhook资源进行操作。\n（可选）卸载快照依赖组件服务，请参考卸载Snapshot依赖组件服务进行操作。\n（可选）卸载Lease资源，请参考卸载Lease资源进行操作。\n","categories":"","description":"","excerpt":"本章节介绍如何在Kubernetes、OpenShift、Tanzu平台卸载华为CSI。\n操作步骤 卸 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%B8%E8%BD%BD%E5%8D%8E%E4%B8%BAcsi/helm%E5%8D%B8%E8%BD%BD%E5%8D%8E%E4%B8%BAcsi/kubernetes-openshift-tanzu%E5%8D%B8%E8%BD%BD%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"Kubernetes、OpenShift、Tanzu卸载华为CSI"},{"body":"华为CSI插件支持如下容器管理平台：\n表 1 支持的容器管理平台\n容器管理平台\n版本\nKubernetes\n1.16~1.30\nRed Hat OpenShift Container Platform\n4.6 EUS, 4.7, 4.8, 4.9, 4.10, 4.11, 4.12, 4.13, 4.14, 4.15\nTanzu Kubernetes\nTKGI 1.14.1, TKGI 1.15, TKGI 1.16, TKGI 1.17, TKGI 1.18\nCCE Agile\n22.3.2\nCCE\n22.9.5\n华为CSI对接Tanzu Kubernetes仅支持集中式存储NAS场景，相关FAQ请参见对接Tanzu Kubernetes集群常见问题及解决方法。 华为CSI对接CCE/CCE Agile仅支持集中式存储。 华为CSI插件支持的操作系统以及多路径信息如下表所示。\n表 2 支持的主机操作系统及多路径软件版本\n操作系统名称\n操作系统版本\n原生DM-Multipath版本\n华为UltraPath版本\nCentOS x86_64\n7.6, 7.7, 7.9\n随OS自带，支持FC/iSCSI\nUltraPath 31.1.0，支持FC/iSCSI\nCentOS x86_64\n8.2, 8.4\n随OS自带，支持FC/iSCSI\nUltraPath 31.1.0，支持FC/iSCSI\nUltraPath-NVMe 31.1.RC8，支持NVMe over RoCE/NVMe over FC\nCentOS ARM\n7.6\n随OS自带，支持FC/iSCSI\n不支持\nRocky Linux x86_64\n8.6\n随OS自带，支持FC/iSCSI\nUltraPath 31.2.1，支持NVMe over RoCE\nSUSE 15 x86_64\nSP2, SP3\n随OS自带，支持FC/iSCSI\nUltraPath 31.1.0，支持FC/iSCSI\nUltraPath-NVMe 31.1.RC8，支持NVMe over RoCE/NVMe over FC\nRed Hat CoreOS x86_64\n4.6, 4.7, 4.8, 4.9, 4.10, 4.11, 4.12, 4.13, 4.14, 4.15\n随OS自带，支持FC/iSCSI\n不支持\nUbuntu x86_64\n18.04, 20.04, 22.04\n随OS自带，支持FC/iSCSI\n不支持\nUbuntu ARM\n22.04\n随OS自带，支持FC/iSCSI\n不支持\nKylin x86_64\n7.6, V10 SP1, V10 SP2, V10 SP3\n随OS自带，支持FC/iSCSI\nUltraPath 31.2.0，支持FC/iSCSI1\nKylin ARM\nV10 SP1, V10 SP2, V10 SP3\n随OS自带，支持FC/iSCSI\nUltraPath 31.3.0，支持iSCSI2\nDebian x86_64\n9, 11, 12\n随OS自带，支持FC/iSCSI\n不支持\nEulerOS x86_64\nV2R9, V2R10, V2R11, V2R12\n随OS自带，支持FC/iSCSI\n不支持\nEulerOS ARM\nV2R10, V2R12\n随OS自带，支持FC/iSCSI\n不支持\nUOS x86_64\nV20\n随OS自带，支持FC/iSCSI\n不支持\nBC-Linux ARM\n21.10\n随OS自带，支持FC/iSCSI\n不支持\nAnolis OS3\n8.8\n随OS自带，支持iSCSI\n不支持\nOpenEuler x86_64\n22.03 LTS SP1\n随OS自带，支持iSCSI\n不支持\n注释1 仅Kylin x86_64 V10 SP2支持UltraPath 31.2.0。\n注释2 仅Kylin ARM V10 SP3支持UltraPath 31.3.0。\n注释3 Anolis OS仅支持OceanStor Pacific存储。\n因DM-Multipath在0.7版本存在执行multipathd show maps时可能无法回显所有的虚拟设备，因此建议使用0.8及以上版本。 DM-Multipath版本可以通过以下途径查询：\n如果使用的是rpm包，执行：rpm -qa | grep multipath或rpm -qa | grep device-mapper。 如果使用的是deb包，执行：dpkg -l | grep multipath。 ","categories":"","description":"","excerpt":"华为CSI插件支持如下容器管理平台：\n表 1 支持的容器管理平台\n容器管理平台\n版本\nKubernetes\n1.16~1.30\nRed …","ref":"/css-docs/docs/%E5%85%BC%E5%AE%B9%E6%80%A7%E5%92%8C%E7%89%B9%E6%80%A7/kubernetes%E5%8F%8A%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%BC%E5%AE%B9%E6%80%A7/","tags":"","title":"Kubernetes及操作系统兼容性"},{"body":"Based on service requirements, files in containers need to be persistently stored on disks. When the containers are re-built or re-allocated to new nodes, the persistent data can still be used.\nTo persistently store data on storage devices, you need to use the PersistentVolume (PV) and PersistentVolumeClaim (PVC) when provisioning containers.\nPV: a piece of storage in the Kubernetes cluster that has been provisioned by an administrator or dynamically provisioned using a StorageClass. PVC: a request for storage by a user. A PVC consumes PV resources. A PVC can request specific size and access modes. For example, a PV can be mounted in ReadWriteOnce, ReadOnlyMany, or ReadWriteMany mode. For details, see Access Modes. This section describes how to use Huawei CSI to create, expand the capacity of, and clone a PV/PVC, as well as create a PVC using a snapshot.\n","categories":"","description":"","excerpt":"Based on service requirements, files in containers need to be …","ref":"/css-docs/en/docs/using-huawei-csi/managing-a-pvc/","tags":"","title":"Managing a PVC"},{"body":"This section describes how to create a storage backend. Currently, you can create a backend based on the configured backend yaml file or the exported configmap.json file.\nIf you create a backend by adding a backend yaml file, configure the backend file by referring to Examples of Storage Backend Configuration Files in Typical Scenarios.\nIf the exported configmap.json file exists, create a storage backend by referring to Creating a Storage Backend.\n","categories":"","description":"","excerpt":"This section describes how to create a storage backend. Currently, you …","ref":"/css-docs/en/docs/storage-backend-management/managing-storage-backends/","tags":"","title":"Managing Storage Backends"},{"body":"This section describes how to view the CSI version.\nProcedure Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to query information about the node where huawei-csi-node resides.\nkubectl get pod -A -owide | grep huawei-csi-node The following is an example of the command output.\nNAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES huawei-csi huawei-csi-node-87mss 3/3 Running 0 6m41s 192.168.129.155 node-1 \u003cnone\u003e \u003cnone\u003e huawei-csi huawei-csi-node-xp8cc 3/3 Running 0 6m41s 192.168.129.156 node-2 \u003cnone\u003e \u003cnone Use a remote access tool, such as PuTTY, to log in to any node where huawei-csi-node resides through the node IP address.\nRun the following command to view the CSI version.\ncat /var/lib/kubelet/plugins/csi.huawei.com/version The version information is displayed as follows:\n4.5.0 ","categories":"","description":"","excerpt":"This section describes how to view the CSI version.\nProcedure Use a …","ref":"/css-docs/en/docs/common-operations/collecting-information/obtaining-the-csi-version/","tags":"","title":"Obtaining the CSI Version"},{"body":"更新后端示例 执行以下命令获取更新存储后端帮助。\noceanctl update backend -h 命令结果如下：\nUpdate a backend for Ocean Storage in Kubernetes Usage: oceanctl update backend \u003cname\u003e [flags] Examples: # Update backend account information in default(huawei-csi) namespace oceanctl update backend \u003cname\u003e --password # Update backend account information in specified namespace oceanctl update backend \u003cname\u003e -n namespace --password Flags: -h, --help help for backend -n, --namespace string namespace of resources --password Update account password 执行以下命令更新存储后端信息。\noceanctl update backend backend-1 --password 根据提示输入新的用户名和密码：\nPlease enter this backend user name:admin Please enter this backend password: backend/backend-1 updated ","categories":"","description":"","excerpt":"更新后端示例 执行以下命令获取更新存储后端帮助。\noceanctl update backend -h 命令结果如下：\nUpdate a …","ref":"/css-docs/docs/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%AE%A1%E7%90%86/%E7%AE%A1%E7%90%86%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/%E6%9B%B4%E6%96%B0%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/oceanctl%E6%9B%B4%E6%96%B0%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E5%AF%86%E7%A0%81/","tags":"","title":"oceanctl更新存储后端密码"},{"body":"例1.配置文件如下：\nparameters: ALUA: \"*\": MULTIPATHTYPE: 1 FAILOVERMODE: 3 SPECIALMODETYPE: 0 PATHTYPE: 0 node1: MULTIPATHTYPE: 1 FAILOVERMODE: 3 SPECIALMODETYPE: 0 PATHTYPE: 1 对于主机名为“node1”，上述ALUA配置段都能用于配置启动器。根据配置华为企业存储后端的ALUA参数中的配置策略规则，优先级顺序为第2条配置段（HostName为\"node1\"）高于第1条配置段（HostName为\"*\"）。\n例2.配置文件如下：\nparameters: ALUA: node[0-9]: MULTIPATHTYPE: 1 FAILOVERMODE: 3 SPECIALMODETYPE: 0 PATHTYPE: 0 node[5-7]: MULTIPATHTYPE: 1 FAILOVERMODE: 3 SPECIALMODETYPE: 0 PATHTYPE: 1 对于主机名为“node6”的主机，上述ALUA配置段都能用于配置启动器。根据配置华为企业存储后端的ALUA参数中的配置策略规则，选择第一条ALUA配置段来配置启动器。\n例3.配置文件如下：\nparameters: ALUA: node$: MULTIPATHTYPE: 1 FAILOVERMODE: 3 SPECIALMODETYPE: 0 PATHTYPE: 0 node10$: MULTIPATHTYPE: 1 FAILOVERMODE: 3 SPECIALMODETYPE: 0 PATHTYPE: 1 根据配置华为企业存储后端的ALUA参数中的配置策略规则，对于主机名为“node1”的主机，选择第一条ALUA配置段来配置启动器；对于主机名为“node10”的主机，选择第二条ALUA配置段来配置启动器。^表示匹配字符串的开头，$表示匹配字符串的结尾。\n","categories":"","description":"","excerpt":"例1.配置文件如下：\nparameters: ALUA: \"*\": MULTIPATHTYPE: 1 FAILOVERMODE: 3 …","ref":"/css-docs/docs/%E9%99%84%E5%BD%95/oceanstor-v5%E7%B3%BB%E5%88%97%E5%92%8Coceanstor-dorado-v3%E7%B3%BB%E5%88%97alua%E7%89%B9%E6%80%A7%E9%85%8D%E7%BD%AE%E7%AD%96%E7%95%A5%E6%A0%B7%E4%BE%8B/","tags":"","title":"OceanStor V5系列和OceanStor Dorado V3系列ALUA特性配置策略样例"},{"body":"PVC Change File Description The sample template of the PVC change file is /examples/volumemodifyclaim.yaml. The following table lists the configuration items.\nTable 1 Parameter description\nParameter\nDescription\nMandatory\nDefault Value\nRemarks\napiVersion\nAPI group, which is of the string type.\nYes\nxuanwu.huawei.io/v1\nThe value is fixed at xuanwu.huawei.io/v1.\nkind\nResource type, which is of the string type.\nYes\nVolumeModifyClaim\nThe value is fixed at VolumeModifyClaim.\nmetadata.name\nName of a cluster resource object, which is of the string type.\nYes\n-\nThe name must comply with the naming rules of a DNS subdomain name. The value can contain a maximum of 63 characters, including digits, lowercase letters, hyphens (-), and periods (.). It must start and end with a lowercase letter or digit.\nspec.source.kind\nData source type, which is of the string type.\nYes\nStorageClass\nThis parameter can only be set to StorageClass.\nspec.source.name\nData source name, which is of the string type.\nYes\n-\nOnly a StorageClass name can be configured.\nspec.parameters.hyperMetro\nWhether to change a common volume to a HyperMetro volume. Currently, the value can only be \"true\".\nYes\n-\nOnly common storage volumes at the primary site can be changed to HyperMetro storage volumes.\nspec.parameters.metroPairSyncSpeed\nData synchronization speed of a HyperMetro pair. The value ranges from 1 to 4.\nThe value can be:\n1: low2: medium3: high4: highest No\n-\nThis parameter is available only when spec.parameters.hyperMetro is set to \"true\".\nNote:\nIf this parameter is not configured, the storage speed of the HyperMetro pair is determined by the storage device.The highest synchronization speed may increase the host latency. The spec.source.kind and spec.source.name parameters are used to specify the volume change scope. For example, if they are set to a StorageClass and the corresponding name respectively, all PVCs in the Bound state provisioned using the target StorageClass will be changed. After all associated PVCs are changed, Huawei CSI will replace the original StorageClass and add the spec.parameters parameter of the VolumeModifyClaim so that the PVCs meet the StorageClass definition. For details about the configuration in typical scenarios, see the following example:\nChanging a Common Volume to a HyperMetro Volume The following is an example of changing a common volume to a HyperMetro volume:\napiVersion: xuanwu.huawei.io/v1 kind: VolumeModifyClaim metadata: name: myvmc spec: source: kind: StorageClass name: mysc parameters: hyperMetro: \"true\" ","categories":"","description":"","excerpt":"PVC Change File Description The sample template of the PVC change file …","ref":"/css-docs/en/docs/advanced-features/pvc-change/configuring-pvc-changes/creating-a-pvc-change/preparing-a-pvc-change-file/","tags":"","title":"Preparing a PVC Change File"},{"body":"Table 1 Static volume provisioning parameters\nParameter\nDescription\nMandatory\nDefault Value\nRemarks\nmetadata.name\nUser-defined name of a PV object.\nYes\n-\nTake Kubernetes v1.22.1 as an example. The value can contain digits, lowercase letters, hyphens (-), and periods (.), and must start and end with a letter or digit.\nspec.volumeMode\nVolume mode. This parameter is optional. When LUN volumes are used, the following types are supported:\nFilesystem: local file system.Block: raw device. No\nFilesystem\nThis parameter takes effect when a PV is mounted. The default value is Filesystem.\nFilesystem indicates that a container accesses a PV using a local file system. The local file system type is specified by the fsType field in the specified StorageClass.Block indicates that a PV is accessed in raw volume mode. spec.storageClassName\nName of the StorageClass object. This parameter is mandatory.\nYes\n-\nSet the parameter to an empty string, that is, enter \"\".\nspec.accessModes\nAccess mode of the volume.\nRWO (ReadWriteOnce): A volume can be mounted to a node in read/write mode. This mode also allows multiple Pods running on the same node to access the volume.ROX (ReadOnlyMany): A volume can be mounted to multiple nodes in read-only mode.RWX (ReadWriteMany): A volume can be mounted to multiple nodes in read/write mode.RWOP (ReadWriteOncePod): A volume can only be mounted to a single Pod in read/write mode. Kubernetes 1.22 and later versions support this feature. Yes\nReadWriteOnce\nRWO/ROX/RWOP: supported by all types of volumes. RWOP is supported only by Kubernetes 1.22 and later versions. Check whether this feature is enabled for your Kubernetes cluster by referring to Enabling the ReadWriteOncePod Feature Gate.The support for RWX is as follows:NAS storage: supported by all volumesSAN storage: supported only by volumes whose volumeMode is set to Block spec.csi.driver\nCSI driver name.\nYes\ncsi.huawei.com\nSet this parameter to the driver name set during Huawei CSI installation.\nspec.csi.volumeHandle\nUnique identifier of a storage resource. This parameter is mandatory.\nFormat: \u003cbackendName\u003e.\u003cvolume-name\u003e\nYes\n-\nThe value of this parameter consists of the following parts:\n\u003cbackendName\u003e: indicates the name of the backend where the volume resides. You can run the following command to obtain the configured backend information.oceanctl get backend\n\u003cvolume-name\u003e: indicates the name of a resource (LUN/file system) on the storage. You can obtain the value from DeviceManager. spec.csi.fsType\nType of a host file system. This parameter is optional. The supported types are:\next2ext3ext4xfs No\n-\nIf this parameter is not set, the default value ext4 is used. This parameter is available only when volumeMode is set to Filesystem.\nspec.capacity.storage\nVolume size.\nYes\n100Gi\nEnsure that the size is the same as that of the corresponding resource on the storage. Kubernetes will not invoke CSI to check whether the value of this parameter is correct. Therefore, the PV can be successfully created even if its capacity is inconsistent with that of the corresponding resource on the storage.\nspec.mountOptions.nfsvers\nNFS mount option on the host. The following mount option is supported:\nnfsvers: protocol version for NFS mounting. The value can be 3, 4, 4.0, 4.1, or 4.2.\nNo\n-\nThis parameter is optional after the -o parameter when the mount command is executed on the host. The value is in list format.\nIf the NFS version is specified for mounting, NFS 3, 4.0, 4.1, and 4.2 protocols are supported (the protocol must be supported and enabled on storage devices). If nfsvers is set to 4, the latest protocol version NFS 4 may be used for mounting due to different OS configurations, for example, 4.2. If the 4.0 protocol is required, you are advised to set nfsvers to 4.0.\nspec.mountOptions.acl\nThe DPC namespace supports the ACL function. The DPC client supports POSIX ACL, NFSv4 ACL, and NT ACL authentication.\nNo\n-\nThe descriptions of acl, aclonlyposix, cnflush, and cflush are for reference only. For details about the parameters, see OceanStor Pacific Series Product Documentation and choose Configuration \u003e Basic Service Configuration Guide for File \u003e Configuring Basic Services (DPC Scenario) \u003e Accessing a DPC Share on a Client \u003e Step 2.\nspec.mountOptions.aclonlyposix\nThe DPC namespace supports POSIX ACL, and the DPC client supports POSIX ACL authentication.\nThe following protocols support POSIX ACL: DPC, NFSv3, and HDFS. If NFSv4 ACL or NT ACL is used, the DPC client cannot identify the ACL of this type. As a result, the ACL of this type does not take effect.\nNo\n-\nIf aclonlyposix and acl are used together, only acl takes effect. That is, the namespace supports the ACL function.\nspec.mountOptions.cnflush\nAsynchronous disk flushing mode. That is, data is not flushed to disks immediately when files in the namespace are closed.\nNo\n-\nAsynchronous flushing mode: When a file is closed, data in the cache is not flushed to storage media in synchronous mode. Instead, data is written from the cache to the storage media in asynchronous flushing mode. After the write service is complete, data is flushed from the cache to disks periodically based on the flushing period. In a multi-client scenario, if concurrent operations are performed on the same file, the file size update is affected by the disk flushing period. That is, the file size is updated only after the disk flushing is complete. Generally, the update is completed within several seconds. Synchronous I/Os are not affected by the disk flushing period.\nspec.mountOptions.cflush\nSynchronous disk flushing mode. That is, data is flushed to disks immediately when files in the namespace are closed.\nNo\n-\nBy default, the synchronous disk flushing mode is used.\n","categories":"","description":"","excerpt":"Table 1 Static volume provisioning parameters\nParameter\nDescription …","ref":"/css-docs/en/docs/using-huawei-csi/managing-a-pvc/creating-a-pvc/static-volume-provisioning/pv-parameters-for-static-volume-provisioning/","tags":"","title":"PV Parameters for Static Volume Provisioning"},{"body":"根据业务的需求，容器中的文件需要在磁盘上进行持久化。当容器被重建或者重新分配至新的节点时，可以继续使用这些持久化数据。\n为了可以将数据持久化到存储设备上，您需要在发放容器时使用持久卷（PersistentVolume，PV）以及持久卷申领（PersistentVolumeClaim，PVC）。\nPV：是Kubernetes集群中的一块存储，可以由管理员事先制备， 或者使用存储类（StorageClass）来动态制备。 PVC：是用户对存储的请求。PVC会耗用 PV 资源。PVC可以请求特定的大小和访问模式 （例如，可以要求 PV能够以 ReadWriteOnce、ReadOnlyMany 或 ReadWriteMany 模式之一来挂载，参见访问模式）。 本章将介绍如何使用华为CSI对PV/PVC进行创建、扩容、克隆以及从快照创建PVC。\n","categories":"","description":"","excerpt":"根据业务的需求，容器中的文件需要在磁盘上进行持久化。当容器被重建或者重新分配至新的节点时，可以继续使用这些持久化数据。\n为了可以将数据持久化 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/pvc%E7%AE%A1%E7%90%86/","tags":"","title":"PVC管理"},{"body":"Prerequisites CSI has been updated using Helm 3. Procedure Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nGo to the helm/esdk working directory. For the directory path, see Table 1.\ncd helm/esdk Run the following command to query the historical versions of the CSI services deployed using Helm.\nhelm history helm-huawei-csi -n huawei-csi The following is an example of the command output.\nREVISION UPDATED STATUS CHART APP VERSION DESCRIPTION 1 Mon Jan 8 04:15:40 2024\tsuperseded\tesdk-4.4.0\t4.4.0 Install complete 2 Mon Jan 8 04:16:12 2024\tdeployed esdk-4.5.0\t4.5.0 Upgrade complete Run the following command to roll back the CSI services to the specified version.\nIn the preceding command, revision-number indicates a version number queried in 3. For example, the version is 1.\nhelm rollback helm-huawei-csi -n huawei-csi 1 The following is an example of the command output. If Rollback was a success is displayed in the command output, the CSI services are successfully rolled back to the specified version.\nRollback was a success! Happy Helming! ","categories":"","description":"","excerpt":"Prerequisites CSI has been updated using Helm 3. Procedure Use a …","ref":"/css-docs/en/docs/installation-and-deployment/upgrading-or-rolling-back-huawei-csi/upgrading-or-rolling-back-huawei-csi-using-helm/rolling-back-huawei-csi/rolling-back-huawei-csi-on-kubernetes-openshift-and-tanzu/","tags":"","title":"Rolling Back Huawei CSI on Kubernetes, OpenShift, and Tanzu"},{"body":"A StorageClass provides administrators with methods to describe a storage “class”. Different types may map to a different group of capability definitions. Kubernetes cluster users can dynamically provision volumes based on a StorageClass.\nIf SAN storage is used, refer to example file /examples/sc-lun.yaml. If NAS storage is used, refer to example file /examples/sc-fs.yaml.\nFor details about how to configure a StorageClass in typical scenarios, see the following examples:\nSetting the Backend and Storage Pool in a StorageClass Setting the NFS Access Mode in a StorageClass Setting a Dtree Type in a StorageClass Setting the Local File System Access Mode in a StorageClass Setting the DPC Access Mode in a StorageClass Setting an Application Type in a StorageClass Setting a Soft Quota in a StorageClass Setting HyperMetro in a StorageClass Setting the Permission on a Mount Directory in a StorageClass Setting QoS in a StorageClass Configuring a StorageClass on the CCE or CCE Agile Platform Setting the Backend and Storage Pool in a StorageClass If multiple Huawei backends are configured in a Kubernetes cluster or a Huawei backend provides multiple storage pools, you are advised to configure the specified backend and storage pool information in the StorageClass. This prevents Huawei CSI from randomly selecting backends and storage pools and ensures that the storage device where the volume resides complies with the plan.\nFor details about how to set the backend and storage pool for SAN storage, see the following configuration example.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com allowVolumeExpansion: true parameters: backend: \"san-181\" # Enter the storage backend name. pool: \"pool001\" # Enter the storage pool name volumeType: lun allocType: thin For details about how to set the backend and storage pool for NAS storage, see the following configuration example.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com allowVolumeExpansion: true parameters: backend: \"san-181\" # Enter the storage backend name. pool: \"pool001\" # Enter the storage pool name volumeType: fs allocType: thin authClient: \"*\" Setting the NFS Access Mode in a StorageClass When a container uses an NFS file system as a storage resource, refer to the following configuration example. In this example, NFS version 4.1 is specified for mounting.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: nfs-nas-181 pool: pool001 volumeType: fs allocType: thin authClient: \"192.168.0.10;192.168.0.0/24;myserver1.test\" mountOptions: - nfsvers=4.1 # Specify the version 4.1 for NFS mounting. Setting a Dtree Type in a StorageClass When a container uses a Dtree as a storage resource, refer to the following configuration example.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: nfs-dtree volumeType: dtree # Set the volume type to dtree. allocType: thin authClient: \"*\" mountOptions: - nfsvers=4.1 Setting the Local File System Access Mode in a StorageClass If a container uses a LUN of enterprise storage or distributed storage as a storage resource and a file system needs to be formatted as a local file system, refer to the following example.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: iscsi-lun-181 pool: pool001 volumeType: lun allocType: thin fsType: xfs Setting the DPC Access Mode in a StorageClass If a container uses OceanStor Pacific series storage and the storage supports DPC-based access, you can configure mounting parameters for DPC-based access in the StorageClass. In this example, acl is used as the authentication parameter for mounting, and cnflush is used to set the asynchronous disk flushing mode.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: nfs-dpc-101 pool: pool001 volumeType: fs allocType: thin authClient: \"*\" mountOptions: - acl # Set the authentication parameter. - cnflush # Set the asynchronous disk flushing mode. Setting an Application Type in a StorageClass When a container uses a LUN of OceanStor Dorado as the storage, if the default application type of the storage cannot meet the I/O model requirements of some services (for example, the container provides the database OLAP service), you can configure an application type in the StorageClass to improve storage performance. For details about the application types to be used, see the product documentation of the corresponding storage product.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: iscsi-lun-181 pool: pool001 volumeType: lun allocType: thin fsType: xfs applicationType: Oracle_OLAP # Set the application type. Setting a Soft Quota in a StorageClass If a container uses a file system of OceanStor Pacific series as the storage, you can configure a soft quota in the StorageClass. The following is a configuration example.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: nfs-pacific-101 pool: pool001 volumeType: fs allocType: thin authClient: \"*\" storageQuota: '{\"spaceQuota\": \"softQuota\", \"gracePeriod\": 100}' # Configure the soft quota. mountOptions: - nfsvers=3 Setting QoS in a StorageClass When containers use enterprise storage or distributed storage as storage resources, you can set QoS for the storage resources used by containers to ensure that the storage read and write operations of these containers meet certain service levels.\nStorage devices of different models or versions support different QoS settings. For details about how to find the configuration items of the corresponding storage devices, see Table 2. In this example, the backend is OceanStor Dorado. For other storage devices, refer to this example.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: iscsi-qos-181 pool: pool001 volumeType: lun allocType: thin fsType: xfs qos: '{\"IOTYPE\": 2, \"MINIOPS\": 1000}' # Configure QoS. vStore users of OceanStor V5 cannot configure QoS policies. The QoS configuration takes effect only on the newly created PVC. QoS cannot be added automatically for PVCs with the same StorageClass name that have been provisioned. Setting HyperMetro in a StorageClass When a container uses an NFS HyperMetro file system as a storage resource, refer to the following configuration example. In this example, the used backend supports HyperMetro, and hyperMetro is set to true.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: nfs-hypermetro-dorado-181 pool: pool001 volumeType: fs hyperMetro: \"true\" # Provision HyperMetro volumes. allocType: thin authClient: \"*\" Before provisioning a NAS HyperMetro volume, you need to configure the HyperMetro relationship between two storage devices, including the remote device, HyperMetro domain, and the like. The HyperMetro domain of the file system can only work in HyperMetro active-active (AA) mode. For details about the configuration operation, see the product documentation of the corresponding storage model. If a storage device is faulty, the logical management port may fail over. In this case, you need to manually clear the corresponding storage resources after deleting the NAS HyperMetro volume. Setting the Permission on a Mount Directory in a StorageClass To modify the permission on a mount directory in a container, you can configure the directory permission in a StorageClass. The following is a configuration example.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com allowVolumeExpansion: true parameters: volumeType: fs allocType: thin authClient: \"*\" fsPermission: \"777\" rootSquash: \"no_root_squash\" # Only NAS storage supports this parameter. allSquash: \"no_all_squash\" # Only NAS storage supports this parameter. After the StorageClass configuration is complete, perform the following steps to create a StorageClass.\nRun the following command to create a StorageClass based on the .yaml file.\nkubectl create -f mysc.yaml Run the following command to view the information about the created StorageClass.\nkubectl get sc The following is an example of the command output.\nNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE mysc csi.huawei.com Delete Immediate false 34s After creating a StorageClass, you can use the StorageClass to create a PV or PVC.\nPay attention to the following when using a StorageClass:\nModifications to a StorageClass do not take effect on existing PVs. You need to delete these PVs and create them again using the modified StorageClass to apply the modified parameters. Configuring a StorageClass on the CCE or CCE Agile Platform Create a StorageClass of the NAS type on the CCE or CCE Agile platform. The following is a configuration example. The value of provisioner must be the same as that of driverName in the values.yaml file.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc annotations: storageclass.kubernetes.io/storageType: file provisioner: csi.oceanstor.com allowVolumeExpansion: true parameters: volumeType: fs allocType: thin authClient: \"*\" Create a StorageClass of the Block type on the CCE or CCE Agile platform. The following is a configuration example. The value of provisioner must be the same as that of driverName in the values.yaml file.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc annotations: storageclass.kubernetes.io/storageType: block provisioner: csi.oceanstor.com allowVolumeExpansion: true parameters: volumeType: lun allocType: thin ","categories":"","description":"","excerpt":"A StorageClass provides administrators with methods to describe a …","ref":"/css-docs/en/docs/using-huawei-csi/managing-a-pvc/creating-a-pvc/dynamic-volume-provisioning/storageclass-configuration-examples-in-typical-dynamic-volume-provisioning-scenarios/","tags":"","title":"StorageClass Configuration Examples in Typical Dynamic Volume Provisioning Scenarios"},{"body":"For details about how to configure a StorageClass in typical Manage Volume Provisioning scenarios, see the following examples:\nSetting the Backend and Storage Pool in a StorageClass Setting the NFS Access Mode in a StorageClass Setting the Local File System Access Mode in a StorageClass Setting the DPC Access Mode in a StorageClass Setting the Permission on a Mount Directory in a StorageClass Setting the Backend and Storage Pool in a StorageClass If multiple Huawei backends are configured in a Kubernetes cluster or a Huawei backend provides multiple storage pools, you are advised to configure the specified backend and storage pool information in the StorageClass. This prevents Huawei CSI from randomly selecting backends and storage pools and ensures that the storage device where the volume resides complies with the plan.\nFor details about how to set the backend and storage pool for SAN storage, see the following configuration example.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com allowVolumeExpansion: true parameters: backend: \"iscsi-san-181\" pool: \"pool001\" volumeType: lun allocType: thin For details about how to set the backend and storage pool for NAS storage, see the following configuration example.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com allowVolumeExpansion: true parameters: backend: \"iscsi-nas-181\" pool: \"pool001\" volumeType: fs allocType: thin authClient: \"*\" Setting the NFS Access Mode in a StorageClass When a container uses an NFS file system as a storage resource, refer to the following configuration example. In this example, NFS version 4.1 is specified for mounting.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: nfs-nas-181 pool: pool001 volumeType: fs allocType: thin mountOptions: - nfsvers=4.1 # Specify the version 4.1 for NFS mounting. Setting the Local File System Access Mode in a StorageClass If a container uses a LUN of enterprise storage or distributed storage as a storage resource and a file system needs to be formatted as a local file system, refer to the following example.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: iscsi-lun-181 pool: pool001 volumeType: lun allocType: thin fsType: xfs Setting the DPC Access Mode in a StorageClass If a container uses OceanStor Pacific series storage and the storage supports DPC-based access, you can configure mounting parameters for DPC-based access in the StorageClass. In this example, acl is used as the authentication parameter for mounting, and cnflush is used to set the asynchronous disk flushing mode.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: nfs-dpc-101 pool: pool001 volumeType: fs allocType: thin authClient: \"*\" mountOptions: - acl # Set the authentication parameter. - cnflush # Set the asynchronous disk flushing mode. Setting the Permission on a Mount Directory in a StorageClass To modify the permission on a mount directory in a container, you can configure the directory permission in a StorageClass. The following is a configuration example.\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com allowVolumeExpansion: true parameters: volumeType: fs allocType: thin authClient: \"*\" fsPermission: \"777\" # Set the directory permission. After the StorageClass configuration is complete, perform the following steps to create a StorageClass.\nRun the following command to create a StorageClass based on the .yaml file.\nkubectl create -f mysc.yaml Run the following command to view the information about the created StorageClass.\nkubectl get sc The following is an example of the command output.\nNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE mysc csi.huawei.com Delete Immediate false 34s After creating a StorageClass, you can use the StorageClass to create a PV or PVC.\nIn the Manage Volume Provisioning mode, pay attention to the following when using a StorageClass:\nModifications to a StorageClass do not take effect on existing PVs. You need to delete these PVs and create them again using the modified StorageClass to apply the modified parameters. ","categories":"","description":"","excerpt":"For details about how to configure a StorageClass in typical Manage …","ref":"/css-docs/en/docs/using-huawei-csi/managing-a-pvc/creating-a-pvc/manage-volume-provisioning/storageclass-configuration-examples-in-typical-manage-volume-provisioning-scenarios/","tags":"","title":"StorageClass Configuration Examples in Typical Manage Volume Provisioning Scenarios"},{"body":"This section describes how to uninstall Huawei CSI on the Kubernetes, OpenShift, and Tanzu platforms.\nProcedure Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to uninstall Huawei CSI. In the command, helm-huawei-csi indicates the custom Helm chart name and huawei-csi indicates the namespace where the Helm chart resides. This command will uninstall the huawei-csi-controller, huawei-csi-node, and RBAC resources of Huawei CSI.\nhelm uninstall helm-huawei-csi -n huawei-csi After the uninstallation command is executed, you need to check whether the uninstallation is successful. In the preceding command, huawei-csi indicates the namespace where the chart is located.\nhelm list -n huawei-csi The following is an example of the command output. If the command output is empty, the service is successfully uninstalled.\nNAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION Uninstall the huawei-csi-host-info object. For details, see Uninstalling the huawei-csi-host-info Object.\nUninstall the webhook resource. For details, see Uninstalling a Webhook Resource.\n(Optional) Uninstall the snapshot-dependent component service. For details, see Uninstalling the Snapshot-Dependent Component Service.\n(Optional) Uninstall the Lease resource. For details, see Uninstalling a Lease Resource.\n","categories":"","description":"","excerpt":"This section describes how to uninstall Huawei CSI on the Kubernetes, …","ref":"/css-docs/en/docs/installation-and-deployment/uninstalling-huawei-csi/uninstalling-huawei-csi-using-helm/uninstalling-huawei-csi-on-kubernetes-openshift-and-tanzu/","tags":"","title":"Uninstalling Huawei CSI on Kubernetes, OpenShift, and Tanzu"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/en/docs/installation-and-deployment/uninstalling-huawei-csi/uninstalling-huawei-csi-using-helm/","tags":"","title":"Uninstalling Huawei CSI Using Helm"},{"body":"Example of Updating a Backend Run the following command to obtain the help information about updating a storage backend.\noceanctl update backend -h The following is an example of the command output.\nUpdate a backend for Ocean Storage in Kubernetes Usage: oceanctl update backend \u003cname\u003e [flags] Examples: # Update backend account information in default(huawei-csi) namespace oceanctl update backend \u003cname\u003e --password # Update backend account information in specified namespace oceanctl update backend \u003cname\u003e -n namespace --password Flags: -h, --help help for backend -n, --namespace string namespace of resources --password Update account password Run the following command to update a storage backend.\noceanctl update backend backend-1 --password Enter the user name and new password as prompted:\nPlease enter this backend user name:admin Please enter this backend password: backend/backend-1 updated ","categories":"","description":"","excerpt":"Example of Updating a Backend Run the following command to obtain the …","ref":"/css-docs/en/docs/storage-backend-management/managing-storage-backends/updating-a-storage-backend/updating-the-password-of-a-storage-backend-using-oceanctl/","tags":"","title":"Updating the Password of a Storage Backend Using oceanctl"},{"body":" In CSI 2.x or 3.x, when block storage is used, the mapping with storage is set up in the huawei-csi-node service. Therefore, the huawei-csi-node service needs to communicate with the storage management network. Because the huawei-csi-node service is deployed as a DaemonSet, the huawei-csi-node service is deployed on each node in the cluster. As a result, in a large-scale cluster, each huawei-csi-node service sends requests to the storage and the number of storage connections may be fully occupied. Accordingly, huawei-csi-node cannot provide services properly. In CSI 4.x, the deployment model is optimized. The setup of the mapping with storage is migrated to the huawei-csi-controller service and the huawei-csi-node service does not need to communicate with the storage management network. This reduces the networking complexity of Huawei CSI. In addition, the huawei-csi-controller service is deployed as a Deployment. The number of copies is set based on the customer’s reliability requirements. Generally, the number of copies ranges from 1 to 3. Therefore, the number of connections between Huawei CSI and storage is greatly reduced, so that Huawei CSI can connect to a large-scale cluster. This change may cause a problem. That is, if a new mount process is generated after CSI is upgraded to 4.x but with workloads provisioned using 2.x or 3.x and the Container Orchestration (CO) system does not invoke the huawei-csi-controller service provided by Huawei CSI, the mounting will fail. For details, see A Pod Fails to Be Created and Message “publishInfo doesn’t exist” Is Displayed in the Events Log.\nBacking Up Storage Backend Configurations If you have evaluated the risks mentioned in the preceding notice and need to upgrade CSI from 2.x or 3.x to 4.5.0, perform the following steps to back up storage backend configurations:\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to back up the backend information to the configmap.json file. For the OpenShift platform, replace kubectl with oc.\nkubectl get cm huawei-csi-configmap -n huawei-csi -o json \u003e configmap.json Upgrading Huawei CSI Perform the upgrade according to the procedure described in Upgrading Huawei CSI.\nConfiguring the Storage Backend Configure the storage backend by following the instructions in Managing Storage Backends according to the backend information backed up in Backing Up Storage Backend Configurations. After the storage backend is successfully configured, perform operations according to the risk handling methods described in the preceding notice to prevent problems during Pod failover.\n","categories":"","description":"","excerpt":" In CSI 2.x or 3.x, when block storage is used, the mapping with …","ref":"/css-docs/en/docs/installation-and-deployment/upgrading-or-rolling-back-huawei-csi/upgrading-or-rolling-back-huawei-csi-using-helm/upgrading-huawei-csi/upgrading-from-2-x-or-3-x-to-4-x/","tags":"","title":"Upgrading from 2.x or 3.x to 4.x"},{"body":"This section describes how to manually upgrade Huawei CSI.\nDuring the upgrade or rollback, the existing resources such as PVCs, snapshots, and Pods will run properly and will not affect your service access.\nSome CSI 2.x versions are unavailable now. If the upgrade fails, CSI may fail to be rolled back to a version which is unavailable now. During the upgrade or rollback, you cannot use Huawei CSI to create new resources or mount or unmount an existing PVC. During the upgrade or rollback, do not uninstall the snapshot-dependent component service. Upgrading CSI from 2.x or 3.x to 4.5.0 To upgrade CSI from 2.x or 3.x to 4.5.0, perform the following operations:\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to back up the backend information to the configmap.json file. For the OpenShift platform, replace kubectl with oc.\nkubectl get cm huawei-csi-configmap -n huawei-csi -o json \u003e configmap.json Uninstall CSI. For details, see Manually Uninstalling Huawei CSI.\nInstall CSI of the current version. For details, see Manually Installing Huawei CSI.\nInstall the backend information backed up in 2 according to Managing Storage Backends.\nUpgrading CSI from 4.x to 4.5.0 To upgrade CSI from 4.x to 4.5.0, perform the following operations:\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address. Uninstall CSI. For details, see Manually Uninstalling Huawei CSI. Install CSI of the current version. For details, see Manually Installing Huawei CSI. ","categories":"","description":"","excerpt":"This section describes how to manually upgrade Huawei CSI.\nDuring the …","ref":"/css-docs/en/docs/installation-and-deployment/upgrading-or-rolling-back-huawei-csi/manual-upgrade-rollback/upgrading-huawei-csi-0/","tags":"","title":"Upgrading Huawei CSI"},{"body":"This section describes how to upgrade Huawei CSI.\nDuring the upgrade or rollback, the existing resources such as PVCs, snapshots, and Pods will run properly and will not affect your service access.\nSome CSI 2.x versions are unavailable now. If the upgrade fails, CSI may fail to be rolled back to a version which is unavailable now. After an upgrade from 2.x, 3.x, or 4.x to 4.5.0, a Pod that has been provisioned in the source version may fail to be mounted again. For details, see Upgrading from 2.x or 3.x to 4.x. During the upgrade or rollback, you cannot use Huawei CSI to create new resources or mount or unmount an existing PVC. During the upgrade or rollback, do not uninstall the snapshot-dependent component service. ","categories":"","description":"","excerpt":"This section describes how to upgrade Huawei CSI.\nDuring the upgrade …","ref":"/css-docs/en/docs/installation-and-deployment/upgrading-or-rolling-back-huawei-csi/upgrading-or-rolling-back-huawei-csi-using-helm/upgrading-huawei-csi/","tags":"","title":"Upgrading Huawei CSI"},{"body":"To upgrade Huawei CSI from 2.x to 4.5.0, uninstall it by referring to the user guide of the earlier version and install Huawei CSI by referring to Installing Huawei CSI Using Helm.\nTo upgrade Huawei CSI from 2.x or 3.x to 4.5.0, see Upgrading from 2.x or 3.x to 4.x.\nTo upgrade Huawei CSI from 4.x to 4.5.0, see Upgrading Huawei CSI on Kubernetes, OpenShift, and Tanzu.\n","categories":"","description":"","excerpt":"To upgrade Huawei CSI from 2.x to 4.5.0, uninstall it by referring to …","ref":"/css-docs/en/docs/installation-and-deployment/upgrading-or-rolling-back-huawei-csi/upgrading-or-rolling-back-huawei-csi-using-helm/","tags":"","title":"Upgrading or Rolling Back Huawei CSI Using Helm"},{"body":"Symptom A PVC is created. After a period of time, the PVC is still in the Pending state.\nRoot Cause Analysis Cause 1: A StorageClass with the specified name is not created in advance. As a result, Kubernetes cannot find the specified StorageClass name when a PVC is created.\nCause 2: The storage pool capability does not match the StorageClass capability. As a result, huawei-csi fails to select a storage pool.\nCause 3: An error code (for example, 50331651) is returned by a RESTful interface of the storage. As a result, huawei-csi fails to create a PVC.\nCause 4: The storage does not return a response within the timeout period set by huawei-csi. As a result, huawei-csi returns a timeout error to Kubernetes.\nCause 5: Other causes.\nSolution or Workaround When a PVC is created, if the PVC is in the Pending state, you need to take different measures according to the following causes.\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to view details about the PVC.\nkubectl describe pvc mypvc Perform the corresponding operation according to the Events information in the detailed PVC information.\nIf the PVC is in the Pending state due to cause 1, perform the following steps.\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Warning ProvisioningFailed 0s (x15 over 3m24s) persistentvolume-controller storageclass.storage.k8s.io \"mysc\" not found Delete the PVC. Create a StorageClass. For details, see StorageClass Configuration Examples in Typical Dynamic Volume Provisioning Scenarios. Create a PVC. For details, see PVC Parameters for Dynamic Volume Provisioning. If the PVC is in the Pending state due to cause 2, perform the following steps.\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Provisioning 63s (x3 over 64s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 External provisioner is provisioning volume for claim \"default/mypvc\" Warning ProvisioningFailed 63s (x3 over 64s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 failed to provision volume with StorageClass \"mysc\": rpc error: code = Internal desc = failed to select pool, the capability filter failed, error: failed to select pool, the final filter field: replication, parameters map[allocType:thin replication:True size:1099511627776 volumeType:lun]. please check your storage class Delete the PVC. Delete the StorageClass. Modify the StorageClass.yaml file based on the Events information. Create a StorageClass. For details, see StorageClass Configuration Examples in Typical Dynamic Volume Provisioning Scenarios. Create a PVC. For details, see PVC Parameters for Dynamic Volume Provisioning. If the PVC is in the Pending state due to cause 3, contact Huawei engineers.\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Provisioning 63s (x4 over 68s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 External provisioner is provisioning volume for claim \"default/mypvc\" Warning ProvisioningFailed 62s (x4 over 68s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 failed to provision volume with StorageClass \"mysc\": rpc error: code = Internal desc = Create volume map[ALLOCTYPE:1 CAPACITY:20 DESCRIPTION:Created from Kubernetes CSI NAME:pvc-63ebfda5-4cf0-458e-83bd-ecc PARENTID:0] error: 50331651 If the PVC is in the Pending state due to cause 4, perform the following steps.\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Provisioning 63s (x3 over 52s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 External provisioner is provisioning volume for claim \"default/mypvc\" Warning ProvisioningFailed 63s (x3 over 52s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 failed to provision volume with StorageClass \"mysc\": rpc error: code = Internal desc = context deadline exceeded (Client.Timeout exceeded while awaiting headers) Wait for 10 minutes and check the PVC details again by referring to this section. If it is still in the Pending state, contact Huawei engineers. If the PVC is in the Pending state due to cause 5, contact Huawei engineers.\n","categories":"","description":"","excerpt":"Symptom A PVC is created. After a period of time, the PVC is still in …","ref":"/css-docs/en/docs/troubleshooting/pvc-issues/when-a-pvc-is-created-the-pvc-is-in-the-pending-state/","tags":"","title":"When a PVC Is Created, the PVC Is in the Pending State"},{"body":"本章节指导用户如何安装Helm 3。\n参考：https://helm.sh/docs/intro/install/\n前提条件 确保Kubernetes集群中的master节点可以访问Internet。\n操作步骤 执行以下命令，下载Helm 3的安装脚本。\ncurl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 执行以下命令，修改Helm 3的安装脚本权限。\nchmod 700 get_helm.sh 根据Helm与Kubernetes版本配套关系确认需要安装的Helm版本，配套关系请参考Helm Version Support Policy，执行以下命令，修改DESIRED_VERSION环境变量为需要安装的Helm版本，并执行安装命令。\nDESIRED_VERSION=v3.9.0 ./get_helm.sh 执行以下命令，查看指定版本的Helm 3是否安装成功。\nhelm version 命令结果示例如下，说明安装成功。\nversion.BuildInfo{Version:\"v3.9.0\", GitCommit:\"7ceeda6c585217a19a1131663d8cd1f7d641b2a7\", GitTreeState:\"clean\", GoVersion:\"go1.17.5\"} ","categories":"","description":"","excerpt":"本章节指导用户如何安装Helm 3。\n参考：https://helm.sh/docs/intro/install/\n前提条件 确 …","ref":"/css-docs/docs/%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/%E5%AE%89%E8%A3%85helm-3/","tags":"","title":"安装Helm 3"},{"body":"本章节将对安装前的准备工作进行详细说明。\n前提条件 在进行本章节所说明的操作前，请确保如下条件已经具备：\n容器管理平台已部署完成并正常运行，且兼容性满足Kubernetes及操作系统兼容性章节的要求。 （企业存储必选）已完成对接华为企业存储初始化配置，包括存储池划分、端口配置等。且存储产品的版本满足华为企业存储兼容性章节的要求。 （分布式存储必选）已完成对接华为分布式存储初始化配置，包括存储池划分、端口配置等。且存储产品的版本满足华为分布式存储兼容性章节的要求。 完成华为存储和容器平台主机连通性配置，例如运行huawei-csi-controller的worker节点与待接入的存储设备的管理IP地址通信正常，运行huawei-csi-node的worker节点与待接入的存储设备的业务IP地址通信正常，iSCSI场景下允许使用ping命令进行连通性校验。 请确保操作系统的语言是英文。 请确保存储池、租户名称等相关存储资源名称是英文。 ","categories":"","description":"","excerpt":"本章节将对安装前的准备工作进行详细说明。\n前提条件 在进行本章节所说明的操作前，请确保如下条件已经具备：\n容器管理平台已部署完成并正常运行， …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%AE%89%E8%A3%85%E5%89%8D%E5%87%86%E5%A4%87/","tags":"","title":"安装前准备"},{"body":"华为CSI支持在华为存储上创建存储资源（LUN/文件系统），并根据用户的设置供给容器使用。具体支持的特性请参考表 华为企业存储支持的特性及约束或者表 华为分布式存储支持的特性及约束。\n创建PVC的方式分为动态卷供应和静态卷供应。\n动态卷供应不需要事先创建PV，华为CSI会根据StorageClass自动在存储设备上创建PV所需要的资源。并且可以在创建PVC时同时创建PV。 静态卷供应需要管理员事先在存储设备上创建好所需要的资源，通过创建PV的方式使用已存在的资源。并且可以在创建PVC时指定关联的PV。 ","categories":"","description":"","excerpt":"华为CSI支持在华为存储上创建存储资源（LUN/文件系统），并根据用户的设置供给容器使用。具体支持的特性请参考表 华为企业存储支持的特性及约 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/pvc%E7%AE%A1%E7%90%86/%E5%88%9B%E5%BB%BApvc/","tags":"","title":"创建PVC"},{"body":"前提条件 待变更PVC关联的存储后端已经组成双活存储后端，若未组成双活存储后端，请参考手动更新存储后端章节配置。\n","categories":"","description":"","excerpt":"前提条件 待变更PVC关联的存储后端已经组成双活存储后端，若未组成双活存储后端，请参考手动更新存储后端章节配置。\n","ref":"/css-docs/docs/%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/pvc%E5%8F%98%E6%9B%B4/%E9%85%8D%E7%BD%AEpvc%E5%8F%98%E6%9B%B4/%E5%88%9B%E5%BB%BApvc%E5%8F%98%E6%9B%B4/","tags":"","title":"创建PVC变更"},{"body":"现象描述 执行完成PVC的创建操作，一段时间后，PVC的状态仍然处于Pending。\n根因分析 原因1：由于没有提前创建指定名称的StorageClass，导致Kubernetes在创建PVC时无法找到指定StorageClass名称。\n原因2：由于存储池能力和StorageClass能力不匹配，导致huawei-csi选择存储池失败。\n原因3：由于存储RESTful接口执行返回具体错误码（例如：50331651），导致huawei-csi在执行创建PVC时失败。\n原因4：由于存储在huawei-csi设定的超时时间内没有返回，huawei-csi向Kubernetes返回超时错误。\n原因5：其他原因。\n解决措施或规避方法 创建PVC时，如果PVC处于Pending状态，需要根据以下不同的原因采取不同的解决措施。\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令，查看PVC的详细信息。\nkubectl describe pvc mypvc 根据PVC详细信息中Events信息，执行相应操作。\n如果由原因1导致PVC处于Pending状态，执行以下步骤。\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Warning ProvisioningFailed 0s (x15 over 3m24s) persistentvolume-controller storageclass.storage.k8s.io \"mysc\" not found 删除PVC。 创建StorageClass，可参考动态卷供应典型场景StorageClass配置示例。 创建新的PVC，可参考动态卷供应PVC参数说明。 如果由原因2导致PVC处于Pending状态，执行以下步骤。\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Provisioning 63s (x3 over 64s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 External provisioner is provisioning volume for claim \"default/mypvc\" Warning ProvisioningFailed 63s (x3 over 64s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 failed to provision volume with StorageClass \"mysc\": rpc error: code = Internal desc = failed to select pool, the capability filter failed, error: failed to select pool, the final filter field: replication, parameters map[allocType:thin replication:True size:1099511627776 volumeType:lun]. please check your storage class 删除PVC。 删除StorageClass。 根据Events信息修改StorageClass.yaml文件。 创建StorageClass，详细请参考动态卷供应典型场景StorageClass配置示例。 创建新的PVC，详情请参考动态卷供应PVC参数说明。 如果由原因3导致PVC处于Pending状态，请联系华为工程师处理。\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Provisioning 63s (x4 over 68s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 External provisioner is provisioning volume for claim \"default/mypvc\" Warning ProvisioningFailed 62s (x4 over 68s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 failed to provision volume with StorageClass \"mysc\": rpc error: code = Internal desc = Create volume map[ALLOCTYPE:1 CAPACITY:20 DESCRIPTION:Created from Kubernetes CSI NAME:pvc-63ebfda5-4cf0-458e-83bd-ecc PARENTID:0] error: 50331651 如果由原因4导致PVC处于Pending状态，执行以下步骤。\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Provisioning 63s (x3 over 52s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 External provisioner is provisioning volume for claim \"default/mypvc\" Warning ProvisioningFailed 63s (x3 over 52s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 failed to provision volume with StorageClass \"mysc\": rpc error: code = Internal desc = context deadline exceeded (Client.Timeout exceeded while awaiting headers) 请先等待10分钟， 参考本章节再次检查PVC详细信息 如果还处于Pending状态，请联系华为工程师处理。 如果由原因5导致PVC处于Pending状态，请联系华为工程师处理。\n","categories":"","description":"","excerpt":"现象描述 执行完成PVC的创建操作，一段时间后，PVC的状态仍然处于Pending。\n根因分析 原因1：由于没有提前创建指定名称 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/pvc%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/%E5%88%9B%E5%BB%BApvc%E6%97%B6-pvc%E7%9A%84%E7%8A%B6%E6%80%81%E4%B8%BApending/","tags":"","title":"创建PVC时， PVC的状态为Pending"},{"body":" 使用oceanctl创建存储后端时，输入的账号和秘钥信息保存在Secret对象中，建议客户容器平台根据供应商或者K8s社区的建议自行对Secret进行加密。K8s社区对Secret加密可参考启用静态加密。 通过json文件创建后端时，旧版本的backend名称中可能存在大写字母或\"_“字符。如果出现这种情况，旧的名称将会被重映射为一个新的名称，映射过程自动发生，不会影响原有功能。例如“ABC_123”将会被映射为“abc-123-fd68e”，具体映射规则如下： 大写字母转换成小写字母。 “_“字符转换成“-”字符。 末尾追加5位Hash码。 当存储后端对接租户时，在存储后端创建完成后，不允许修改租户名称。 创建后端步骤 参考典型场景存储后端配置文件示例章节准备后端配置文件，如backend.yaml，若需创建多个后端，请使用’”—“分隔。\nstorage: \"oceanstor-san\" name: \"backend-1\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.157:8088\" pools: - \"StoragePool001\" parameters: protocol: \"roce\" portals: - \"10.10.30.20\" - \"10.10.30.21\" maxClientThreads: \"30\" --- storage: \"oceanstor-san\" name: \"backend-2\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.158:8088\" pools: - \"StoragePool001\" parameters: protocol: \"roce\" portals: - \"10.10.30.20\" - \"10.10.30.21\" maxClientThreads: \"30\" 执行以下命令创建存储后端。\noceanctl create backend -f /path/to/backend.yaml -i yaml 命令结果如下：\nNUMBER CONFIGURED NAME STORAGE URLS 1 false backend-1 oceanstor-san https://192.168.129.157:8088 2 false backend-2 oceanstor-san https://192.168.129.158:8088 Please enter the backend number to configure (Enter 'exit' to exit): 输入待创建后端序号，并输入账号密码。\nPlease enter the backend number to configure (Enter 'exit' to exit):1 Please enter this backend user name:admin Please enter this backend password: Backend backend-1 is configured NUMBER CONFIGURED NAME STORAGE URLS 1 true backend-1 oceanstor-san https://192.168.129.157:8088 2 false backend-2 oceanstor-san https://192.168.129.158:8088 Please enter the backend number to configure (Enter 'exit' to exit): 检查存储后端创建结果。\noceanctl get backend 命令结果示例如下，后端状态为“Bound“则创建成功：\nNAMESPACE NAME PROTOCOL STORAGETYPE SN STATUS ONLINE URL huawei-csi backend-1 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.157:8088 huawei-csi backend-2 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.158:8088 ","categories":"","description":"","excerpt":" 使用oceanctl创建存储后端时，输入的账号和秘钥信息保存在Secret对象中，建议客户容器平台根据供应商或者K8s社区的建议自行 …","ref":"/css-docs/docs/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%AE%A1%E7%90%86/%E7%AE%A1%E7%90%86%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/%E5%88%9B%E5%BB%BA%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/","tags":"","title":"创建存储后端"},{"body":"前提条件 完成证书制作。以OceanStor Dorado为例，证书制作过程请参考：点此前往。\n创建证书示例 提前准备好证书文件，如cert.crt。\n执行以下命令获取存储后端。\noceanctl get backend 命令结果示例如下。\nNAMESPACE NAME PROTOCOL STORAGETYPE SN STATUS ONLINE URL huawei-csi backend-1 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.157:8088 huawei-csi backend-2 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.158:8088 执行以下命令为指定存储后端创建证书。\noceanctl create cert cert-1 -b backend-1 -f /path/to/cert.crt 检查证书创建结果。\noceanctl get cert -b backend-1 命令结果示例如下。\nNAMESPACE NAME BOUNDBACKEND huawei-csi cert-1 backend-1 ","categories":"","description":"","excerpt":"前提条件 完成证书制作。以OceanStor Dorado为例，证书制作过程请参考：点此前往。\n创建证书示例 提前准备好证书文件， …","ref":"/css-docs/docs/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%AE%A1%E7%90%86/%E6%96%B0%E5%A2%9E%E8%AF%81%E4%B9%A6%E5%88%B0%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E5%8F%AF%E9%80%89/%E5%88%9B%E5%BB%BA%E8%AF%81%E4%B9%A6%E5%88%B0%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/","tags":"","title":"创建证书到存储后端"},{"body":" 在CSI 2.x或3.x 版本中，使用块存储时，与存储建立映射的操作是在huawei-csi-node服务进行的，所以huawei-csi-node服务需要和存储管理网络通信。又由于huawei-csi-node服务是以DaemonSet部署的，在集群中每个节点都会部署一个huawei-csi-node服务，这样部署模型导致了在大规模集群下，每个huawei-csi-node服务都会向存储发起请求，可能导致存储连接数被占满，使得huawei-csi-node不能提供正常服务。 在CSI 4.x版本优化了该部署模型，将与存储建立映射操作迁移至huawei-csi-controller服务，huawei-csi-node服务不再需要和存储管理网络通信，降低了华为CSI依赖的组网复杂度，同时huawei-csi-controller服务以Deployment形式部署，副本数根据客户可靠性要求设置，一般情况下，副本数为1~3。所以极大的减少了华为CSI与存储的连接数量，使得华为CSI服务能够接入大规模集群。 该架构变化可能会导致一个问题：升级后，使用2.x或3.x发放的工作负载，升级CSI至4.x版本之后，如果产生了一次新的挂载流程，并且CO（Container Orchestration system）未调用华为CSI提供的huawei-csi-controller服务，会导致挂载失败。问题请参考创建Pod失败，Events日志显示“publishInfo doesn’t exist”。\n备份存储后端配置 如果您已按照以上须知评估风险后，确认需要从2.x或3.x版本的CSI升级至4.5.0版本，请按照以下操作步骤备份存储后端配置：\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令备份后端信息到configmap.json文件中。OpenShift平台使用oc替换kubectl命令。\nkubectl get cm huawei-csi-configmap -n huawei-csi -o json \u003e configmap.json 升级华为CSI 请按照升级华为CSI中的步骤进行升级。\n配置存储后端 请将备份存储后端配置中备份的后端信息，按照管理存储后端章节的说明配置存储后端，存储后端配置成功后，请务必按照以上须知所述的风险处理方法进行操作，避免Pod在漂移过程中出现问题。\n","categories":"","description":"","excerpt":" 在CSI 2.x或3.x 版本中，使用块存储时，与存储建立映射的操作是在huawei-csi-node服务进行的，所 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E4%BD%BF%E7%94%A8helm%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E5%8D%87%E7%BA%A7%E5%8D%8E%E4%B8%BAcsi/%E4%BB%8E2-x%E6%88%963-x%E5%8D%87%E7%BA%A7%E8%87%B34-x%E7%89%88%E6%9C%AC/","tags":"","title":"从2.x或3.x升级至4.x版本"},{"body":"典型场景的backend配置请参考下列示例，详细的参数配置请参考存储后端配置项说明。\n配置iSCSI协议类型的存储后端 配置FC协议类型的存储后端 配置NVMe over RoCE协议类型的存储后端 配置NVMe over FC协议类型的存储后端 配置NFS协议类型的存储后端 配置SCSI协议类型的存储后端 配置DPC协议类型的存储后端 配置Dtree类型的存储后端 配置双活类型的存储后端 配置iSCSI协议类型的存储后端 如果要使用iSCSI协议类型，请确保在安装华为CSI前，主机上已安装iSCSI客户端，可通过检查主机依赖软件状态章节检查。如未安装iSCSI客户端，请在安装iSCSI客户端之后重启huawei-csi-node服务，重启期间，不能使用华为CSI创建新的资源，或者对已有的PVC做挂载/卸载操作。参考命令如下：\nkubectl delete pods -n huawei-csi -l app=huawei-csi-node 企业存储配置iSCSI协议类型的后端配置文件示例如下：\nstorage: \"oceanstor-san\" name: \"dorado-iscsi-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" - \"https://192.168.129.156:8088\" pools: - \"StoragePool001\" parameters: protocol: \"iscsi\" portals: - \"192.168.128.120\" - \"192.168.128.121\" maxClientThreads: \"30\" 分布式存储配置iSCSI协议类型的后端配置文件示例如下：\nstorage: \"fusionstorage-san\" name: \"pacific-iscsi-125\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.125:8088\" - \"https://192.168.129.126:8088\" pools: - \"StoragePool001\" parameters: protocol: \"iscsi\" portals: - \"192.168.128.122\" - \"192.168.128.123\" maxClientThreads: \"30\" 配置FC协议类型的存储后端 如果要使用FC协议类型，请确保在安装华为CSI前，主机和存储的FC网络已联通，如未FC网络未打通，请在打通FC网络之后重启huawei-csi-node服务，重启期间，不能使用华为CSI创建新的资源，或者对已有的PVC做挂载/卸载操作。参考命令如下：\nkubectl delete pods -n huawei-csi -l app=huawei-csi-node 企业存储配置FC协议类型的后端配置文件示例如下：\nstorage: \"oceanstor-san\" name: \"fc-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" - \"https://192.168.129.156:8088\" pools: - \"StoragePool001\" parameters: protocol: \"fc\" maxClientThreads: \"30\" 配置NVMe over RoCE协议类型的存储后端 如果要使用NVMe over RoCE协议类型，请确保在安装华为CSI前，主机和存储的NVMe over RoCE网络已联通，如未NVMe over RoCE网络未打通，请在打通NVMe over RoCE网络之后重启huawei-csi-node服务，重启期间，不能使用华为CSI创建新的资源，或者对已有的PVC做挂载/卸载操作。参考命令如下：\nkubectl delete pods -n huawei-csi -l app=huawei-csi-node 企业存储配置NVMe over RoCE协议类型的后端配置文件示例如下：\nstorage: \"oceanstor-san\" name: \"roce-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" - \"https://192.168.129.156:8088\" pools: - \"StoragePool001\" parameters: protocol: \"roce\" portals: - \"192.168.128.120\" - \"192.168.128.121\" maxClientThreads: \"30\" 配置NVMe over FC协议类型的存储后端 企业存储配置NVMe over FC协议类型的后端配置文件示例如下：\nstorage: \"oceanstor-san\" name: \"fc-nvme-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" - \"https://192.168.129.156:8088\" pools: - \"StoragePool001\" parameters: protocol: \"fc-nvme\" maxClientThreads: \"30\" 配置NFS协议类型的存储后端 企业存储配置NFS协议类型的后端配置文件示例如下：\nstorage: \"oceanstor-nas\" name: \"nfs-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" - \"https://192.168.129.156:8088\" pools: - \"StoragePool001\" parameters: protocol: \"nfs\" portals: - \"192.168.128.155\" maxClientThreads: \"30\" 分布式存储配置NFS协议类型的后端配置文件示例如下：\nstorage: \"fusionstorage-nas\" name: \"nfs-126\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.125:8088\" - \"https://192.168.129.126:8088\" pools: - \"StoragePool001\" parameters: protocol: \"nfs\" portals: - \"192.168.128.123\" maxClientThreads: \"30\" 配置SCSI协议类型的存储后端 分布式存储配置SCSI协议类型的后端配置文件示例如下：\nstorage: \"fusionstorage-san\" name: \"scsi-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" pools: - \"StoragePool001\" parameters: protocol: \"scsi\" portals: - {\"hostname01\": \"192.168.125.21\",\"hostname02\": \"192.168.125.22\"} maxClientThreads: \"30\" 配置DPC协议类型的存储后端 分布式存储配置DPC协议类型的后端配置文件示例如下：\nstorage: \"fusionstorage-nas\" name: \"dpc-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" - \"https://192.168.129.156:8088\" pools: - \"StoragePool001\" parameters: protocol: \"dpc\" maxClientThreads: \"30\" 配置Dtree类型的存储后端 企业存储配置Dtree类型后端配置文件示例如下：\nstorage: \"oceanstor-dtree\" name: \"nfs-dtree\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" parameters: protocol: \"nfs\" parentname: \"parent-filesystem\" portals: - \"192.168.128.155\" maxClientThreads: \"30\" 配置双活类型的存储后端 配置NAS双活前，需要在两台存储设备之间配置双活关系，包含远端设备、双活域等，仅支持文件系统双活域工作模式为双活AA模式，配置操作请参考对应存储型号的产品文档。 对接NAS双活后端的账号必须为存储租户的租户管理员账号。 除NAS双活后端外，其他后端的管理URL不能配置为在已建立双活关系的租户的逻辑管理端口的URL。 使用双活类型的存储后端时，请勿发放普通文件系统。否则，在逻辑端口漂移场景下，有业务中断的风险。 CSI支持在对接OceanStor或OceanStor Dorado，并在存储侧发放NFS类型的双活卷时。需要配置互为双活的存储后端，具体操作为分别创建两个配置文件，逐一创建后端。\n本示例展示了如何为华为OceanStor或OceanStor Dorado存储配置双活类型的后端。首先创建本端的存储后端配置文件nfs-hypermetro-155.yaml：\nstorage: \"oceanstor-nas\" name: \"nfs-hypermetro-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" - \"https://192.168.129.156:8088\" pools: - \"StoragePool001\" metrovStorePairID: \"f09838237b93c000\" metroBackend: \"nfs-hypermetro-157\" parameters: protocol: \"nfs\" portals: - \"192.168.129.155\" maxClientThreads: \"30\" 创建本端后端完成后，创建远端的存储后端配置文件nfs-hypermetro-157.yaml：\nstorage: \"oceanstor-nas\" name: \"nfs-hypermetro-157\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.157:8088\" - \"https://192.168.129.158:8088\" pools: - \"StoragePool001\" metrovStorePairID: \"f09838237b93c000\" metroBackend: \"nfs-hypermetro-155\" parameters: protocol: \"nfs\" portals: - \"192.168.129.157\" maxClientThreads: \"30\" ","categories":"","description":"","excerpt":"典型场景的backend配置请参考下列示例，详细的参数配置请参考存储后端配置项说明。\n配置iSCSI协议类型的存储后端 配置FC协议类型的存 …","ref":"/css-docs/docs/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%AE%A1%E7%90%86/%E7%AE%A1%E7%90%86%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/%E5%88%9B%E5%BB%BA%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/%E5%85%B8%E5%9E%8B%E5%9C%BA%E6%99%AF%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%A4%BA%E4%BE%8B/","tags":"","title":"典型场景存储后端配置文件示例"},{"body":"动态卷供应（Dynamic Volume Provisioning）允许按需创建存储卷。动态卷供应依赖StorageClass对象。 集群管理员可以根据需要定义多个StorageClass对象，在声明PV或者PVC时，指定满足业务要求的StorageClass。华为CSI在从华为存储设备上申请资源时，会根据StorageClass的预置定义，创建满足业务要求的存储资源。\n为了完成动态卷供应，需要完成如下两步：\n配置StorageClass 配置PVC 配置StorageClass 根据业务需要，参考动态卷供应典型场景StorageClass配置示例和动态卷供应StorageClass参数说明，创建StorageClass配置文件，如本例从的mysc.yaml文件。\n执行命令，使用配置文件创建StorageClass。\nkubectl apply -f mysc.yaml 执行命令，查看已创建的StorageClass信息。\nkubectl get sc mysc 命令结果示例如下：\nNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE mysc csi.huawei.com Delete Immediate true 8s 配置PVC 根据业务需要，参考本节描述和PVC配置文件示例，修改具体参数，生成本次需要创建的PVC配置文件，如本例中mypvc.yaml文件。\nkind: PersistentVolumeClaim apiVersion: v1 metadata: name: mypvc spec: accessModes: - ReadWriteOnce volumeMode: Filesystem storageClassName: mysc resources: requests: storage: 100Gi 执行命令，使用配置文件创建PVC。\nkubectl create -f mypvc.yaml 等待一段时间后，执行以下命令，查看已经创建的PVC信息。\nkubectl get pvc mypvc 命令结果示例如下，如果PVC的状态是“Bound”时，则说明该PVC已经创建成功，后续可以被Pod使用。\nNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE mypvc Bound pvc-840054d3-1d5b-4153-b73f-826f980abf9e 100Gi RWO mysc 12s 完成创建PVC操作后，如果长时间后（如一分钟后）PVC的状态是Pending，请参考创建PVC时， PVC的状态为Pending。 建议每批次最多批量创建/删除100个PVC。 使用PVC 在完成PVC创建后，就可以使用PVC来创建Pod。如下示例是一个简单的使用PVC示例，在该示例中，创建的Pod使用了刚刚创建的 mypvc。\napiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: selector: matchLabels: app: nginx replicas: 2 template: metadata: labels: app: nginx spec: containers: - image: nginx:alpine name: container-0 volumeMounts: - mountPath: /tmp name: pvc-mypvc restartPolicy: Always volumes: - name: pvc-mypvc persistentVolumeClaim: claimName: mypvc # name of PVC ","categories":"","description":"","excerpt":"动态卷供应（Dynamic Volume Provisioning）允许按需创建存储卷。动态卷供应依赖StorageClass对象。 集群管 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/pvc%E7%AE%A1%E7%90%86/%E5%88%9B%E5%BB%BApvc/%E5%8A%A8%E6%80%81%E5%8D%B7%E4%BE%9B%E5%BA%94/","tags":"","title":"动态卷供应"},{"body":"存储类（StorageClass）为管理员提供了描述存储 “类” 的方法。 不同的类型可能会映射到一组不同的能力定义。Kubernetes集群用户可基于StorageClass进行动态卷制备。\n使用SAN存储时可参考示例文件/examples/sc-lun.yaml，使用NAS存储时可参考示例文件/examples/sc-fs.yaml。\n典型场景下StorageClass配置请参考如下示例：\nStorageClass中设置后端和存储池 StorageClass中设置NFS访问方式 StorageClass中设置Dtree类型 StorageClass中设置本地文件系统访问方式 StorageClass中设置DPC访问方式 StorageClass中设置应用类型 StorageClass中设置软配额 StorageClass中设置双活 StorageClass中设置挂载目录权限 StorageClass中设置QoS CCE / CCE Agile平台中配置StorageClass StorageClass中设置后端和存储池 如果在一个Kubernetes集群中配置了多个华为后端，或者一个华为后端提供多个存储池，建议在StorageClass中配置指定的后端和存储池信息，避免华为CSI随机选择后端和存储池，导致卷所在的存储不符合规划。\nSAN存储设置后端和存储池可以参考如下配置示例。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com allowVolumeExpansion: true parameters: backend: \"san-181\" # 存储后端名称 pool: \"pool001\" # 存储池名称 volumeType: lun allocType: thin NAS存储设置后端和存储池可以参考如下配置示例。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com allowVolumeExpansion: true parameters: backend: \"san-181\" # 存储后端名称 pool: \"pool001\" # 存储池名称 volumeType: fs allocType: thin authClient: \"*\" StorageClass中设置NFS访问方式 容器使用NFS文件系统作为存储资源时，可以参考如下配置示例。该示例中，NFS挂载时指定版本为4.1。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: nfs-nas-181 pool: pool001 volumeType: fs allocType: thin authClient: \"192.168.0.10;192.168.0.0/24;myserver1.test\" mountOptions: - nfsvers=4.1 # NFS挂载时指定版本为4.1 StorageClass中设置Dtree类型 容器使用Dtree作为存储资源时，可以参考如下配置示例。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: nfs-dtree volumeType: dtree # 卷类型配置为 dtree allocType: thin authClient: \"*\" mountOptions: - nfsvers=4.1 StorageClass中设置本地文件系统访问方式 容器使用企业存储或者分布式存储的LUN作为存储资源时，且需要格式化文件系统为本地文件系统时，可以参考如下示例。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: iscsi-lun-181 pool: pool001 volumeType: lun allocType: thin fsType: xfs StorageClass中设置DPC访问方式 当容器使用OceanStor Pacific系列存储，且存储支持DPC协议访问时，可以在StorageClass中配置DPC访问的挂载参数。本例中设置挂载时使用“acl”做鉴权参数，使用“cnflush”为设置异步刷盘模式。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: nfs-dpc-101 pool: pool001 volumeType: fs allocType: thin authClient: \"*\" mountOptions: - acl # 鉴权参数 - cnflush # 设置异步刷盘模式 StorageClass中设置应用类型 当容器使用OceanStor Dorado存储的LUN作为存储时，如果使用存储默认的应用类型无法满足某些业务的I/O模型要求（如容器对外提供数据库OLAP服务），可以在StorageClass中配置应用类型，提升存储性能。具体需要使用的应用类型请参考对应存储产品的产品文档说明。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: iscsi-lun-181 pool: pool001 volumeType: lun allocType: thin fsType: xfs applicationType: Oracle_OLAP # 配置应用类型 StorageClass中设置软配额 当容器使用OceanStor Pacific系列存储的文件系统作为存储时，可以在StorageClass中配置软配额信息，可以参考如下配置示例。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: nfs-pacific-101 pool: pool001 volumeType: fs allocType: thin authClient: \"*\" storageQuota: '{\"spaceQuota\": \"softQuota\", \"gracePeriod\": 100}' # 配置软配额 mountOptions: - nfsvers=3 StorageClass中设置QoS 容器使用企业存储或者分布式存储作为存储资源时，可以为容器使用的存储资源设置QoS，从而保证这些容器对存储读写满足一定的服务等级。\n不同型号或版本的存储支持的QoS设置不同，请参考表 支持的QoS配置找到对应存储的配置项。本示例中的后端是OceanStor Dorado存储，其他存储可以参考本例设置。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: iscsi-qos-181 pool: pool001 volumeType: lun allocType: thin fsType: xfs qos: '{\"IOTYPE\": 2, \"MINIOPS\": 1000}' # 配置QoS OceanStor V5 租户用户不支持配置QoS策略。 配置QoS后只能在新建的PVC上生效；对于同名StorageClass已经发放的PVC，不能自动添加QoS StorageClass中设置双活 容器使用NFS双活文件系统作为存储资源时，可以参考如下配置示例。该示例中，使用的后端是支持双活的后端，且配置“hyperMetro”参数为“true”。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: nfs-hypermetro-dorado-181 pool: pool001 volumeType: fs hyperMetro: \"true\" # 发放双活卷 allocType: thin authClient: \"*\" 发放NAS双活卷前，需要在两台存储设备之间配置双活关系，包含远端设备、双活域等，仅支持文件系统双活域工作模式为双活AA模式，配置操作请参考对应存储型号的产品文档。 若存储发生故障，逻辑管理端口可能产生漂移，在漂移状态下删除NAS双活卷后，需手动清理对应的存储资源。 StorageClass中设置挂载目录权限 当需要修改容器内挂载目录的权限时，可以在StorageClass中配置目录权限信息，可以参考如下配置示例。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com allowVolumeExpansion: true parameters: volumeType: fs allocType: thin authClient: \"*\" fsPermission: \"777\" rootSquash: \"no_root_squash\" # 该参数仅支持NAS存储 allSquash: \"no_all_squash\" # 该参数仅支持NAS存储 完成StorageClass配置后，进行如下步骤创建StorageClass。\n执行以下命令，基于该yaml文件创建StorageClass。\nkubectl create -f mysc.yaml 执行以下命令，查看当前已经创建的StorageClass信息。\nkubectl get sc 命令结果示例如下。\nNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE mysc csi.huawei.com Delete Immediate false 34s 创建StorageClass后，就可以使用该StorageClass进行创建PV或者PVC。\n在StorageClass的使用中请注意如下事项：\n针对StorageClass进行的修改将不会在已经创建的PV上生效。您需要删除这些PV，并重新使用修改后的StorageClass创建才能应用修改的参数。 CCE / CCE Agile平台中配置StorageClass 在CCE / CCE Agile平台中创建NAS类型StorageClass，可以参考如下配置示例。其中provisioner保持和values.yaml文件中driverName一致。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc annotations: storageclass.kubernetes.io/storageType: file provisioner: csi.oceanstor.com allowVolumeExpansion: true parameters: volumeType: fs allocType: thin authClient: \"*\" 在CCE / CCE Agile平台中创建Block类型StorageClass，可以参考如下配置示例。其中provisioner保持和values.yaml文件中driverName一致。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc annotations: storageclass.kubernetes.io/storageType: block provisioner: csi.oceanstor.com allowVolumeExpansion: true parameters: volumeType: lun allocType: thin ","categories":"","description":"","excerpt":"存储类（StorageClass）为管理员提供了描述存储 “类” 的方法。 不同的类型可能会映射到一组不同的能力定义。Kubernetes集 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/pvc%E7%AE%A1%E7%90%86/%E5%88%9B%E5%BB%BApvc/%E5%8A%A8%E6%80%81%E5%8D%B7%E4%BE%9B%E5%BA%94/%E5%8A%A8%E6%80%81%E5%8D%B7%E4%BE%9B%E5%BA%94%E5%85%B8%E5%9E%8B%E5%9C%BA%E6%99%AFstorageclass%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/","tags":"","title":"动态卷供应典型场景StorageClass配置示例"},{"body":"本章节介绍如何创建存储后端，当前支持根据配置的后端yaml文件和导出的configmap.json文件两种方式创建后端。\n如果通过新增后端yaml文件创建后端，请参考典型场景存储后端配置文件示例章节配置后端文件。\n如果已存在导出的configmap.json文件，请参考创建存储后端章节创建存储后端。\n","categories":"","description":"","excerpt":"本章节介绍如何创建存储后端，当前支持根据配置的后端yaml文件和导出的configmap.json文件两种方式创建后端。\n如果通过新增后 …","ref":"/css-docs/docs/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%AE%A1%E7%90%86/%E7%AE%A1%E7%90%86%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/","tags":"","title":"管理存储后端"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%8D%8E%E4%B8%BAcsi%E6%9C%8D%E5%8A%A1%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/","tags":"","title":"华为CSI服务相关问题"},{"body":"现象描述 worker节点 A上运行Pod, 并通过CSI挂载外置块设备到该Pod；异常掉电节点worker节点A； Kubernetes平台会在感知到节点故障后，将Pod切换至worker节点B；恢复worker节点A， 节点A上的盘符会从正常变为故障。\n环境配置 Kubernetes版本：1.18及以上\n存储类型：块存储\n根因分析 worker节点A恢复后，Kubernetes会向存储发起解除映射操作，但是不会发起主机侧的移除盘符操作。在Kubernetes解除映射后，worker节点A上就会出现盘符残留。\n解决措施或规避方法 目前的解决方法只能人工介入，手动清理掉主机的残留盘符（或者再次重启主机，利用主机重启过程中扫盘机制，清理掉残留盘符）。具体方法如下：\n排查主机的残留盘符。\n执行命令，判断是否存在多路径状态异常的DM多路径设备：\nmultipath -ll 命令结果示例如下。路径状态为failed faulty running表示异常，对应的DM多路径设备为dm-12，关联的SCSI磁盘为sdi和sdj，在配置多条路径时，会有多个SCSI磁盘。记录这些SCSI磁盘。\nmpathb (3618cf24100f8f457014a764c000001f6) dm-12 HUAWEI ,XSG1 size=100G features='0' hwhandler='0' wp=rw `-+- policy='service-time 0' prio=-1 status=active |- 39:0:0:1 sdi 8:48 failed faulty running `- 38:0:0:1 sdj 8:64 failed faulty running 是 =\u003e 继续执行步骤1.2。 否 =\u003e 不涉及。 执行以下命令，判断残留的DM多路径设备是否可读。\ndd if=/dev/dm-12 of=/dev/null count=1 bs=1M iflag=direct 命令结果示例如下。如果返回结果为：Input/output error，且读取数据为“0 bytes (0 B) copied”，表示该设备不可读。其中，dm-xx 为步骤1.1查到的设备号。\ndd: error reading ‘/dev/dm-12’: Input/output error 0+0 records in 0+0 records out 0 bytes (0 B) copied, 0.0236862 s, 0.0 kB/s 是 =\u003e 记录残留的dm-xx设备以及关联磁盘号（见步骤1.1），执行清理步骤。 命令卡死 =\u003e 继续执行步骤1.3 其他 =\u003e 联系技术支持。 在另一窗口再次登录该节点。\n执行以下命令，查看卡死的进程。\nps -ef | grep dm-12 | grep -w dd 命令结果示例如下。\nroot 21725 9748 0 10:33 pts/10 00:00:00 dd if=/dev/dm-12 of=/dev/null count=1 bs=10M iflag=direct 将该pid杀死。\nkill -9 pid 记录残留的dm-xx设备以及关联磁盘号（见步骤1.1），执行清理步骤。\n清理主机的残留盘符。\n根据步骤1获取的DM多路径设备，执行命令，清理残留的多路径聚合设备信息。\nmultipath -f /dev/dm-12 如果执行报错，请联系技术支持。\n清理残留的SCSI磁盘，根据步骤1获取的残留磁盘的盘符，依次执行命令：\necho 1 \u003e /sys/block/xxxx/device/delete 配置多条多路径时，依次根据盘符清除，本次残留路径为sdi/sdj：\necho 1 \u003e /sys/block/sdi/device/delete echo 1 \u003e /sys/block/sdj/device/delete 如果执行报错，请联系技术支持。\n确认DM多路径设备和SCSI磁盘信息是否已经清理干净。\n依次执行下列命令，查询的多路径和磁盘信息显示，残留的dm-12和SCSI磁盘sdi/sdj均已消失，则证明清理完成。\n查看多路径信息。\nmultipath -ll 命令结果示例如下。残留的dm-12已消失。\nmpathb (3618cf24100f8f457014a764c000001f6) dm-3 HUAWEI ,XSG1 size=100G features='0' hwhandler='0' wp=rw `-+- policy='service-time 0' prio=-1 status=active |- 39:0:0:1 sdd 8:48 active ready running `- 38:0:0:1 sde 8:64 active ready running mpathn (3618cf24100f8f457315a764c000001f6) dm-5 HUAWEI ,XSG1 size=100G features='0' hwhandler='0' wp=rw `-+- policy='service-time 0' prio=-1 status=active |- 39:0:0:2 sdc 8:32 active ready running `- 38:0:0:2 sdb 8:16 active ready running 查看设备信息。\nls -l /sys/block/ 命令结果示例如下。SCSI磁盘sdi/sdj均已消失。\ntotal 0 lrwxrwxrwx 1 root root 0 Aug 11 19:56 dm-0 -\u003e ../devices/virtual/block/dm-0 lrwxrwxrwx 1 root root 0 Aug 11 19:56 dm-1 -\u003e ../devices/virtual/block/dm-1 lrwxrwxrwx 1 root root 0 Aug 11 19:56 dm-2 -\u003e ../devices/virtual/block/dm-2 lrwxrwxrwx 1 root root 0 Aug 11 19:56 dm-3 -\u003e ../devices/virtual/block/dm-3 lrwxrwxrwx 1 root root 0 Aug 11 19:56 sdb -\u003e ../devices/platform/host35/session2/target35:0:0/35:0:0:1/block/sdb lrwxrwxrwx 1 root root 0 Aug 11 19:56 sdc -\u003e ../devices/platform/host34/target34:65535:5692/34:65535:5692:0/block/sdc lrwxrwxrwx 1 root root 0 Aug 11 19:56 sdd -\u003e ../devices/platform/host39/session6/target39:0:0/39:0:0:1/block/sdd lrwxrwxrwx 1 root root 0 Aug 11 19:56 sde -\u003e ../devices/platform/host38/session5/target38:0:0/38:0:0:1/block/sde lrwxrwxrwx 1 root root 0 Aug 11 19:56 sdh -\u003e ../devices/platform/host39/session6/target39:0:0/39:0:0:3/block/sdh lrwxrwxrwx 1 root root 0 Aug 11 19:56 sdi -\u003e ../devices/platform/host38/session5/target38:0:0/38:0:0:3/block/sdi 查看磁盘信息\nls -l /dev/disk/by-id/ 命令结果示例如下。SCSI磁盘sdi/sdj均已消失。\ntotal 0 lrwxrwxrwx 1 root root 10 Aug 11 19:57 dm-name-mpathb -\u003e ../../dm-3 lrwxrwxrwx 1 root root 10 Aug 11 19:58 dm-name-mpathn -\u003e ../../dm-5 lrwxrwxrwx 1 root root 10 Aug 11 19:57 dm-uuid-mpath-3618cf24100f8f457014a764c000001f6 -\u003e ../../dm-3 lrwxrwxrwx 1 root root 10 Aug 11 19:58 dm-uuid-mpath-3618cf24100f8f457315a764c000001f6 -\u003e ../../dm-5 lrwxrwxrwx 1 root root 9 Aug 11 19:57 scsi-3618cf24100f8f457014a764c000001f6 -\u003e ../../sdd lrwxrwxrwx 1 root root 9 Aug 11 19:57 scsi-3618cf24100f8f45712345678000103e8 -\u003e ../../sdi lrwxrwxrwx 1 root root 9 Aug 3 15:17 scsi-3648435a10058805278654321ffffffff -\u003e ../../sdb lrwxrwxrwx 1 root root 9 Aug 2 14:49 scsi-368886030000020aff44cc0d060c987f1 -\u003e ../../sdc lrwxrwxrwx 1 root root 9 Aug 11 19:57 wwn-0x618cf24100f8f457014a764c000001f6 -\u003e ../../sdd lrwxrwxrwx 1 root root 9 Aug 11 19:57 wwn-0x618cf24100f8f45712345678000103e8 -\u003e ../../sdi lrwxrwxrwx 1 root root 9 Aug 3 15:17 wwn-0x648435a10058805278654321ffffffff -\u003e ../../sdb lrwxrwxrwx 1 root root 9 Aug 2 14:49 wwn-0x68886030000020aff44cc0d060c987f1 -\u003e ../../sdc ","categories":"","description":"","excerpt":"现象描述 worker节点 A上运行Pod, 并通过CSI挂载外置块设备到该Pod；异常掉电节点worker节点A； Kubernetes平 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/pod%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/%E9%9B%86%E7%BE%A4%E4%B8%ADworker%E8%8A%82%E7%82%B9%E5%AE%95%E6%9C%BA%E5%B9%B6%E6%81%A2%E5%A4%8D%E5%90%8E-pod%E5%AE%8C%E6%88%90failover-%E4%BD%86%E6%98%AFpod%E6%89%80%E5%9C%A8%E6%BA%90%E4%B8%BB%E6%9C%BA%E5%87%BA%E7%8E%B0%E7%9B%98%E7%AC%A6%E6%AE%8B%E7%95%99/","tags":"","title":"集群中worker节点宕机并恢复后，Pod完成failover，但是Pod所在源主机出现盘符残留"},{"body":"如果您需要在容器环境中使用卷快照以及卷快照关联的特性，请通过检查卷快照依赖组件检查您的环境是否部署了卷快照依赖组件以及卷快照api-versions信息。\n","categories":"","description":"","excerpt":"如果您需要在容器环境中使用卷快照以及卷快照关联的特性，请通过检查卷快照依赖组件检查您的环境是否部署了卷快照依赖组件以及卷快 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/%E5%88%9B%E5%BB%BAvolumesnapshot/%E6%A3%80%E6%9F%A5%E5%8D%B7%E5%BF%AB%E7%85%A7%E4%BE%9D%E8%B5%96%E7%BB%84%E4%BB%B6%E4%BF%A1%E6%81%AF/","tags":"","title":"检查卷快照依赖组件信息"},{"body":"表 1 静态卷供应参数\n参数\n说明\n必选参数\n默认值\n备注\nmetadata.name\n自定义的PV对象名称。\n是\n-\n以Kubernetes v1.22.1为例，支持数字、小写字母、中划线（-）和点（.）的组合，并且必须以字母数字开头和结尾。\nspec.volumeMode\n卷模式。可选参数。 当使用LUN类型的卷时，支持配置以下类型：\nFilesystem：本地文件系统。Block：裸设备。 否\nFilesystem\n该参数在挂载PV时生效，默认为Filesystem。\nFilesystem表示在容器通过一个本地文件系统访问PV，本地文件系统类型为指定StorageClass中的fsType字段指定。Block表示使用裸卷的方式访问访问PV。 spec.storageClassName\nStorageClass对象名称。必选参数。\n是\n-\n此处须设置为空字符串（即输入\"\"）。\nspec.accessModes\n指定卷访问模式。\nRWO（ReadWriteOnce）：卷可以被一个节点以读写方式挂载。 该模式也允许运行在同一节点上的多个 Pod 访问卷。ROX（ReadOnlyMany）：卷可以被多个节点以只读方式挂载。RWX（ReadWriteMany）：卷可以被多个节点以读写方式挂载。RWOP（ReadWriteOncePod）：卷只能被单个 Pod 以读写方式挂载。该特性需要 Kubernetes 1.22 以上版本。 是\nReadWriteOnce\nRWO/ROX/RWOP：所有类型卷均支持，RWOP需Kubernetes 1.22版本以上支持。请参考开启ReadWriteOncePod功能门章节，检查您的Kubernetes集群是否开启该特性。RWX支持情况如下：NAS存储：所有卷均支持。SAN存储：仅volumeMode设置为Block的卷支持。 spec.csi.driver\nCSI驱动名称。\n是\ncsi.huawei.com\n该字段需要指定为安装华为CSI时设置的驱动名称。\nspec.csi.volumeHandle\n存储资源的唯一标志。必选参数。\n格式为：\u003cbackendName\u003e.\u003cvolume-name\u003e\n是\n-\n该参数值由以下两部分构成：\n\u003cbackendName\u003e：该卷所在的后端名称，可使用如下命令获取配置的后端信息：oceanctl get backend\n\u003cvolume-name\u003e：存储上资源（LUN/文件系统）的名称，可通过DeviceManager查看。 spec.csi.fsType\n指定主机文件系统类型。可选参数。支持类型为：\next2ext3ext4xfs 否\n-\n如果不设置，默认为ext4。仅当volumeMode配置为“Filesystem”时生效。\nspec.capacity.storage\n指定卷大小。\n是\n100Gi\n请确保与存储上对应资源的容量保持一致。Kubernetes并不会调用CSI检查此字段值的正确性，所以在PV容量与存储上对应资源的容量不一致也能被成功创建。\nspec.mountOptions.nfsvers\n主机侧NFS挂载选项。支持如下挂载选项：\nnfsvers：挂载NFS时的协议版本。支持配置的参数值为“3”，“4”，“4.0”，“4.1”和“4.2”。\n否\n-\n在主机执行mount命令时-o参数后的可选选项。列表格式。\n指定NFS版本挂载时，当前支持NFS 3/4.0/4.1/4.2协议（需存储设备支持且开启）。当配置参数为nfsvers=4时，因为操作系统配置的不同，实际挂载可能为NFS 4的最高版本协议，如4.2，当需要使用4.0协议时，建议配置nfsvers=4.0。\nspec.mountOptions.acl\nDPC命名空间支持ACL功能。DPC客户端支持POSIX ACL、NFSv4 ACL、NT ACL的鉴权行为。\n否\n-\nacl、aclonlyposix、cnflush、cflush参数描述仅供参考，详细参数说明请参考《OceanStor Pacific系列 产品文档》 \u003e 配置 \u003e 文件服务基础业务配置指南 \u003e 配置基础业务（DPC场景） \u003e 客户端访问DPC共享 \u003e 步骤2。\nspec.mountOptions.aclonlyposix\nDPC命名空间支持POSIX ACL功能，DPC客户端支持POSIX ACL的鉴权行为。\n支持POSIX ACL的协议有：DPC、NFSv3、HDFS。如使用NFSv4 ACL或NT ACL，会导致DPC客户端无法识别该类型的ACL，从而导致该类型的ACL不会生效。\n否\n-\naclonlyposix与acl参数同时使用时，仅acl参数生效，即命名空间支持ACL功能。\nspec.mountOptions.cnflush\n异步刷盘模式，即关闭命名空间下的文件时不会立即刷盘。\n否\n-\n异步刷盘模式，当文件关闭时不会同步将Cache的数据持久化到存储介质中，而是通过Cache异步刷盘的方式将数据写入存储介质，Cache的后台刷盘将在写业务完成后根据刷盘周期定时刷盘。在多客户端场景下，对同一文件进行并行操作，文件Size的更新会受刷盘周期的影响，即当刷盘动作完成后才会更新文件的Size，更新通常会在数秒内完成。同步I/O不受刷盘周期影响。\nspec.mountOptions.cflush\n同步刷盘模式，即关闭命名空间下的文件时立即刷盘。\n否\n-\n默认使用同步刷盘模式。\n","categories":"","description":"","excerpt":"表 1 静态卷供应参数\n参数\n说明\n必选参数\n默认值\n备注\nmetadata.name\n自定义的PV对象名称。\n是\n-\n …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/pvc%E7%AE%A1%E7%90%86/%E5%88%9B%E5%BB%BApvc/%E9%9D%99%E6%80%81%E5%8D%B7%E4%BE%9B%E5%BA%94/%E9%9D%99%E6%80%81%E5%8D%B7%E4%BE%9B%E5%BA%94pv%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E/","tags":"","title":"静态卷供应PV参数说明"},{"body":"当前华为CSI安装时默认关闭PVC变更特性，如需要使用该特性，请按照以下步骤开启。\n","categories":"","description":"","excerpt":"当前华为CSI安装时默认关闭PVC变更特性，如需要使用该特性，请按照以下步骤开启。\n","ref":"/css-docs/docs/%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/pvc%E5%8F%98%E6%9B%B4/%E5%BC%80%E5%90%AFpvc%E5%8F%98%E6%9B%B4%E7%89%B9%E6%80%A7/","tags":"","title":"开启PVC变更特性"},{"body":"纳管卷供应典型场景下StorageClass配置请参考如下示例：\nStorageClass中设置后端和存储池 StorageClass中设置NFS访问方式 StorageClass中设置本地文件系统访问方式 StorageClass中设置DPC访问方式 StorageClass中设置挂载目录权限 StorageClass中设置后端和存储池 如果在一个Kubernetes集群中配置了多个华为后端，或者一个华为后端提供多个存储池，建议在StorageClass中配置指定的后端和存储池信息，避免华为CSI随机选择后端和存储池，导致卷所在的存储不符合规划。\nSAN存储设置后端和存储池可以参考如下配置示例。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com allowVolumeExpansion: true parameters: backend: \"iscsi-san-181\" pool: \"pool001\" volumeType: lun allocType: thin NAS存储设置后端和存储池可以参考如下配置示例。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com allowVolumeExpansion: true parameters: backend: \"iscsi-nas-181\" pool: \"pool001\" volumeType: fs allocType: thin authClient: \"*\" StorageClass中设置NFS访问方式 容器使用NFS文件系统作为存储资源时，可以参考如下配置示例。该示例中，NFS挂载时指定版本为4.1。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: nfs-nas-181 pool: pool001 volumeType: fs allocType: thin mountOptions: - nfsvers=4.1 # NFS挂载时指定版本为4.1 StorageClass中设置本地文件系统访问方式 容器使用企业存储或者分布式存储的LUN作为存储资源时，且需要格式化文件系统为本地文件系统时，可以参考如下示例。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: iscsi-lun-181 pool: pool001 volumeType: lun allocType: thin fsType: xfs StorageClass中设置DPC访问方式 当容器使用OceanStor Pacific系列存储，且存储支持DPC协议访问时，可以在StorageClass中配置DPC访问的挂载参数。本例中设置挂载时使用“acl”做鉴权参数，使用“cnflush”为设置异步刷盘模式。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com parameters: backend: nfs-dpc-101 pool: pool001 volumeType: fs allocType: thin authClient: \"*\" mountOptions: - acl # 鉴权参数 - cnflush # 设置异步刷盘模式 StorageClass中设置挂载目录权限 当需要修改容器内挂载目录的权限时，可以在StorageClass中配置目录权限信息，可以参考如下配置示例。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: mysc provisioner: csi.huawei.com allowVolumeExpansion: true parameters: volumeType: fs allocType: thin authClient: \"*\" fsPermission: \"777\" # 设置目录权限 完成StorageClass配置后，进行如下步骤创建StorageClass。\n执行以下命令，基于该yaml文件创建StorageClass。\nkubectl create -f mysc.yaml 执行以下命令，查看当前已经创建的StorageClass信息。\nkubectl get sc 命令结果示例如下。\nNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE mysc csi.huawei.com Delete Immediate false 34s 创建StorageClass后，就可以使用该StorageClass进行创建PV或者PVC。\n在纳管卷供应场景下，StorageClass的使用中请注意如下事项：\n针对StorageClass进行的修改将不会在已经创建的PV上生效。您需要删除这些PV，并重新使用修改后的StorageClass创建才能应用修改的参数。 ","categories":"","description":"","excerpt":"纳管卷供应典型场景下StorageClass配置请参考如下示例：\nStorageClass中设置后端和存储池 StorageClass中设 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/pvc%E7%AE%A1%E7%90%86/%E5%88%9B%E5%BB%BApvc/%E7%BA%B3%E7%AE%A1%E5%8D%B7%E4%BE%9B%E5%BA%94/%E7%BA%B3%E7%AE%A1%E5%8D%B7%E4%BE%9B%E5%BA%94%E5%85%B8%E5%9E%8B%E5%9C%BA%E6%99%AFstorageclass%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/","tags":"","title":"纳管卷供应典型场景StorageClass配置示例"},{"body":"ALUA（Asymmetric Logical Unit Access，非对称逻辑单元访问），是一种多目标器端口访问模型。在多路径状态下，ALUA标准提供了一种将卷的Active/Passive模型呈现给主机的方式。同时还提供了端口的可访问状态切换接口，可用来实现卷工作控制器切换等。例如，卷在一个控制器故障时，可以将该控制器的端口置为Unavailable，支持ALUA的主机多路径软件收到该状态后，会将I/O切换到另一端控制器。\n","categories":"","description":"","excerpt":"ALUA（Asymmetric Logical Unit Access，非对称逻辑单元访问），是一种多目标器端口访问模型。在多路径状态 …","ref":"/css-docs/docs/%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/%E9%85%8D%E7%BD%AEalua%E7%89%B9%E6%80%A7/","tags":"","title":"配置ALUA特性"},{"body":"华为企业存储针对ALUA的配置请参考产品对应的主机连通性指南文档说明。\n针对不同的操作系统，ALUA配置可能有所不同。进入华为技术支持，在搜索输入框中输入“主机连通性指南”，单击搜索。在搜索结果中，选择对应操作系统的主机连通性指南。结合实际需要根据指南的说明进行ALUA配置。华为CSI将在华为存储上对该主机的启动器应用您设置的配置项。\n已经发放的Pod的节点不会主动更改ALUA信息，需要通过在该节点重新发放Pod才会变更主机ALUA配置。\nOceanStor V5系列和OceanStor Dorado V3系列存储后端的ALUA参数 华为CSI支持的OceanStor V5系列和OceanStor Dorado V3系列存储的ALUA参数见表 华为CSI支持的OceanStor V5系列和OceanStor Dorado V3系列存储的ALUA参数说明。\n表 1 华为CSI支持的OceanStor V5系列和OceanStor Dorado V3系列存储的ALUA参数说明\n参数名\n参数描述\n备注\nHostName\n主机名规则。必填，可使用正则表达式。\n主机名通常使用 cat /etc/hostname 可获取。支持正则表达式方式匹配，如当HostName=“*”时，该条配置对任意主机名的主机生效。可参考《正则表达式》。\n当计算节点的主机名可已匹配多条ALUA配置选项，会根据匹配的精确度进行排序，使用第一条ALUA配置选项。排序规则见ALUA配置项匹配主机名的规则。\nMULTIPATHTYPE\n多路径类型。必填，取值为：\n0：不使用第三方多路径1：使用第三方多路径 --\nFAILOVERMODE\n启动器的切换模式。条件必选，取值为：\n0：旧版本ALUA1：通用ALUA2：不使用ALUA3：特殊模式ALUA 当使用第三方多路径时该参数才需要指定。请参考连通性指南的说明，配置启动器的切换模式。\nSPECIALMODETYPE\n启动器的特殊模式类型。条件必选，取值为：\n0：特殊模式01：特殊模式12：特殊模式23：特殊模式3 当启动器的切换模式为“特殊模式ALUA”时该参数才需要指定。请参考连通性指南的说明，配置启动器的特殊模式类型。\nPATHTYPE\n启动器的路径类型。条件必选，取值为：\n0：优选路径1：非优选路径 当使用第三方多路径时该参数才需要指定。请参考连通性指南的说明，配置启动器的路径类型。\n以OceanStor 18500 V5存储对接Red Hat操作系统为例，主机连通性指南见《华为SAN存储在Red Hat系统下的主机连通性指南》。\n如下ALUA设置示例，是非双活存储场景下，OceanStor 18500 V5存储的Red Hat操作系统的连通性指南的推荐设置。本例中假设Kubernetes集群中计算节点“myhost01”的操作系统是RHEL 5.x，其他计算节点操作系统均为RHEL 7.x。根据推荐，RHEL 5.x的切换模式应该为“不使用ALUA”，RHEL 7.x的切换模式应该为“通用ALUA”。\nstorage: oceanstor-san name: oceanstor-iscsi-155 urls: - https://192.168.129.155:8088 - https://192.168.129.156:8088 pools: - StoragePool001 parameters: protocol: iscsi portals: - 192.168.128.120 - 192.168.128.121 ALUA: ^myhost01$: MULTIPATHTYPE: 1 FAILOVERMODE: 2 PATHTYPE: 0 \"*\": MULTIPATHTYPE: 1 FAILOVERMODE: 1 PATHTYPE: 0 OceanStor和OceanStor Dorado系列存储后端的ALUA参数 华为CSI支持的OceanStor和OceanStor Dorado系列存储的ALUA参数见表 OceanStor和OceanStor Dorado系列存储的ALUA参数说明。\nOceanStor和OceanStor Dorado系列存储在默认情况下启动器主机访问模式即为“均衡模式”，因此不建议对OceanStor和OceanStor Dorado系列存储配置ALUA参数。\n表 2 OceanStor和OceanStor Dorado系列存储的ALUA参数说明\n参数名\n参数描述\n备注\nHostName\n主机名规则。必填，可使用正则表达式。\n主机名通常使用 cat /etc/hostname 可获取。支持正则表达式方式匹配，如当HostName=“*”时，该条配置对任意主机名的主机生效。可参考《正则表达式》。\n当计算节点的主机名可已匹配多条ALUA配置选项，会根据匹配的精确度进行排序，使用第一条ALUA配置选项。排序规则见ALUA配置项匹配主机名的规则。\naccessMode\n主机访问模式。必填，取值为：\n0：均衡模式1：非对称模式 非双活场景下建议使用均衡模式。当前华为CSI未支持SAN双活场景，请谨慎使用非对称模式。\nhyperMetroPathOptimized\n双活场景下，主机在当前阵列的路径是否优选。取值为：\n1：是0：否 当主机访问模式设置为非对称模式时，才需要配置该参数。\n当前华为CSI未支持SAN双活场景，请谨慎使用非对称模式。\n以OceanStor Dorado 18500存储对接Red Hat操作系统为例，主机连通性指南见《OceanStor Dorado \u0026 OceanStor在Red Hat下的主机连通性指南》。\n如下ALUA设置示例，是非双活存储场景下，OceanStor Dorado 18500存储的Red Hat操作系统的连通性指南的推荐设置。\nstorage: \"oceanstor-san\" name: \"dorado-iscsi-155\" urls: - \"https://192.168.129.155:8088\" - \"https://192.168.129.156:8088\" pools: - \"StoragePool001\" parameters: protocol: \"iscsi\" portals: - \"192.168.128.120\" - \"192.168.128.121\" ALUA: \"*\": accessMode: 0 ALUA配置项匹配主机名的规则 如果设置的主机名规则精确匹配的业务节点主机名，则使用该主机名规则对应的ALUA配置项。\n如配置项1中主机名规则为“*”，配置项2中的主机名规则为“^myhost01$”。当计算节点的主机名是“myhost01”时，精确匹配配置项2，华为CSI将使用配置项2中的配置应用到存储侧。\n如果设置的主机名规则无法精确匹配的业务节点主机名，则直接使用正则匹配到的第一条ALUA配置项。\n如配置项1中主机名规则为“myhost0[0-9]”，配置项2中的主机名规则为“myhost0[5-9]”，配置项1的优先级高于配置项2。当计算节点的主机名是“myhost06”时，两个配置项均可以匹配，此时华为CSI将使用配置项1中的配置应用到存储侧。\n","categories":"","description":"","excerpt":"华为企业存储针对ALUA的配置请参考产品对应的主机连通性指南文档说明。\n针对不同的操作系统，ALUA配置可能有所不同。进入华为技术支持，在搜 …","ref":"/css-docs/docs/%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/%E9%85%8D%E7%BD%AEalua%E7%89%B9%E6%80%A7/%E9%80%9A%E8%BF%87helm%E9%85%8D%E7%BD%AEalua%E7%89%B9%E6%80%A7/%E9%85%8D%E7%BD%AE%E5%8D%8E%E4%B8%BA%E4%BC%81%E4%B8%9A%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%9A%84alua%E5%8F%82%E6%95%B0/","tags":"","title":"配置华为企业存储后端的ALUA参数"},{"body":"现象描述 启动huawei-csi-node时，无法启动huawei-csi-node服务， 使用kubectl describe daemonset huawei-csi-node -n huawei-csi命令查看，提示错误为：“/var/lib/iscsi is not a directory”。\n根因分析 huawei-csi-node中容器内部无/var/lib/iscsi目录。\n解决措施或规避方法 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n进入Helm工程的目录下，如果无法找到之前的Helm工程，则将组件包中的helm目录拷贝到master节点的任意目录下，组件包路径请参考表 软件包组件描述。\n进入下一级目录templates,找到huawei-csi-node.yaml文件。\ncd /templates 执行以下命令，将huawei-csi-node.yaml \u003e volumes \u003e iscsi-dir \u003e hostPath中“path“设置为“/var/lib/iscsi“ ，然后保存并退出文件。\nvi huawei-csi-node.yaml 执行以下命令升级Helm chart。升级命令将更新Deployment、DaemonSet和RBAC资源。其中，helm-huawei-csi为自定义的chart名称，huawei-csi为自定义的命名空间。\nhelm upgrade helm-huawei-csi ./ -n huawei-csi values.yaml 命令结果示例如下。\nRelease \"helm-huawei-csi\" has been upgraded. Happy Helming! NAME: helm-huawei-csi LAST DEPLOYED: Thu Jun 9 07:58:15 2022 NAMESPACE: huawei-csi STATUS: deployed REVISION: 2 TEST SUITE: None ","categories":"","description":"","excerpt":"现象描述 启动huawei-csi-node时，无法启动huawei-csi-node服务， 使用kubectl describe …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%8D%8E%E4%B8%BAcsi%E6%9C%8D%E5%8A%A1%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/%E5%90%AF%E5%8A%A8huawei-csi-node%E5%A4%B1%E8%B4%A5-%E6%8F%90%E7%A4%BA%E9%94%99%E8%AF%AF%E4%B8%BA-var-lib-iscsi-is-not-a-directory/","tags":"","title":"启动huawei-csi-node失败，提示错误为：“/var/lib/iscsi is not a directory”"},{"body":"读者对象 本文档主要适用于以下读者对象：\n技术支持工程师 运维工程师 具备存储和Kubernetes基础知识的工程师 符号约定 在本文中可能出现下列标志，它们所代表的含义如下。\n符号\n说明\n表示如不避免则将会导致死亡或严重伤害的具有高等级风险的危害。\n表示如不避免则可能导致死亡或严重伤害的具有中等级风险的危害。\n表示如不避免则可能导致轻微或中度伤害的具有低等级风险的危害。\n用于传递设备或环境安全警示信息。如不避免则可能会导致设备损坏、数据丢失、设备性能降低或其它不可预知的结果。\n“须知”不涉及人身伤害。\n对正文中重点信息的补充说明。\n“说明”不是安全警示信息，不涉及人身、设备及环境伤害信息。\n","categories":"","description":"","excerpt":"读者对象 本文档主要适用于以下读者对象：\n技术支持工程师 运维工程师 具备存储和Kubernetes基础知识的工程师 符号约定 在本文中可能 …","ref":"/css-docs/docs/%E5%89%8D%E8%A8%80/","tags":"","title":"前言"},{"body":"本章节指导用户如何查看CSI版本信息。\n操作步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令，查看huawei-csi-node所在节点信息。\nkubectl get pod -A -owide | grep huawei-csi-node 命令结果示例如下：\nNAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES huawei-csi huawei-csi-node-87mss 3/3 Running 0 6m41s 192.168.129.155 node-1 \u003cnone\u003e \u003cnone\u003e huawei-csi huawei-csi-node-xp8cc 3/3 Running 0 6m41s 192.168.129.156 node-2 \u003cnone\u003e \u003cnone 使用远程访问工具（以PuTTY为例），通过节点IP地址，登录任意huawei-csi-node所在节点。\n执行以下命令，查看CSI版本信息。\ncat /var/lib/kubelet/plugins/csi.huawei.com/version 命令显示版本信息如下。\n4.5.0 ","categories":"","description":"","excerpt":"本章节指导用户如何查看CSI版本信息。\n操作步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任 …","ref":"/css-docs/docs/%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96csi%E7%89%88%E6%9C%AC%E4%BF%A1%E6%81%AF/","tags":"","title":"如何获取CSI版本信息"},{"body":"本章节介绍如何升级华为CSI。\n升级/回退过程中，已经存在的PVC/快照/Pod等资源会正常运行，不会影响您的业务访问。\n部分2.x版本CSI已经下架，若升级失败，可能无法回退到已下架版本的CSI。 从2.x或3.x版本或4.x版本升级至4.5.0版本，可能存在旧版本已发放Pod重新挂载时失败的问题，具体请参考从2.x或3.x升级至4.x版本 在升级/回退过程中，不能使用华为CSI创建新的资源，或者对已有的PVC做挂载/卸载操作。 在升级/回退过程中，请勿卸载Snapshot依赖组件服务。 ","categories":"","description":"","excerpt":"本章节介绍如何升级华为CSI。\n升级/回退过程中，已经存在的PVC/快照/Pod等资源会正常运行，不会影响您的业务访问。\n部分2.x版 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E4%BD%BF%E7%94%A8helm%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E5%8D%87%E7%BA%A7%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"升级华为CSI"},{"body":"本章节介绍如何手动升级华为CSI。\n升级/回退过程中，已经存在的PVC/快照/Pod等资源会正常运行，不会影响您的业务访问。\n部分2.x版本CSI已经下架，若升级失败，可能无法回退到已下架版本的CSI。 在升级/回退过程中，不能使用华为CSI创建新的资源，或者对已有的PVC做挂载/卸载操作。 在升级/回退过程中，请勿卸载Snapshot依赖组件服务。 2.x和3.x版本的CSI升级至4.5.0版本 如果您从2.x和3.x版本的CSI升级至4.5.0版本，请按照以下操作步骤升级：\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行命令备份后端信息到configmap.json文件中。OpenShift平台使用oc替换kubectl命令。\nkubectl get cm huawei-csi-configmap -n huawei-csi -o json \u003e configmap.json 参考手动卸载华为CSI卸载CSI。\n参考手动安装华为CSI安装当前版本的CSI。\n将2中备份的后端信息，按照管理存储后端章节的说明安装。\n从4.x版本的CSI升级至4.5.0版本。 如果您从4.x版本的CSI升级至4.5.0版本，请按照以下操作步骤升级：\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。 参考手动卸载华为CSI卸载CSI。 参考手动安装华为CSI安装当前版本的CSI。 ","categories":"","description":"","excerpt":"本章节介绍如何手动升级华为CSI。\n升级/回退过程中，已经存在的PVC/快照/Pod等资源会正常运行，不会影响您的业务访问。\n部分2.x版 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E6%89%8B%E5%8A%A8%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80/%E5%8D%87%E7%BA%A7%E5%8D%8E%E4%B8%BAcsi-0/","tags":"","title":"升级华为CSI"},{"body":"Helm安装说明 本章节介绍如何使用Helm 3安装部署华为CSI。\n华为CSI的安装支持root用户和非root用户。使用非root用户安装华为CSI时，需要保证当前用户能够访问Kubernetes集群的API Server，配置非root用户访问Kubernetes集群请参考配置非root用户访问Kubernetes集群。 华为CSI必须在root用户权限下运行。 Helm是Kubernetes生态系统中的一个软件包管理工具，类似Ubuntu的APT、CentOS的YUM、或Python的pip一样，专门负责管理Kubernetes的应用资源。\n使用Helm可以对Kubernetes应用进行统一打包、分发、安装、升级以及回退等操作。\nHelm的获取、安装请参考：https://helm.sh/docs/intro/install/ Helm与Kubernetes版本对应关系请参考：https://helm.sh/docs/topics/version_skew/ Helm在安装huawei-csi-controller时，将在指定命名空间的Deployment类型的工作负载中部署以下组件：\nhuawei-csi-driver：华为CSI驱动。 storage-backend-controller：华为后端管理控制器，管理storageBackendClaim资源。 storage-backend-sidecar：用于管理storageBackendContent资源。 Kubernetes External Provisioner：用于提供/删除卷。 Kubernetes External Attacher：用于挂载/解挂载卷。 Kubernetes External Resizer：用于扩容卷。 Kubernetes External liveness-probe： 用来判断Pod健康状态。 （可选）huawei-csi-extender：华为CSI扩展。 （可选）Kubernetes External Snapshotter：提供快照支持（作为CRD安装）。 （可选）Kubernetes External Snapshot Controller ：用于卷快照控制。 Helm在安装huawei-csi-node时，将在指定命名空间的DaemonSet类型的工作负载中部署以下组件：\nhuawei-csi-driver：华为CSI驱动。 Kubernetes Node Registrar：处理驱动程序注册。 liveness-probe: 用来判断Pod健康状态。 ","categories":"","description":"","excerpt":"Helm安装说明 本章节介绍如何使用Helm 3安装部署华为CSI。\n华为CSI的安装支持root用户和非root用户。使用非root用户安 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%AE%89%E8%A3%85%E5%8D%8E%E4%B8%BAcsi/%E4%BD%BF%E7%94%A8helm%E5%AE%89%E8%A3%85%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"使用Helm安装华为CSI"},{"body":"前提条件 已使用Helm安装华为CSI。 要求华为CSI v4.5.0及以上版本。 操作步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令检查PVC变更特性是否开启。\n其中helm-huawei-csi为安装时指定的Helm Chart名称，huawei-csi为安装时指定的Helm Chart命名空间。组件包路径请参考表 软件包组件描述。\nhelm get values helm-huawei-csi -n huawei-csi -a | grep volumeModify -A 1 命令结果示例如下：\n若回显内容为“enabled: true”，则表示特性开启，可跳过后续步骤。 若回显内容为“enabled: false”，请按照后续步骤开启PVC变更特性。 volumeModify: enabled: false 进入/helm/esdk目录，执行命令，配置卷变更CRD。\n# kubectl apply -f ./crds/volume-modify/ customresourcedefinition.apiextensions.k8s.io/volumemodifyclaims.xuanwu.huawei.io configured customresourcedefinition.apiextensions.k8s.io/volumemodifycontents.xuanwu.huawei.io configured 如回显中存在“Warning: resource customresourcedefinitions/volumemodifycontents.xuanwu.huawei.io is missing the kubectl.kubernetes.io/last-applied-configuration…”提示，可忽略该提示。该提示出现原因是由于Helm安装应用时使用的是kubectl create命令而不是kubectl apply命令。\n执行以下命令，获取原有服务配置文件。\nhelm get values helm-huawei-csi -n huawei-csi -a \u003e ./update-values.yaml 执行vi update-values.yaml命令打开4中获取的文件，修改以下配置。修改完成后，按Esc，并输入**:wq!**，保存修改。\ncsiExtender: volumeModify: enabled: true 执行以下命令更新华为CSI服务。\nhelm upgrade helm-huawei-csi ./ -n huawei-csi -f ./update-values.yaml 执行命令检查服务是否启动。\nkubectl get pod -n huawei-csi 命令结果示例如下，其中huawei-csi为华为CSI部署命名空间。\nNAME READY STATUS RESTARTS AGE huawei-csi-controller-6dfcc4b79f-9vjtq 10/10 Running 0 24m huawei-csi-node-tqs87 3/3 Running 0 20m ","categories":"","description":"","excerpt":"前提条件 已使用Helm安装华为CSI。 要求华为CSI v4.5.0及以上版本。 操作步骤 使用远程访问工具（以PuTTY为例），通过管 …","ref":"/css-docs/docs/%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/pvc%E5%8F%98%E6%9B%B4/%E5%BC%80%E5%90%AFpvc%E5%8F%98%E6%9B%B4%E7%89%B9%E6%80%A7/%E4%BD%BF%E7%94%A8helm%E5%BC%80%E5%90%AFpvc%E5%8F%98%E6%9B%B4%E7%89%B9%E6%80%A7/","tags":"","title":"使用Helm开启PVC变更特性"},{"body":"如果您从2.x版本升级至4.5.0版本，请参考旧版本用户指南卸载CSI，然后参考使用Helm安装华为CSI章节安装华为CSI。\n如果您从2.x或3.x版本升级至4.5.0版本，请参考从2.x或3.x升级至4.x版本章节升级华为CSI。\n如果您从4.x版本升级至4.5.0版本，请参考Kubernetes、OpenShift、Tanzu升级华为CSI章节升级华为CSI。\n","categories":"","description":"","excerpt":"如果您从2.x版本升级至4.5.0版本，请参考旧版本用户指南卸载CSI，然后参考使用Helm安装华为CSI章节安装华为CSI。\n如果您 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E4%BD%BF%E7%94%A8helm%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"使用Helm升级/回退华为CSI"},{"body":"现象描述 当webhook的配置发生改变后，例如修改webhookPort参数值后，此时使用oceanctl工具对后端进行管理时调用webhook报错，如下：\n根因分析 当webhook的配置发生改变后，导致validatingwebhookconfiguration资源失效。\n解决措施或规避方法 执行以下命令，删除validatingwebhookconfiguration资源。\nkubectl delete validatingwebhookconfiguration storage-backend-controller.xuanwu.huawei.io 执行以下命令，重启CSI Controller，请通过“–replicas=*”恢复CSI Controller的副本数，下例为恢复至1个，请根据实际情况修改。\nkubectl scale deployment huawei-csi-controller -n huawei-csi --replicas=0 kubectl scale deployment huawei-csi-controller -n huawei-csi --replicas=1 执行以下命令，检查CSI Controller是否成功拉起。\nkubectl get pod -n huawei-csi 命令结果示例如下。Pod状态为“Running“说明Controller成功拉起。\nNAME READY STATUS RESTARTS AGE huawei-csi-controller-58d5b6b978-s2dsq 9/9 Running 0 19s huawei-csi-node-dt6nd 3/3 Running 0 77m ","categories":"","description":"","excerpt":"现象描述 当webhook的配置发生改变后，例如修改webhookPort参数值后，此时使用oceanctl工具对后端进行管理时调 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/%E4%BD%BF%E7%94%A8oceanctl%E5%B7%A5%E5%85%B7%E7%AE%A1%E7%90%86%E5%90%8E%E7%AB%AF%E6%97%B6%E8%B0%83%E7%94%A8webhook%E5%A4%B1%E8%B4%A5/","tags":"","title":"使用oceanctl工具管理后端时调用webhook失败"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/docs/%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/%E9%85%8D%E7%BD%AEalua%E7%89%B9%E6%80%A7/%E9%80%9A%E8%BF%87helm%E9%85%8D%E7%BD%AEalua%E7%89%B9%E6%80%A7/","tags":"","title":"通过Helm配置ALUA特性"},{"body":"操作步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n进入Helm工程的目录下，如果无法找到之前的Helm工程，则将组件包中的helm目录拷贝到master节点的任意目录下，组件包路径请参考表 软件包组件描述。\n进入后端服务配置目录/examples/backend/下，备份backend.yaml文件\ncp backend.yaml backend.yaml.bak 执行vi backend.yaml命令打开文件，按需求配置拓扑感知，示例如下所示。修改完成后，按Esc，并输入 :wq!，保存修改。\nstorage: \"oceanstor-san\" name: \"dorado-iscsi-155\" namespace: \"huawei-csi\" urls: - \"https://192.168.129.155:8088\" pools: - \"StoragePool001\" parameters: protocol: \"iscsi\" portals: - \"10.10.30.20\" - \"10.10.30.21\" supportedTopologies: - { \"topology.kubernetes.io/region\": \"China-west\", \"topology.kubernetes.io/zone\": \"ChengDu\" } - { \"topology.kubernetes.io/region\": \"China-south\",\"topology.kubernetes.io/zone\": \"ShenZhen\" } maxClientThreads: \"30\" 执行以下命令删除待修改存储后端，其中“dorado-iscsi-155”为存储后端名称。\noceanctl delete backend dorado-iscsi-155 -n huawei-csi 执行以下命令创建存储后端。\noceanctl create backend -f ../examples/backend/backend.yaml -i yaml 根据命令提示输入存储用户名和密码。\nPlease enter this backend user name:admin Please enter this backend password: 执行vi StorageClass.yaml命令，修改yaml文件。按I或Insert进入编辑状态，在yaml文件下增加相关参数，详细参数说明请参见表 参数说明。修改完成后，按Esc，并输入 :wq! ，保存修改。\n在StorageClass.yaml文件中添加以下配置项。拓扑\n示例1： 在StorageClass中配置zone和region信息\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: example-storageclass provisioner: csi.huawei.com parameters: volumeType: lun allocType: thin volumeBindingMode: WaitForFirstConsumer allowedTopologies: - matchLabelExpressions: - key: topology.kubernetes.io/zone values: - ChengDu - key: topology.kubernetes.io/region values: - China-west 示例2： 在StorageClass中配置协议信息\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: protocol-example-storageclass provisioner: csi.huawei.com parameters: volumeType: lun allocType: thin volumeBindingMode: WaitForFirstConsumer allowedTopologies: - matchLabelExpressions: - key: topology.kubernetes.io/protocol.iscsi values: - csi.huawei.com 表 1 参数说明\n参数名\n参数描述\n备注\nvolumeBindingMode\nPersistentVolume绑定方式，用于控制何时进行PersistentVolume动态资源调配和绑定。\n可配置“WaitForFirstConsumer”或“Immediate”\n“WaitForFirstConsumer”：表示延迟PersistentVolume的绑定和调配，直到创建使用PVC的Pod。\n“Immediate”：表示创建PVC后，立即发生PersistentVolume绑定和调配。\nallowedTopologies.matchLabelExpressions\n拓扑信息标签，用于过滤CSI后端和Kubernetes节点。如果匹配失败，会导致PVC或Pod无法创建。\n配置时需要同时按照固定格式配置“key”和“value”.\n“key”：可支持配置“topology.kubernetes.io/zone”，“topology.kubernetes.io/region”，\ntopology.kubernetes.io/protocol.\u003cprotocol\u003e， 其中\u003cprotocol\u003e为协议类型， 例如：iscsi, fc, nfs等。\n“value”：\n“key”如果是“topology.kubernetes.io/zone”，“topology.kubernetes.io/region”，“value”值需要和前提条件中设置的拓扑标签保持一致。\n“key”如果是topology.kubernetes.io/protocol.\u003cprotocol\u003e， “value”值固定为“csi.huawei.com”\n执行以下命令，基于该yaml文件创建StorageClass。\nkubectl create -f StorgeClass.yaml 使用该StorageClass创建具有拓扑能力的PVC，详细操作请参考动态卷供应PVC参数说明。\n","categories":"","description":"","excerpt":"操作步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n进入Helm工程的目 …","ref":"/css-docs/docs/%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/%E9%85%8D%E7%BD%AE%E5%AD%98%E5%82%A8%E6%8B%93%E6%89%91%E6%84%9F%E7%9F%A5/%E9%80%9A%E8%BF%87helm%E9%85%8D%E7%BD%AE%E5%AD%98%E5%82%A8%E6%8B%93%E6%89%91%E6%84%9F%E7%9F%A5/","tags":"","title":"通过Helm配置存储拓扑感知"},{"body":"现象描述 创建huawei-csi-controller和huawei-csi-node时，仅Deployment和DaemonSet资源创建成功，controller和node的Pod未创建。\n根因分析 创建资源使用的service account没有PSP策略的“use”权限。\n解决措施或规避方法 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行vi psp-use.yaml 命令， 创建psp-use.yaml文件。\nvi psp-use.yaml 配置psp-use.yaml文件。\napiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: huawei-csi-psp-role rules: - apiGroups: ['policy'] resources: ['podsecuritypolicies'] verbs: ['use'] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: huawei-csi-psp-role-cfg roleRef: kind: ClusterRole name: huawei-csi-psp-role apiGroup: rbac.authorization.k8s.io subjects: - kind: Group apiGroup: rbac.authorization.k8s.io name: system:serviceaccounts:huawei-csi - kind: Group apiGroup: rbac.authorization.k8s.io name: system:serviceaccounts:default 执行以下命令，创建PSP权限。\nkubectl create -f psp-use.yaml ","categories":"","description":"","excerpt":"现象描述 创建huawei-csi-controller和huawei-csi-node时，仅Deployment和DaemonSet资源创 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%AF%B9%E6%8E%A5tanzu-kubernetes%E9%9B%86%E7%BE%A4%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/%E6%9C%AA%E5%88%9B%E5%BB%BApsp%E6%9D%83%E9%99%90%E5%AF%BC%E8%87%B4pod%E6%97%A0%E6%B3%95%E5%88%9B%E5%BB%BA/","tags":"","title":"未创建PSP权限导致Pod无法创建"},{"body":"本章节详细说明了下载方法以及软件包组件结构。\n打开浏览器，访问仓库地址：https://github.com/Huawei/eSDK_K8S_Plugin/releases。\n根据CPU架构，下载对应的4.5.0版本软件包。\n软件包命名规范：插件名称（eSDK_Huawei_Storage_Kubernetes_CSI_Plugin）+版本号+CPU架构\n将下载的软件包解压。软件包组件结构如下表所示。\n表 1 软件包组件描述\n组件\n组件描述\nimage/huawei-csi-v4.5.0-arch.tar\nhuawei-csi-driver镜像，\"arch\"为X86或ARM。\nimage/storage-backend-controller-v4.5.0-arch.tar\n后端管理控制器镜像，\"arch\"为X86或ARM。\nimage/storage-backend-sidecar-v4.5.0-arch.tar\n后端管理sidecar镜像，\"arch\"为X86或ARM。\nimage/huawei-csi-extender-v4.5.0-arch.tar\nhuawei-csi-extender镜像，\"arch\"为X86或ARM。\nbin/\n华为提供的镜像使用的二进制文件。\nbin/oceanctl\n华为提供的命令行工具，可用于管理存储后端。\nhelm/\nHelm工程，用于部署华为CSI。\nmanual/\n用于手动安装部署华为CSI。\nexamples/\nCSI使用过程中的yaml示例文件。\nexamples/backend\n创建存储后端的yaml示例文件。\n","categories":"","description":"","excerpt":"本章节详细说明了下载方法以及软件包组件结构。\n打开浏览器，访问仓库地 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%AE%89%E8%A3%85%E5%89%8D%E5%87%86%E5%A4%87/%E4%B8%8B%E8%BD%BD%E5%8D%8E%E4%B8%BAcsi%E8%BD%AF%E4%BB%B6%E5%8C%85/","tags":"","title":"下载华为CSI软件包"},{"body":"PVC变更文件说明 PVC变更文件样例模板为/examples/volumemodifyclaim.yaml，具体配置项如下表所示：\n表 1 参数说明\n参数\n描述\n必选参数\n默认值\n备注\napiVersion\nAPI组，string类型\n是\nxuanwu.huawei.io/v1\n固定填写xuanwu.huawei.io/v1\nkind\n资源的类型，string类型\n是\nVolumeModifyClaim\n固定填写VolumeModifyClaim\nmetadata.name\n集群资源对象的名称，string类型\n是\n-\n名称必须满足DNS 子域名的命名规则，支持数字、小写字母、中划线（-）和点（.）的组合，并且必须以小写字母数字字符开头和结尾，最大长度不超过63个字符\nspec.source.kind\n数据源类型，string类型\n是\nStorageClass\n仅支持设置为：StorageClass\nspec.source.name\n数据源名称，string类型\n是\n-\n仅支持设置StorageClass名称\nspec.parameters.hyperMetro\n是否将普通卷变更为双活卷。当前取值仅支持\"true\"。\n是\n-\n仅支持主站点普通存储卷变更为双活存储卷。\nspec.parameters.metroPairSyncSpeed\n双活Pair同步速率。支持配置为1~4。\n可选值：\n1：低2：中3：高4：最高 否\n-\n当且仅当spec.parameters.hyperMetro为\"true\"时生效。\n注意：\n未配置该参数时，双活Pair存储速率由存储决定。最高速率同步时可能导致主机时延增大。 spec.source.kind和spec.source.name用于指定卷变更范围，例如配置为StorageClass和对应名称时，将会变更使用目标StorageClass发放的所有的处于Bound状态的PVC。 当所有关联的PVC完成变更后，华为CSI会替换原有的StorageClass，并增加VolumeModifyClaim的spec.parameters参数，使得PVC满足StorageClass定义。 典型场景配置请参考如下示例：\n变更普通卷为双活卷 配置变更普通卷为双活卷示例如下：\napiVersion: xuanwu.huawei.io/v1 kind: VolumeModifyClaim metadata: name: myvmc spec: source: kind: StorageClass name: mysc parameters: hyperMetro: \"true\" ","categories":"","description":"","excerpt":"PVC变更文件说明 PVC变更文件样例模板为/examples/volumemodifyclaim.yaml，具体配置项如下表所示：\n表 1 …","ref":"/css-docs/docs/%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/pvc%E5%8F%98%E6%9B%B4/%E9%85%8D%E7%BD%AEpvc%E5%8F%98%E6%9B%B4/%E5%88%9B%E5%BB%BApvc%E5%8F%98%E6%9B%B4/%E5%87%86%E5%A4%87pvc%E5%8F%98%E6%9B%B4%E6%96%87%E4%BB%B6/","tags":"","title":"准备PVC变更文件"},{"body":"This section describes how to create a certificate for a storage backend. If certificate verification is required for logging in to the storage, you can add a certificate by referring to this section. Currently, you can create a certificate for a storage backend based on the specified .crt or .pem file.\nBefore creating a certificate for a storage backend, import the prepared certificate to the storage array.\n","categories":"","description":"","excerpt":"This section describes how to create a certificate for a storage …","ref":"/css-docs/en/docs/storage-backend-management/optional-adding-a-certificate-to-a-storage-backend/","tags":"","title":"(Optional) Adding a Certificate to a Storage Backend"},{"body":"Symptom A user fails to create a storage backend using the oceanctl tool, and “failed to call webhook: xxx :context deadline exceeded; error: exist status 1” is displayed on the console.\nRoot Cause Analysis When a storage backend is created, the webhook service provided by CSI is invoked to verify the connectivity with the storage management network and the storage account and password. The possible causes are as follows:\nHuawei CSI fails to verify the connectivity of the storage management network. The communication between kube-apiserver and CSI webhook is abnormal. Huawei CSI Fails to Verify the Connectivity of the Storage Management Network Perform the following steps to check whether Huawei CSI fails to verify the connectivity of the storage management network.\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to obtain CSI service information. huawei-csi indicates the namespace where the CSI services are deployed.\nkubectl get pod -n huawei-csi -owide The following is an example of the command output.\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES huawei-csi-controller-xxx 9/9 Running 0 19h host-ip1 host-1 \u003cnone\u003e \u003cnone\u003e huawei-csi-node-mnqbz 3/3 Running 0 19h host-ip1 host-1 \u003cnone\u003e \u003cnone\u003e Log in to the node where huawei-csi-controller resides, for example, host-1 in 2.\nGo to the /var/log/huawei directory.\n# cd /var/log/huawei View the storage-backend-controller log. The following uses the storage connection timeout as an example.\ntail -n 1000 storage-backend-controller The following is a log example.\n2024-01-01 06:30:44.280661 1 [INFO]: Try to login https://192.168.129.155:8088/deviceManager/rest 2024-01-01 06:31:44.281626 1 [ERROR]: Send request method: POST, Url: https://192.168.129.155:8088/deviceManager/rest/xx/sessions, error: Post \"https://192.168.129.155:8088/deviceManager/rest/xx/sessions\": context deadline exceeded (Client.Timeout exceeded while awaiting headers) 2024-01-01 06:31:44.281793 1 [WARNING]: Login https://192.168.129.155:8088/deviceManager/rest error due to connection failure, gonna try another Url 2024-01-01 06:31:44.291668 1 [INFO]: Finished validateCreate huawei-csi/backend-test. 2024-01-01 06:31:44.291799 1 [ERROR]: Failed to validate StorageBackendClaim, error: unconnected If the log contains information about login timeout, login failure, or long request duration, check the connectivity between the host machine and the storage or the network status.\nIf no request is recorded in the log, the communication between kube-apiserver and CSI webhook is abnormal.\nAbnormal Communication Between kube-apiserver and CSI Webhook Contact the Kubernetes platform administrator to check the network between kube-apiserver and CSI webhook. For example, if kube-apiserver has an HTTPS proxy, the CSI webhook service may fail to be accessed.\nIn the temporary workaround, the webhook resource will be deleted. This resource is used to check whether the entered account information is correct and whether the connection to the storage can be set up when a storage backend is created. Therefore, deleting this resource affects only the verification during backend creation and does not affect other functions. Pay attention to the following:\nEnsure that the host machine where the huawei-csi-controller service is located can properly communicate with the storage. Ensure that the entered account and password are correct. Run the following command to view CSI webhook information.\nkubectl get validatingwebhookconfiguration storage-backend-controller.xuanwu.huawei.io The following is an example of the command output.\nNAME WEBHOOKS AGE storage-backend-controller.xuanwu.huawei.io 1 4d22h Contact the Kubernetes platform administrator to check whether the communication between kube-apiserver and CSI webhook is abnormal.\nPerform the following temporary workaround: Run the following command to delete the webhook.\nkubectl delete validatingwebhookconfiguration storage-backend-controller.xuanwu.huawei.io Create a storage backend. For details, see Managing Storage Backends.\nIf the communication between kube-apiserver and CSI webhook is restored, you need to reconstruct the webhook. In this case, run the following command to restart CSI Controller and restore the number of CSI Controller copies by specifying –replicas=*. In the following example, the number is restored to 1. Change it based on actual requirements.\nChange the number of copies to 0 first.\nkubectl scale deployment huawei-csi-controller -n huawei-csi --replicas=0 Then restore the number of copies to the original number.\nkubectl scale deployment huawei-csi-controller -n huawei-csi --replicas=1 ","categories":"","description":"","excerpt":"Symptom A user fails to create a storage backend using the oceanctl …","ref":"/css-docs/en/docs/troubleshooting/storage-backend-issues/a-backend-fails-to-be-created-using-the-oceanctl-tool-and-error-message-context-deadline-exceeded-is/","tags":"","title":"A Backend Fails to Be Created Using the oceanctl Tool and Error Message `context deadline exceeded` Is Displayed"},{"body":"Symptom Before a PVC is deleted, the PVC is in the Pending state.\nRoot Cause Analysis Cause 1: A StorageClass with the specified name is not created in advance. As a result, Kubernetes cannot find the specified StorageClass name when a PVC is created.\nCause 2: The storage pool capability does not match the StorageClass capability. As a result, huawei-csi fails to select a storage pool.\nCause 3: An error code (for example, 50331651) is returned by a RESTful interface of the storage. As a result, huawei-csi fails to create a PVC.\nCause 4: The storage does not return a response within the timeout period set by huawei-csi. As a result, huawei-csi returns a timeout error to Kubernetes.\nCause 5: Other causes.\nSolution or Workaround To delete a PVC in the Pending state, you need to take different measures according to the following causes.\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to view details about the PVC.\nkubectl describe pvc mypvc Perform the corresponding operation according to the Events information in the detailed PVC information.\nIf the PVC is in the Pending state due to cause 1, run the **kubectl delete pvc **mypvc command to delete the PVC.\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Warning ProvisioningFailed 0s (x15 over 3m24s) persistentvolume-controller storageclass.storage.k8s.io \"mysc\" not found If the PVC is in the Pending state due to cause 2, run the **kubectl delete pvc **mypvc command to delete the PVC.\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Provisioning 63s (x3 over 64s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 External provisioner is provisioning volume for claim \"default/mypvc\" Warning ProvisioningFailed 63s (x3 over 64s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 failed to provision volume with StorageClass \"mysc\": rpc error: code = Internal desc = failed to select pool, the capability filter failed, error: failed to select pool, the final filter field: replication, parameters map[allocType:thin replication:True size:1099511627776 volumeType:lun]. please check your storage class If the PVC is in the Pending state due to cause 3, run the kubectl delete pvc mypvc command to delete the PVC.\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Provisioning 63s (x4 over 68s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 External provisioner is provisioning volume for claim \"default/mypvc\" Warning ProvisioningFailed 62s (x4 over 68s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 failed to provision volume with StorageClass \"mysc\": rpc error: code = Internal desc = Create volume map[ALLOCTYPE:1 CAPACITY:20 DESCRIPTION:Created from Kubernetes CSI NAME:pvc-63ebfda5-4cf0-458e-83bd-ecc PARENTID:0] error: 50331651 If the PVC is in the Pending state due to cause 4, contact Huawei engineers.\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Provisioning 63s (x3 over 52s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 External provisioner is provisioning volume for claim \"default/mypvc\" Warning ProvisioningFailed 63s (x3 over 52s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 failed to provision volume with StorageClass \"mysc\": rpc error: code = Internal desc = context deadline exceeded (Client.Timeout exceeded while awaiting headers) If the PVC is in the Pending state due to cause 5, contact Huawei engineers.\n","categories":"","description":"","excerpt":"Symptom Before a PVC is deleted, the PVC is in the Pending state.\nRoot …","ref":"/css-docs/en/docs/troubleshooting/pvc-issues/before-a-pvc-is-deleted-the-pvc-is-in-the-pending-state/","tags":"","title":"Before a PVC Is Deleted, the PVC Is in the Pending State"},{"body":" 在升级/回退过程中，已经存在的PVC/快照/Pod等资源会正常运行，不会影响您的业务访问。 在升级/回退过程中，不能使用华为CSI创建新的资源，或者对已有的PVC做挂载/卸载操作。 在升级/回退过程中，请勿卸载Snapshot依赖组件服务。 前提条件 已下载原版本CSI的软件包。\n操作步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。 参考操作步骤卸载CSI。 参考CCE和CCE Agile平台安装华为CSI重新安装原版本的CSI。 ","categories":"","description":"","excerpt":" 在升级/回退过程中，已经存在的PVC/快照/Pod等资源会正常运行，不会影响您的业务访问。 在升级/回退过程中，不能使用华为CSI创建新的 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E4%BD%BF%E7%94%A8helm%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/cce%E5%92%8Ccce-agile%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"CCE和CCE Agile回退华为CSI"},{"body":"本章节介绍如何在CCE / CCE Agile平台安装华为CSI。\n制作Helm安装包 CCE和CCE Agile平台无法直接通过Helm安装华为CSI，需要手动制作Helm安装包后上传至平台模板市场进行安装。\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录已部署Helm的任意节点。\n将华为CSI组件包中的\"helm\"目录拷贝到节点的任意目录下。Helm工具路径请参见表 软件包组件描述。\n进入到helm的工作目录下。\ncd helm/ 修改helm/esdk/values.yaml文件中kubeletConfigDir和csiDriver.driverName参数。\nvi ./esdk/values.yaml 修改如下参数：\n# Specify kubelet config dir path. # kubernetes and openshift is usually /var/lib/kubelet # Tanzu is usually /var/vcap/data/kubelet # CCE is usually /mnt/paas/kubernetes/kubelet kubeletConfigDir: /mnt/paas/kubernetes/kubelet # The CSI driver parameter configuration csiDriver: # Driver name, it is strongly recommended not to modify this parameter # The CCE platform needs to modify this parameter, e.g. csi.oceanstor.com driverName: csi.oceanstor.com 执行命令制作Helm安装包，该命令会将安装包生成到当前路径下。\nhelm package ./esdk/ -d ./ 安装华为CSI 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录已部署CCE Agile平台master的任意节点。\n执行命令创建部署华为CSI的命名空间，huawei-csi为自定义的命名空间。\nkubectl create namespace huawei-csi 导出Helm安装包，具体请参考制作Helm安装包。\n在主页单击“模板市场\u003e 我的模板\u003e上传模板”，进入上传模板对话框。将导出的Helm安装包导入CCE Agile平台。\n安装包上传完毕，在主页单击“模板市场\u003e我的模板”，进入我的模板页面，单击“安装\u003e提交”。其中模板实例名称可自定义填写。\n在主页单击“模板市场\u003e模板实例”，选择安装时指定的项目（例如样例中的项目是“default”）。安装成功后执行状态将回显为“安装成功”。\n","categories":"","description":"","excerpt":"本章节介绍如何在CCE / CCE Agile平台安装华为CSI。\n制作Helm安装包 CCE和CCE Agile平台无法直接通过Helm安 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%AE%89%E8%A3%85%E5%8D%8E%E4%B8%BAcsi/%E4%BD%BF%E7%94%A8helm%E5%AE%89%E8%A3%85%E5%8D%8E%E4%B8%BAcsi/cce%E5%92%8Ccce-agile%E5%B9%B3%E5%8F%B0%E5%AE%89%E8%A3%85%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"CCE和CCE Agile平台安装华为CSI"},{"body":"本章节介绍如何在CCE / CCE Agile平台卸载华为CSI，以CCE Agile v22.3.2为例。\n操作步骤 登录CCE Agile平台。\n在主页单击“模板市场\u003e 模板实例 ”，进入模板实例页面。\n选择华为CSI模板实例，单击“卸载”，在弹出的提示框中单击“确定”。\n卸载huawei-csi-host-info对象，请参考卸载huawei-csi-host-info对象进行操作。\n卸载webhook资源，请参考卸载Webhook资源进行操作。\n（可选）卸载快照依赖组件服务，请参考卸载Snapshot依赖组件服务进行操作。\n","categories":"","description":"","excerpt":"本章节介绍如何在CCE / CCE Agile平台卸载华为CSI，以CCE Agile v22.3.2为例。\n操作步骤 登录CCE …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%B8%E8%BD%BD%E5%8D%8E%E4%B8%BAcsi/helm%E5%8D%B8%E8%BD%BD%E5%8D%8E%E4%B8%BAcsi/cce%E5%92%8Ccce-agile%E5%8D%B8%E8%BD%BD%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"CCE和CCE Agile卸载华为CSI"},{"body":"Symptom A Pod fails to be created, and error message “mount point does not exist” is recorded in Huawei CSI logs.\nRoot Cause Analysis The native Kubernetes cluster in the pods-dir directory of huawei-csi-node is inconsistent with the Tanzu Kubernetes cluster.\nSolution or Workaround Go to the helm/esdk/ directory and run the vi values.yaml command to open the configuration file.\nvi values.yaml Change the value of kubeletConfigDir to the actual installation directory of kubelet.\n# Specify kubelet config dir path. # kubernetes and openshift is usually /var/lib/kubelet # Tanzu is usually /var/vcap/data/kubelet kubeletConfigDir: /var/vcap/data/kubelet ","categories":"","description":"","excerpt":"Symptom A Pod fails to be created, and error message “mount point does …","ref":"/css-docs/en/docs/troubleshooting/common-problems-and-solutions-for-interconnecting-with-the-tanzu-kubernetes-cluster/changing-the-mount-point-of-a-host/","tags":"","title":"Changing the Mount Point of a Host"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/en/docs/common-operations/collecting-information/","tags":"","title":"Collecting Information"},{"body":"VolumeSnapshotClass provides a way to describe the “classes” of storage when provisioning a VolumeSnapshot. Each VolumeSnapshotClass contains the driver, deletionPolicy, and parameters fields, which are used when a VolumeSnapshot belonging to the class needs to be dynamically provisioned.\nThe name of a VolumeSnapshotClass object is significant, and is how users can request a particular class. Administrators set the name and other parameters of a class when first creating VolumeSnapshotClass objects, and the objects cannot be updated once they are created.\nThe following is an example of a VolumeSnapshotClass used by Huawei CSI:\nIf api-versions in your environment supports v1, use the following example:\napiVersion: snapshot.storage.k8s.io/v1 kind: VolumeSnapshotClass metadata: name: mysnapclass driver: csi.huawei.com deletionPolicy: Delete If api-versions in your environment supports v1beta1, use the following example:\napiVersion: snapshot.storage.k8s.io/v1beta1 kind: VolumeSnapshotClass metadata: name: mysnapclass driver: csi.huawei.com deletionPolicy: Delete If api-versions in your environment supports both v1 and v1beta1, v1 is recommended.\nYou can modify the parameters according to Table 1. Currently, Huawei CSI does not support user-defined parameters (parameters) in a VolumeSnapshotClass. Therefore, you are advised to create a VolumeSnapshotClass for all snapshots.\nTable 1 VolumeSnapshotClass parameters\nParameter\nDescription\nRemarks\nmetadata.name\nUser-defined name of a VolumeSnapshotClass object.\nTake Kubernetes v1.22.1 as an example. The value can contain digits, lowercase letters, hyphens (-), and periods (.), and must start and end with a letter or digit.\ndriver\ndriver identifier. This parameter is mandatory.\nSet this parameter to the driver name set during Huawei CSI installation. The default driver name is csi.huawei.com.\ndeletionPolicy\nSnapshot deletion policy. This parameter is mandatory. The value can be:\nDeleteRetain If the deletion policy is Delete, the snapshot on the storage device will be deleted together with the VolumeSnapshotContent object.If the deletion policy is Retain, the snapshot and VolumeSnapshotContent object on the storage device will be retained. Prerequisites Huawei CSI supports snapshots, and the volume snapshot component CRD on which its running depends has been installed. For details about the CRD, see Checking Volume Snapshot-Dependent Components. For details about the Kubernetes versions that support VolumeSnapshot creation, see Table 1.\nProcedure Run the following command to create a VolumeSnapshotClass using the created VolumeSnapshotClass configuration file.\nkubectl create -f mysnapclass.yaml Run the following command to view the information about the created VolumeSnapshotClass.\nkubectl get volumesnapshotclass The following is an example of the command output.\nNAME DRIVER DELETIONPOLICY AGE mysnapclass csi.huawei.com Delete 25s ","categories":"","description":"","excerpt":"VolumeSnapshotClass provides a way to describe the “classes” of …","ref":"/css-docs/en/docs/using-huawei-csi/creating-a-volumesnapshot/configuring-a-volumesnapshotclass/","tags":"","title":"Configuring a VolumeSnapshotClass"},{"body":"For details about how to configure ALUA for Huawei distributed storage, see the host connectivity guide of the corresponding product.\nThe ALUA configuration may vary according to the OS. Visit Huawei Technical Support, enter Host Connectivity Guide in the search box, and click the search button. In the search result, select the host connectivity guide for the desired OS. Configure ALUA according to the actual situation and the description in the guide. Huawei CSI will apply the configuration items you set to the initiator of the host on Huawei storage.\nA node with a Pod provisioned does not proactively change ALUA information. The host ALUA configuration changes only after a Pod is provisioned again to the node. In non-HyperMetro scenarios of distributed storage, you are advised to set the switchover mode to “disable ALUA” (default value). This is because the storage system is in active/active mode and “enables ALUA” is meaningless. Therefore, you are advised not to configure ALUA parameters for distributed storage.\nTable 1 lists the ALUA parameters supported by Huawei CSI for distributed storage.\nTable 1 ALUA parameters for distributed storage\nParameter\nDescription\nRemarks\nHostName\nThe value of HostName is the host name of a worker node, for example, HostName1 and HostName2.\nThe host name can be obtained by running the cat /etc/hostname command. It can be matched by using regular expressions. When HostName is set to *, the configuration takes effect on hosts with any name. For details, see Regular expression.\nIf the host name of a compute node matches multiple ALUA configuration options, they will be sorted based on the matching accuracy and the first ALUA configuration option will be used. For details about the sorting rules, see Rules for Matching ALUA Configuration Items with Host Names.\nswitchoverMode\nSwitchover mode. This parameter is mandatory. The value can be:\nDisable_alua: disables ALUA.Enable_alua: enables ALUA. In non-HyperMetro scenario, you are advised to set the switchover mode to \"disable ALUA\". This is because the storage system is in active/active mode and \"enables ALUA\" is meaningless. Currently, Huawei CSI does not support SAN HyperMetro scenarios. Exercise caution when enabling ALUA.\npathType\nPath type. This parameter is conditionally mandatory. The value can be:\noptimal_path: preferred pathnon_optimal_path: non-preferred path This parameter is mandatory when the switchover mode is set to \"enables ALUA\".\nRules for Matching ALUA Configuration Items with Host Names If the configured host name rule exactly matches the host name of the service node, the ALUA configuration item corresponding to the host name rule is used.\nFor example, the host name rule in configuration item 1 is * and that in configuration item 2 is ^myhost01$. If the host name of a compute node is myhost01, it exactly matches configuration item 2. In this case, Huawei CSI will apply the configuration information in configuration item 2 to the storage side.\nIf the configured host name rule does not exactly match the host name of the service node, the first ALUA configuration item matched by regular expressions is used.\nFor example, the host name rule in configuration item 1 is myhost0[0-9] and that in configuration item 2 is myhost0[5-9]. In this case, configuration item 1 has a higher priority than configuration item 2. If the host name of a compute node is myhost06, both configuration items can be matched. In this case, Huawei CSI will apply the configuration information in configuration item 1 to the storage side.\n","categories":"","description":"","excerpt":"For details about how to configure ALUA for Huawei distributed …","ref":"/css-docs/en/docs/advanced-features/configuring-alua/configuring-alua-using-helm/configuring-alua-parameters-for-a-distributed-storage-backend/","tags":"","title":"Configuring ALUA Parameters for a Distributed Storage Backend"},{"body":"The PVC change feature is implemented using CRD. Related resources are described as follows.\nTable 1 Resource description\nNAME\nAPIVERSION\nNAMESPACED\nKIND\nvolumemodifyclaims\nxuanwu.huawei.io/v1\nfalse\nVolumeModifyClaim\nvolumemodifycontents\nxuanwu.huawei.io/v1\nfalse\nVolumeModifyContent\nVolumeModifyClaim resources can be created, deleted, and queried, but cannot be updated. VolumeModifyContent resources can only be queried and are used to display the change details of a single PVC. Do not manually create, delete, or modify the resources. VolumeModifyContent resources are managed by VolumeModifyClaim. Do not manually manage VolumeModifyContent resources. ","categories":"","description":"","excerpt":"The PVC change feature is implemented using CRD. Related resources are …","ref":"/css-docs/en/docs/advanced-features/pvc-change/configuring-pvc-changes/","tags":"","title":"Configuring PVC Changes"},{"body":"In the Kubernetes cluster, resources can be scheduled and provisioned based on the topology labels of nodes and the topology capabilities supported by storage backends.\nPrerequisites You need to configure topology labels on worker nodes in the cluster. The method is as follows:\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to view information about worker nodes in the current cluster.\nkubectl get node The following is an example of the command output.\nNAME STATUS ROLES AGE VERSION node01 Ready controlplane,etcd,worker 42d v1.22.3 node02 Ready worker 42d v1.22.3 node03 Ready worker 42d v1.22.3 Run the following command to configure a topology label for a worker node. In the preceding command, nodename indicates the name of a worker node. For details about the key and value parameters, see Table 1.\nkubectl label node \u003cnodename\u003e \u003ckey\u003e=\u003cvalue\u003e Table 1 Parameter description\nParameter\nDescription\nRemarks\n\u003ckey\u003e\nUnique identifier of a topology label.\nThe value can be zone, region, or protocol.\u003cprotocol\u003e.\n\u003cprotocol\u003e can be set to iscsi, nfs, fc, or roce.\n\u003cvalue\u003e\nValue of a topology label.\nIf key is set to zone or region, value is a user-defined parameter.\nIf key is set to protocol.\u003cprotocol\u003e, value is fixed at csi.huawei.com.\nA topology label must start with topology.kubernetes.io. Topology label examples: Example 1: topology.kubernetes.io/region=China-west Example 2: topology.kubernetes.io/zone=ChengDu Example 3: topology.kubernetes.io/protocol.iscsi=csi.huawei.com Example 4: topology.kubernetes.io/protocol.fc=csi.huawei.com A key in a topology label on a node can have only one value. If multiple protocols are configured in a topology label on a node, when you configure a StorageClass, the StorageClass needs to meet only one of the protocols. If both the region and the zone are configured in a topology label on a node, when you configure a StorageClass, the StorageClass must meet all filter criteria. Run the following command to view the label information about all worker nodes in the current cluster.\nkubectl get nodes -o=jsonpath='{range .items[*]}[{.metadata.name}, {.metadata.labels}]{\"\\n\"}{end}' | grep --color \"topology.kubernetes.io\" The following is an example of the command output.\n[node01,\"beta.kubernetes.io/arch\":\"amd64\",\"beta.kubernetes.io/os\":\"linux\",\"kubernetes.io/arch\":\"amd64\",\"kubernetes.io/hostname\":\"node01\",\"kubernetes.io/os\":\"linux\",\"node-role.kubernetes.io/controlplane\":\"true\",\"node-role.kubernetes.io/etcd\":\"true\",\"node-role.kubernetes.io/worker\":\"true\",\"topology.kubernetes.io/zone\":\"ChengDu\"}] ","categories":"","description":"","excerpt":"In the Kubernetes cluster, resources can be scheduled and provisioned …","ref":"/css-docs/en/docs/advanced-features/configuring-storage-topology-awareness/","tags":"","title":"Configuring Storage Topology Awareness"},{"body":"This section describes how to create a PVC change resource based on a configured PVC change file.\nOnly the HyperMetro active-active (AA) mode is supported. When a common volume is changed to a HyperMetro volume, only the storage volume at the primary site can be changed. Do not use Huawei CSI to manage a PVC during PVC change resource creation. Multiple VolumeModifyClaim resources cannot be created for the same PVC. If the target PVC needs to be changed for multiple times, perform the changes one by one. Procedure Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to create a PVC change.\nkubectl create -f volumemodifyclaim.yaml Query the creation result by following the instructions in Querying a PVC Change.\n","categories":"","description":"","excerpt":"This section describes how to create a PVC change resource based on a …","ref":"/css-docs/en/docs/advanced-features/pvc-change/configuring-pvc-changes/creating-a-pvc-change/creating-a-pvc-change-resource/","tags":"","title":"Creating a PVC Change Resource"},{"body":"In Kubernetes, a VolumeSnapshot is a snapshot of a volume on a storage system. The VolumeSnapshot capability provides Kubernetes users with a standard way to replicate the content of a volume at a specified point in time without creating a volume. For example, this function enables database administrators to back up the database before making changes such as editing or deleting.\nThis section describes how to create a VolumeSnapshot using Huawei CSI. To create a VolumeSnapshot, perform the following steps:\nChecking information about volume snapshot-dependent components Configuring a VolumeSnapshotClass Configuring a VolumeSnapshot ","categories":"","description":"","excerpt":"In Kubernetes, a VolumeSnapshot is a snapshot of a volume on a storage …","ref":"/css-docs/en/docs/using-huawei-csi/creating-a-volumesnapshot/","tags":"","title":"Creating a VolumeSnapshot"},{"body":"Prerequisites Huawei CSI has been manually installed.\nProcedure Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nGo to the manual/esdk working directory and run the following command to configure the volume change CRD.\nkubectl apply -f ./crds/volume-modify/ Run the following command. For details about the component package path, see Table 1.\nkubectl apply -f ./deploy/huawei-csi-controller-extender.yaml Run the following command to check whether the services are started.\nkubectl get pod -n huawei-csi The following is an example of the command output. In the preceding command, huawei-csi indicates the namespace for deploying Huawei CSI.\nNAME READY STATUS RESTARTS AGE huawei-csi-controller-6dfcc4b79f-9vjtq 10/10 Running 0 24m huawei-csi-node-tqs87 3/3 Running 0 24m ","categories":"","description":"","excerpt":"Prerequisites Huawei CSI has been manually installed.\nProcedure Use a …","ref":"/css-docs/en/docs/advanced-features/pvc-change/enabling-the-pvc-change-feature/enabling-the-pvc-change-feature-manually/","tags":"","title":"Enabling the PVC Change Feature Manually"},{"body":"Example 1: The configuration file content is as follows:\nparameters: ALUA: \"*\": accessMode: 1 hyperMetroPathOptimized: 1 node1: accessMode: 1 hyperMetroPathOptimized: 0 If the host name is node1, both of the preceding ALUA configuration sections can be used to configure initiators. According to the configuration policy rules in Configuring ALUA Parameters for a Huawei Enterprise Storage Backend, the priority of the second configuration section (where HostName is node1) is higher than that of the first configuration section (where HostName is *).\nExample 2: The configuration file content is as follows:\nparameters: ALUA: node[0-9]: accessMode: 1 hyperMetroPathOptimized: 1 node[5-7]: accessMode: 1 hyperMetroPathOptimized: 0 If the host name is node6, both of the preceding ALUA configuration sections can be used to configure initiators. According to the configuration policy rules in Configuring ALUA Parameters for a Huawei Enterprise Storage Backend, select the first ALUA configuration section to configure initiators.\nExample 3: The configuration file content is as follows:\nparameters: node1$: node[0-9]: accessMode: 1 hyperMetroPathOptimized: 1 node10$: accessMode: 1 hyperMetroPathOptimized: 0 According to the configuration policy rules in Configuring ALUA Parameters for a Huawei Enterprise Storage Backend: For host node1, select the first ALUA configuration section to configure initiators. For host node10, select the second ALUA configuration section to configure initiators. ^ matches the beginning of a character string, and $ matches the end of a character string.\n","categories":"","description":"","excerpt":"Example 1: The configuration file content is as follows:\nparameters: …","ref":"/css-docs/en/docs/appendix/example-alua-configuration-policy-of-oceanstor-dorado/","tags":"","title":"Example ALUA Configuration Policy of OceanStor Dorado"},{"body":"When the capacity of a PVC used by a container is insufficient, you need to expand the capacity of the PVC.\nPrerequisites A PVC has been created, the backend to which it resides exists and supports capacity expansion.\nFor details about the storage devices that support capacity expansion, see Table 2 and Table 2. For details about the Kubernetes versions that support capacity expansion, see Kubernetes Feature Matrix.\nThe csi-resizer service is enabled for huawei-csi-controller.\nkubectl describe deploy huawei-csi-controller -n huawei-csi | grep csi-resizer If the following information is displayed, the csi-resizer service is enabled.\ncsi-resizer: Image: k8s.gcr.io/sig-storage/csi-resizer:v1.4.0 Procedure Run the following command to check whether the StorageClass supports capacity expansion. In the preceding command, mysc indicates the name of the StorageClass to be queried.\nkubectl get sc mysc The following is an example of the command output.\nNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE mysc csi.huawei.com Delete Immediate true 172m If the value of ALLOWVOLUMEEXPANSION is true, the current StorageClass supports capacity expansion. In this case, go to 3.\nRun the following command to change the value of allowVolumeExpansion to true. In the preceding command, mysc indicates the name of the StorageClass to be modified.\nkubectl patch sc mysc --patch '{\"allowVolumeExpansion\":true}' Run the following command to query the StorageClass name of the PVC. In the preceding command, mypvc indicates the name of the PVC to be expanded.\nkubectl get pvc mypvc The following is an example of the command output.\nNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE mypvc Bound pvc-3383be36-537c-4cb1-8f32-a415fa6ba384 2Gi RW0 mysc 145m Run the following command to expand the capacity.\nkubectl patch pvc mypvc -p '{\"spec\":{\"resources\":{\"requests\":{\"storage\":\"120Gi\"}}}}' In the preceding command, mypvc indicates the name of the PVC to be expanded, and 120Gi indicates the capacity after expansion. Change the values based on the site requirements.\nThe PVC capacity depends on storage specifications and host specifications. For example, OceanStor Dorado 6.1.2 or OceanStor Pacific series 8.1.0 is connected to CentOS 7. If ext4 file systems are used, see Table 2. If XFS file systems are used, see Table 3. If NFS or raw devices are used, the capacity must meet the specifications of the used Huawei storage device model and version. If the PVC capacity does not meet the specifications, a PVC or Pod may fail to be created due to the limitations of storage specifications or host file system specifications. If the capacity expansion fails because the target capacity exceeds the storage pool capacity, see Failed to Expand the PVC Capacity Because the Target Capacity Exceeds the Storage Pool Capacity. Run the following command to check whether the capacity modification takes effect.\nkubectl get pvc The following is an example of the command output. If the value of CAPACITY is changed to the specified capacity, the capacity expansion is successful.\nNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE mypvc Bound pvc-3383be36-537c-4cb1-8f32-a415fa6ba384 120Gi RWO mysc 24s ","categories":"","description":"","excerpt":"When the capacity of a PVC used by a container is insufficient, you …","ref":"/css-docs/en/docs/using-huawei-csi/managing-a-pvc/expanding-the-capacity-of-a-pvc/","tags":"","title":"Expanding the Capacity of a PVC"},{"body":"Symptom During the installation and deployment of CSI, a Pod fails to run and is in the ContainerCreating state. Alarm /etc/localtime is not a file is generated for the Pod.\nRoot Cause Analysis When the container mounts the /etc/localtime file on the host, the type is incorrectly identified. As a result, the container fails to mount the /etc/localtime file on the host and the Pod cannot run.\nProcedure Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to check the running status of the Pod of the CSI services.\nkubectl get pod -n huawei-csi The following is an example of the command output. huawei-csi indicates the namespace where the CSI services are deployed.\nNAME READY STATUS RESTARTS AGE huawei-csi-controller-6dfcc4b79f-9vjtq 9/9 ContainerCreating 0 24m huawei-csi-controller-6dfcc4b79f-csphc 9/9 ContainerCreating 0 24m huawei-csi-node-g6f4k 3/3 ContainerCreating 0 20m huawei-csi-node-tqs87 3/3 ContainerCreating 0 20m Run the following command to check the Events parameter of the container.\nkubectl describe pod huawei-csi-controller-6dfcc4b79f-9vjtq -n huawei-csi The following is an example of the command output. In the command, huawei-csi-controller-6dfcc4b79f-9vjtq indicates the name of the Pod in the ContainerCreating state found in 2, and huawei-csi indicates the namespace to which the Pod belongs.\n... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 96s default-scheduler Successfully assigned huawei-csi/huawei-csi-controller-6dfcc4b79f-9vjtq to node1 Warning FailedMount 33s (x8 over 96s) kubelet MountVolume.SetUp failed for volume \"host-time\" : hostPath type check failed: /etc/localtime is not a file Run the cd /helm/esdk/templates command to go to the CSI installation package path. For the path, see Table 1.\nTake the huawei-csi-controller.yaml file as an example. Run the following command to view the file content.\nvi huawei-csi-controller.yaml Find the host-time configuration item under volumes, and delete the type: File line. Perform the same operations on the huawei-csi-node.yaml deployment file that involves the configuration item in the templates directory.\n... ... volumes: - hostPath: path: /var/log/ type: Directory name: log - hostPath: path: /etc/localtime type: File name: host-time ... ... Uninstall and reinstall the service by referring to Uninstalling Huawei CSI Using Helm.\nRun the following command to check whether the Pod running status of Huawei CSI services is Running.\nkubectl get pod -n huawei-csi The following is an example of the command output.\nNAME READY STATUS RESTARTS AGE huawei-csi-controller-6dfcc4b79f-9vjts 9/9 Running 0 24m huawei-csi-controller-6dfcc4b79f-csphb 9/9 Running 0 24m huawei-csi-node-g6f41 3/3 Running 0 20m huawei-csi-node-tqs85 3/3 Running 0 20m ","categories":"","description":"","excerpt":"Symptom During the installation and deployment of CSI, a Pod fails to …","ref":"/css-docs/en/docs/troubleshooting/huawei-csi-service-issues/huawei-csi-services-fail-to-be-started-and-error-message-etc-localtime-is-not-a-file-is-displayed/","tags":"","title":"Huawei CSI Services Fail to Be Started and Error Message '/etc/localtime is not a file' Is Displayed"},{"body":"This section describes how to install Huawei CSI.\nIn the current version, resource requests and limits are added to Huawei CSI. For details, see Huawei CSI Resource Management.\nPrerequisites Operations described in Installation Preparations have been completed. All worker nodes of the cluster communicate properly with the service network of the storage device to be connected. In iSCSI scenarios, the ping command can be used to verify the connectivity. Software clients required by the corresponding protocol, such as iSCSI and NFS clients, have been installed on all worker nodes of the cluster. ","categories":"","description":"","excerpt":"This section describes how to install Huawei CSI.\nIn the current …","ref":"/css-docs/en/docs/installation-and-deployment/installing-huawei-csi/","tags":"","title":"Installing Huawei CSI"},{"body":"This section describes how to install Huawei CSI on the CCE or CCE Agile platform.\nCreating a Helm Installation Package The CCE or CCE Agile platform cannot directly install Huawei CSI using Helm. You need to manually create a Helm installation package and upload it to the chart list on the platform for installation.\nUse a remote access tool, such as PuTTY, to log in to any node where Helm is deployed through the management IP address.\nCopy the helm directory in the Huawei CSI component package to any directory on the node. For details about the Helm tool path, see Table 1.\nGo to the helm working directory.\ncd helm/ Modify the kubeletConfigDir and csiDriver.driverName parameters in the helm/esdk/values.yaml file.\nvi ./esdk/values.yaml Modify the following parameters:\n# Specify kubelet config dir path. # kubernetes and openshift is usually /var/lib/kubelet # Tanzu is usually /var/vcap/data/kubelet # CCE is usually /mnt/paas/kubernetes/kubelet kubeletConfigDir: /mnt/paas/kubernetes/kubelet # The CSI driver parameter configuration csiDriver: # Driver name, it is strongly recommended not to modify this parameter # The CCE platform needs to modify this parameter, e.g. csi.oceanstor.com driverName: csi.oceanstor.com Run the following command to create a Helm installation package. This command will generate the installation package to the current path.\nhelm package ./esdk/ -d ./ Installing Huawei CSI Use a remote access tool, such as PuTTY, to log in to any master node where the CCE Agile platform is deployed through the management IP address.\nRun the following command to create a namespace for deploying Huawei CSI. huawei-csi indicates the custom namespace.\nkubectl create namespace huawei-csi Export the Helm installation package. For details, see Creating a Helm Installation Package.\nOn the home page, choose Charts \u003e My Charts \u003e Upload Chart. The Upload Chart dialog box is displayed. Import the exported Helm installation package to the CCE Agile platform.\nAfter the installation package is uploaded, choose Charts \u003e My Charts. On the My Charts page that is displayed, choose Install \u003e Submit. The chart release name can be customized.\nOn the home page, choose Charts \u003e Releases and select the project specified during installation (for example, default in the following figure). After the installation is successful, Installed is displayed in the Status column.\n","categories":"","description":"","excerpt":"This section describes how to install Huawei CSI on the CCE or CCE …","ref":"/css-docs/en/docs/installation-and-deployment/installing-huawei-csi/installing-huawei-csi-using-helm/installing-huawei-csi-on-the-cce-or-cce-agile-platform/","tags":"","title":"Installing Huawei CSI on the CCE or CCE Agile Platform"},{"body":"This section describes the features of different Kubernetes versions supported by Huawei CSI.\nTable 1 Kubernetes versions and supported features\nFeature\nV1.16\nV1.17\nV1.18\nV1.19\nV1.20\nV1.21+\nStatic Provisioning\n√\n√\n√\n√\n√\n√\nDynamic Provisioning\n√\n√\n√\n√\n√\n√\nManage Provisioning1\n√\n√\n√\n√\n√\n√\nExpand Persistent Volume\n√\n√\n√\n√\n√\n√\nCreate VolumeSnapshot\nx\n√\n√\n√\n√\n√\nRestore VolumeSnapshot\nx\n√\n√\n√\n√\n√\nDelete VolumeSnapshot\nx\n√\n√\n√\n√\n√\nClone Persistent Volume\nx\n√\n√\n√\n√\n√\nModify Volume2\n√\n√\n√\n√\n√\n√\nRaw Block Volume\n√\n√\n√\n√\n√\n√\nTopology\n√\n√\n√\n√\n√\n√\nGeneric Ephemeral Inline Volumes\nx\nx\nx\nx\nx\n√\nVolume Limits\nx\n√\n√\n√\n√\n√\nFSGroup Support\nx\nx\nx\nx\n√\n√\nNote 1: Manage Provisioning is a volume management feature customized by Huawei CSI. This feature allows existing storage resources to be managed by Kubernetes. You are not allowed to manage a storage resource for multiple times and concurrently delete or create a storage resource. When a storage resource is managed by multiple clusters, operations on the managed volume in a single cluster take effect only in the cluster and will not be synchronized to other clusters. Instead, you need to perform these operations on the managed volume in other clusters. Note 2: Modify Volume is a PVC change feature customized by Huawei CSI. This feature allows a common volume to be changed to a HyperMetro volume. To use this feature, ensure that the connected storage supports the volume HyperMetro feature. ","categories":"","description":"","excerpt":"This section describes the features of different Kubernetes versions …","ref":"/css-docs/en/docs/compatibility-and-features/kubernetes-feature-matrix/","tags":"","title":"Kubernetes Feature Matrix"},{"body":"前提条件 旧版本华为CSI使用Helm安装。 新版本华为CSI镜像已制作完成，并且按照上传华为CSI镜像章节说明，上传到镜像仓库或者导入到所有节点。 升级华为CSI 如果您旧版本CSI使用Helm部署，请按照以下操作步骤升级华为CSI。\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n将目标版本CSI组件包拷贝到master节点的任意目录下。\n进入到helm/esdk的工作目录下，目录路径请参见表 软件包组件描述。\ncd helm/esdk 执行kubectl apply -f ./crds/backend/命令，更新存储后端CRD\nkubectl apply -f ./crds/backend/ （可选） 请务必按照检查卷快照依赖组件章节检查快照依赖组件，确认无误后执行执行kubectl apply -f ./crds/snapshot-crds/ –validate=false命令更新快照CRD，如果controller.snapshot.enabled参数设置为false或Kubernetes版本低于v1.17，可跳过本步骤，详情请参考表 controller配置项说明。\nkubectl apply -f ./crds/snapshot-crds/ --validate=false 执行以下命令，获取原有服务配置文件。其中helm-huawei-csi为旧版本安装时指定的Helm Chart名称，huawei-csi为旧版本安装时指定的Helm Chart命名空间。\nhelm get values helm-huawei-csi -n huawei-csi -a \u003e ./update-values.yaml 执行vi update-values.yaml命令打开6中获取的文件，修改images配置项，更新镜像至最新版本。需要修改的参数请参考表 images配置项。\n表 1 images配置项\n参数\n描述\n修改为\nimages.huaweiCSIService\nhuawei-csi镜像。\nhuawei-csi:4.5.0\nimages.storageBackendSidecar\n华为后端管理storageBackendContent资源的镜像\nstorage-backend-sidecar:4.5.0\nimages.storageBackendController\n华为后端管理storageBackendClaim资源的镜像。\nstorage-backend-controller:4.5.0\nimages.huaweiCSIExtender\nhuawei-csi-extender镜像\nhuawei-csi-extender:4.5.0\nimages.sidecar.livenessProbe\nlivenessprobe sidecar镜像。\nk8s.gcr.io/sig-storage/livenessprobe:v2.5.0\nimages.sidecar.provisioner\ncsi-provisioner sidecar镜像。\nk8s.gcr.io/sig-storage/csi-provisioner:v3.0.0\nimages.sidecar.attacher\ncsi-attacher sidecar镜像。\nk8s.gcr.io/sig-storage/csi-attacher:v3.4.0\nimages.sidecar.resizer\ncsi-resizer sidecar镜像。\nk8s.gcr.io/sig-storage/csi-resizer:v1.4.0\nimages.sidecar.snapshotter\ncsi-snapshotter sidecar镜像。\nk8s.gcr.io/sig-storage/csi-snapshotter:v4.2.1\nimages.sidecar.snapshotController\nsnapshot-controller sidecar镜像。\nk8s.gcr.io/sig-storage/snapshot-controller:v4.2.1\nimages.sidecar.registrar\ncsi-node-driver-registrar sidecar镜像。\nk8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.3.0\n（可选）在升级过程中如需自定义更新配置项信息或者需要新增配置信息，可参考Helm values.yaml参数说明修改update-values.yaml文件中配置信息。\n升级时，如果update-values.yaml与values.yaml配置文件中存在相同配置项，update-values.yaml中的配置将会优先生效。\n执行以下命令，升级华为CSI。其中helm-huawei-csi为指定的Helm Chart名称，huawei-csi为指定的Helm Chart命名空间，update-values.yaml为步骤6中获取的文件。\nhelm upgrade helm-huawei-csi ./ -n huawei-csi -f ./values.yaml -f ./update-values.yaml 完成huawei-csi服务部署后，执行命令检查服务是否启动。\nkubectl get pod -n huawei-csi 命令结果示例如下，Pod状态为“Running“表明服务启动成功。\nNAME READY STATUS RESTARTS AGE huawei-csi-controller-6dfcc4b79f-9vjtq 9/9 Running 0 24m huawei-csi-controller-6dfcc4b79f-csphc 9/9 Running 0 24m huawei-csi-node-g6f4k 3/3 Running 0 20m huawei-csi-node-tqs87 3/3 Running 0 20m ","categories":"","description":"","excerpt":"前提条件 旧版本华为CSI使用Helm安装。 新版本华为CSI镜像已制作完成，并且按照上传华为CSI镜像章节说明，上传到镜像仓库或者导入到所 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E4%BD%BF%E7%94%A8helm%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E5%8D%87%E7%BA%A7%E5%8D%8E%E4%B8%BAcsi/kubernetes-openshift-tanzu%E5%8D%87%E7%BA%A7%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"Kubernetes、OpenShift、Tanzu升级华为CSI"},{"body":"本章节说明华为CSI在不同Kubernetes版本下支持的特性。\n表 1 Kubernetes版本与支持的特性\n特性\nV1.16\nV1.17\nV1.18\nV1.19\nV1.20\nV1.21+\nStatic Provisioning\n√\n√\n√\n√\n√\n√\nDynamic Provisioning\n√\n√\n√\n√\n√\n√\nManage Provisioning1\n√\n√\n√\n√\n√\n√\nExpand Persistent Volume\n√\n√\n√\n√\n√\n√\nCreate VolumeSnapshot\nx\n√\n√\n√\n√\n√\nRestore VolumeSnapshot\nx\n√\n√\n√\n√\n√\nDelete VolumeSnapshot\nx\n√\n√\n√\n√\n√\nClone Persistent Volume\nx\n√\n√\n√\n√\n√\nModify Volume2\n√\n√\n√\n√\n√\n√\nRaw Block Volume\n√\n√\n√\n√\n√\n√\nTopology\n√\n√\n√\n√\n√\n√\nGeneric Ephemeral Inline Volumes\nx\nx\nx\nx\nx\n√\nVolume Limits\nx\n√\n√\n√\n√\n√\nFSGroup Support\nx\nx\nx\nx\n√\n√\n注释1 Manage Provisioning是华为CSI自定义的纳管卷特性，该特性支持将已有存储资源纳管至Kubernetes。不允许将一个存储资源纳管多次和针对同一个存储资源进行并发删除/创建操作。当同一个存储资源被多个集群纳管时，在单个集群中针对该纳管卷的操作仅在当前集群内生效，不会同步到其他集群中，需要使用者自行在其他集群中对该纳管卷进行数据同步操作。 注释2 Modify Volume是华为CSI自定义的PVC变更特性，该特性支持将普通卷变更为双活卷，使用该特性需要对接存储支持卷双活特性。 ","categories":"","description":"","excerpt":"本章节说明华为CSI在不同Kubernetes版本下支持的特性。\n表 1 Kubernetes版本与支持的特性\n特性\nV1.16\nV1.17 …","ref":"/css-docs/docs/%E5%85%BC%E5%AE%B9%E6%80%A7%E5%92%8C%E7%89%B9%E6%80%A7/kubernetes%E7%89%B9%E6%80%A7%E7%9F%A9%E9%98%B5/","tags":"","title":"Kubernetes特性矩阵"},{"body":"Manage Volume Provisioning allows administrators to use resources created on storage as PVs and supports features of dynamic volumes, such as capacity expansion, snapshot, and clone. This is a custom capability of Huawei CSI. This feature applies to the following scenarios:\nIn the reconstruction containerized applications, existing storage volumes need to be used. The Kubernetes cluster is rebuilt. Storage data is migrated in disaster recovery (DR) scenarios. In scenarios where multiple Kubernetes clusters are deployed, when Manage Volume Provisioning is used to manage the same storage resource, management operations performed on the PVC corresponding to the resource in any cluster will not be synchronized to other clusters. For example, when you expand the capacity of a PVC in a cluster, the capacity of the corresponding PVC in other clusters will not be automatically expanded. In this case, you need to manually expand the capacity in other clusters by running the expansion commands in Expanding the Capacity of a PVC.\nPrerequisites You have registered the storage where the volume to be managed resides with CSI. You have logged in to the storage device to obtain the name and capacity of the volume to be managed. Configuring a StorageClass Create a StorageClass configuration file, for example, mysc.yaml, based on service requirements by referring to StorageClass Configuration Examples in Typical Manage Volume Provisioning Scenarios and StorageClass Parameters for Manage Volume Provisioning.\nRun the following command to create a StorageClass using the configuration file.\nkubectl apply -f mysc.yaml Run the following command to view the information about the created StorageClass.\nkubectl get sc mysc The following is an example of the command output.\nNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE mysc csi.huawei.com Delete Immediate true 8s Configuring a PVC Based on service requirements, modify specific parameters by referring to the description in this section and the PVC configuration file example to generate the PVC configuration file to be created, for example, the mypvc.yaml file in this example.\nkind: PersistentVolumeClaim apiVersion: v1 metadata: name: mypvc annotations: csi.huawei.com/manageVolumeName: \"*\" # Enter the storage resource name. csi.huawei.com/manageBackendName: \"*\" # Enter the storage backend name. labels: provisioner: csi.huawei.com spec: accessModes: - ReadWriteOnce volumeMode: Filesystem storageClassName: mysc resources: requests: storage: 100Gi Run the following command to create a PVC using the configuration file.\nkubectl create -f mypvc.yaml After a period of time, run the following command to view the information about the created PVC.\nkubectl get pvc mypvc The following is an example of the command output. If the PVC status is Bound, the PVC has been created and can be used by a Pod.\nNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE mypvc Bound pvc-840054d3-1d5b-4153-b73f-826f980abf9e 100Gi RWO mysc 12s After the PVC is created, if the PVC is in the Pending state after a long time (for example, one minute), refer to When a PVC Is Created, the PVC Is in the Pending State. You are advised to create or delete a maximum of 100 PVCs in a batch. Using a PVC The use method is the same as that for dynamic volume provisioning in Using a PVC.\n","categories":"","description":"","excerpt":"Manage Volume Provisioning allows administrators to use resources …","ref":"/css-docs/en/docs/using-huawei-csi/managing-a-pvc/creating-a-pvc/manage-volume-provisioning/","tags":"","title":"Manage Volume Provisioning"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/en/docs/installation-and-deployment/upgrading-or-rolling-back-huawei-csi/manual-upgrade-rollback/","tags":"","title":"Manual Upgrade/Rollback"},{"body":"This section describes how to manually install Huawei CSI.\nCurrently, only the Kubernetes platform supports manual installation of Huawei CSI.\nProcedure Use a remote access tool, such as PuTTY, to log in to any master node in the cluster through the management IP address.\nCopy the manual directory in the Kubernetes CSI component package to any directory on the master node.\nRun the following command to create a namespace.\nkubectl create ns huawei-csi Go to the manual/esdk working directory. For details about the path, see Table 1.\ncd manual/esdk Run the following command to update the storage backend CRD.\nkubectl apply -f ./crds/backend/ (Optional) Check snapshot-dependent components by following the instructions provided in Checking Volume Snapshot-Dependent Components. After confirming that the components are correct, run the following command to update the snapshot CRD. If the Kubernetes version is earlier than v1.17, skip this step.\nkubectl apply -f ./crds/snapshot-crds/ --validate=false (Optional) Run the following command to install CSIDriver. If the CSIDriver feature is not used, you can skip this step. For details, see the CSIDriver feature.\nkubectl apply -f ./deploy/csidriver.yaml Run the following command to install the huawei-csi-controller service.\nIf the Kubernetes version is earlier than v1.17, modify the ./deploy/huawei-csi-controller.yaml file as follows:\nIf the Kubernetes version is earlier than v1.17, the snapshot feature is not supported. In this case, delete the snapshot-related container configurations items csi-snapshotter and snapshot-controller. If the Kubernetes version is earlier than v1.17, the csi-provisioner sidecar image provided by the Kubernetes community does not support the –leader-election parameter. Therefore, the leader-election parameter of the csi-provisioner container is deleted and only single-copy deployment is supported. Modify the dependent image version based on the version requirements in Checking the Images on Which CSI Depends. kubectl apply -f ./deploy/huawei-csi-controller.yaml Run the following command to install the huawei-csi-node service.\nkubectl apply -f ./deploy/huawei-csi-node.yaml Run the following command to check whether the services are started.\nkubectl get pod -n huawei-csi The following is an example of the command output. If the Pod status is Running, the installation is successful.\nNAME READY STATUS RESTARTS AGE huawei-csi-controller-68745d489c-v5xkj 9/9 Running 0 13m huawei-csi-node-4hbqp 3/3 Running 0 13m huawei-csi-node-f7dkf 3/3 Running 0 13m huawei-csi-node-xrntc 3/3 Running 0 13m In the multi-copy controller deployment scenario, you can modify the spec.replica field of the Deployment resource in the ./deploy/huawei-csi-controller.yaml file to specify the number of copies. After the modification, run the following command for the modification to take effect.\nkubectl apply -f ./deploy/huawei-csi-controller.yaml ","categories":"","description":"","excerpt":"This section describes how to manually install Huawei CSI.\nCurrently, …","ref":"/css-docs/en/docs/installation-and-deployment/installing-huawei-csi/manually-installing-huawei-csi/","tags":"","title":"Manually Installing Huawei CSI"},{"body":"This section describes how to manually uninstall Huawei CSI.\nIf you do not uninstall Huawei CSI for the purpose of an upgrade, ensure that all resources (such as PV, PVC, snapshot, and storage backend resources) provisioned by Huawei CSI have been cleared on your container platform before uninstalling Huawei CSI. Otherwise, once you uninstall Huawei CSI, these resources cannot be automatically scheduled, managed, or cleared.\nUninstalling the huawei-csi-node Service Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to uninstall the huawei-csi-node service. Replace huawei-csi with the namespace where Huawei CSI is located.\nkubectl delete daemonset huawei-csi-node -n huawei-csi Run the following command to check whether the service is successfully uninstalled. If NotFound is displayed, the service is successfully uninstalled.\nkubectl get daemonset huawei-csi-node -n huawei-csi Uninstalling the huawei-csi-controller Service Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to uninstall the huawei-csi-controller service. Replace huawei-csi with the namespace where Huawei CSI is located.\nkubectl delete deployment huawei-csi-controller -n huawei-csi Run the following command to check whether the service is successfully uninstalled. If NotFound is displayed, the service is successfully uninstalled.\nkubectl get deployment huawei-csi-controller -n huawei-csi Uninstalling the csidriver Object If the CSIDriver feature is not used during installation, you can skip the following steps.\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to uninstall the csidriver object.\nkubectl delete csidriver csi.huawei.com Run the following command to check whether the service is successfully uninstalled. If NotFound is displayed, the service is successfully uninstalled.\nkubectl get csidriver csi.huawei.com Deleting the RBAC Permission Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nDelete the RBAC permission.\nkubectl -n huawei-csi -l provisioner=csi.huawei.com delete ServiceAccount,Service,role,rolebinding,ClusterRole,ClusterRoleBinding Uninstalling Other Resources Uninstall the huawei-csi-host-info object. For details, see Uninstalling the huawei-csi-host-info Object. Uninstall the webhook resource. For details, see Uninstalling a Webhook Resource. (Optional) Uninstall the snapshot-dependent component service. For details, see Uninstalling the Snapshot-Dependent Component Service. (Optional) Uninstall the Lease resource. For details, see Uninstalling a Lease Resource. ","categories":"","description":"","excerpt":"This section describes how to manually uninstall Huawei CSI.\nIf you do …","ref":"/css-docs/en/docs/installation-and-deployment/uninstalling-huawei-csi/manually-uninstalling-huawei-csi/","tags":"","title":"Manually Uninstalling Huawei CSI"},{"body":" PVC provisioning must be based on a configured storage backend. Therefore, if a PVC has been provisioned on a storage backend, do not change the storage backend. The name uniquely identifies a storage backend. The name of a storage backend with a PVC provisioned cannot be changed. After a storage backend is modified, the new configuration applies only to volumes to be provisioned. Do not perform volume management operations during the modification of a storage backend. Procedure Delete the storage backend to be modified. For details, see Deleting a Storage Backend. Create a storage backend with the same name. For details, see Creating a Storage Backend. The storage backend name cannot be changed. ","categories":"","description":"","excerpt":" PVC provisioning must be based on a configured storage backend. …","ref":"/css-docs/en/docs/storage-backend-management/managing-storage-backends/updating-a-storage-backend/manually-updating-a-storage-backend/","tags":"","title":"Manually Updating a Storage Backend"},{"body":"例1.配置文件如下：\nparameters: ALUA: \"*\": accessMode: 1 hyperMetroPathOptimized: 1 node1: accessMode: 1 hyperMetroPathOptimized: 0 对于主机名为“node1”，上述ALUA配置段都能用于配置启动器。根据配置华为企业存储后端的ALUA参数中的配置策略规则，优先级顺序为第2条配置段（HostName为\"node1\"）高于第1条配置段（HostName为\"*\"）。\n例2.配置文件如下：\nparameters: ALUA: node[0-9]: accessMode: 1 hyperMetroPathOptimized: 1 node[5-7]: accessMode: 1 hyperMetroPathOptimized: 0 对于主机名为“node6”的主机，上述ALUA配置段都能用于配置启动器。根据配置华为企业存储后端的ALUA参数中的配置策略规则，选择第一条ALUA配置段来配置启动器。\n例3.配置文件如下：\nparameters: node1$: node[0-9]: accessMode: 1 hyperMetroPathOptimized: 1 node10$: accessMode: 1 hyperMetroPathOptimized: 0 根据配置华为企业存储后端的ALUA参数中的配置策略规则，对于主机名为“node1”的主机，选择第一条ALUA配置段来配置启动器；对于主机名为“node10”的主机，选择第二条ALUA配置段来配置启动器。^表示匹配字符串的开头，$表示匹配字符串的结尾。\n","categories":"","description":"","excerpt":"例1.配置文件如下：\nparameters: ALUA: \"*\": accessMode: 1 …","ref":"/css-docs/docs/%E9%99%84%E5%BD%95/oceanstor-dorado-alua%E7%89%B9%E6%80%A7%E9%85%8D%E7%BD%AE%E7%AD%96%E7%95%A5%E6%A0%B7%E4%BE%8B/","tags":"","title":"OceanStor Dorado ALUA特性配置策略样例"},{"body":"Container Storage Interface (CSI) is an industry standard used to expose block and file storage systems to container workloads on container orchestration systems (COs) such as Kubernetes. Huawei CSI plug-in is used to communicate with Huawei enterprise storage and distributed storage products and provide storage services for Kubernetes container workloads. It is a mandatory plug-in used by Huawei enterprise storage and distributed storage in the Kubernetes environment.\nKubernetes uses a series of officially maintained sidecar components to register and listen to Kubernetes object resources and call CSI Driver through gRPC when necessary. Huawei CSI Driver implements the call initiated by sidecar on Huawei storage, for example, creating a Persistent Volume (PV) is to create a LUN or file system on Huawei storage. The following figure shows the overall structure of Kubernetes, Huawei CSI, and Huawei storage.\nFigure 1 CSI overall architecture\nHuawei CSI consists of two components: huawei-csi-controller and huawei-csi-node.\nhuawei-csi-controller: one or more Pods (including Controller Service and Identity Service) running in Deployment mode. It is used to interact with Huawei storage using RESTful. Therefore, the node running the huawei-csi-controller component must be connected to the management plane network of the storage. huawei-csi-node: a Pod (including Node Service and Identity Service) that runs on Kubernetes worker nodes in DaemonSet mode. It is used to mount and unmount a LUN/file system provided by Huawei storage on worker nodes. Therefore, the node running the huawei-csi-node component must be connected to the service plane network of the storage. The following figure shows the deployment model of Huawei CSI.\nFigure 2 CSI deployment model\nThis document describes how to install, deploy, and use the Huawei CSI V4.5.0 plug-in.\n","categories":"","description":"","excerpt":"Container Storage Interface (CSI) is an industry standard used to …","ref":"/css-docs/en/docs/overview/","tags":"","title":"Overview"},{"body":"Table 1 PVC parameters\nParameter\nDescription\nMandatory\nDefault Value\nRemarks\nmetadata.name\nUser-defined name of a PVC object.\nYes\n-\nTake Kubernetes v1.22.1 as an example. The value can contain digits, lowercase letters, hyphens (-), and periods (.), and must start and end with a letter or digit.\nspec.accessModes\nAccess mode of the volume.\nRWO (ReadWriteOnce): A volume can be mounted to a node in read/write mode. This mode also allows multiple Pods running on the same node to access the volume.ROX (ReadOnlyMany): A volume can be mounted to multiple nodes in read-only mode.RWX (ReadWriteMany): A volume can be mounted to multiple nodes in read/write mode.RWOP (ReadWriteOncePod): A volume can only be mounted to a single Pod in read/write mode. Kubernetes 1.22 and later versions support this feature. Yes\nReadWriteOnce\nRWO/ROX/RWOP: supported by all types of volumes. RWOP is supported only by Kubernetes 1.22 and later versions. Check whether this feature is enabled for your Kubernetes cluster by referring to Enabling the ReadWriteOncePod Feature Gate.The support for RWX is as follows:NAS storage: supported by all volumesSAN storage: supported only by volumes whose volumeMode is set to Block spec.volumeMode\nVolume mode.\nNo\nFilesystem\nThis parameter is optional. The value can be Filesystem or Block. The default value is Filesystem. This parameter takes effect when a Pod is created. Filesystem indicates that a file system is created on a PVC to access the storage. Block indicates that a raw volume is used to access the storage.\nspec.resources.requests.storage\nSize of the volume to be created.\nYes\n-\nSize of the volume to be created. The format is ***Gi and the unit is GiB.\nThe PVC capacity depends on storage specifications and host specifications. For example, OceanStor Dorado 6.1.2 or OceanStor Pacific series 8.1.0 is connected to CentOS 7. If ext4 file systems are used, see Table 2. If XFS file systems are used, see Table 3. If NFS or raw devices are used, the capacity must meet the specifications of the used Huawei storage device model and version.\nIf the PVC capacity does not meet the specifications, a PVC or Pod may fail to be created due to the limitations of storage specifications or host file system specifications.\nWhen a PVC is created using a static PV and the PVC capacity is smaller than the capacity of the bound PV, the PVC capacity is set to the capacity of the bound PV. If the PVC capacity is greater than the capacity of the bound PV, the PVC cannot be created.\nspec.volumeName\nName of the PV object.\nYes\n-\nThis parameter is mandatory when a PVC is created statically.\nspec.storageClassName\nName of the StorageClass object.\nYes\n-\nWhen a PVC is created, an empty character string is transferred. If this parameter is not set, the default StorageClass object name will be used.\n","categories":"","description":"","excerpt":"Table 1 PVC parameters\nParameter\nDescription\nMandatory\nDefault Value …","ref":"/css-docs/en/docs/using-huawei-csi/managing-a-pvc/creating-a-pvc/static-volume-provisioning/pvc-parameters-for-static-volume-provisioning/","tags":"","title":"PVC Parameters for Static Volume Provisioning"},{"body":"This section describes how to use Kubectl to query the PVC change status. Currently, Huawei CSI provides the following APIs through CRD.\nQuerying a VolumeModifyClaim To query a VolumeModifyClaim using kubectl, perform the following steps.\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to query a PVC change. In the command, vmc-name indicates the name of the VolumeModifyClaim resource.\nkubectl get volumemodifyclaims \u003cvmc-name\u003e -owide The following is an example of the command output.\nNAME STATUS READY SOURCEKIND SOURCENAME STARTEDAT COMPLETEDAT AGE myvmc Completed 1/1 StorageClass mysc 2024-06-06T03:19:13Z 2024-06-06T03:19:16Z 2m2s Table 1 Command output description\nParameter\nDescription\nNAME\nVolumeModifyClaim resource name.\nSTATUS\nVolumeModifyClaim resource status. The value can be:\nPending: initial status.Creating: The VolumeModifyClaim has completed basic verification and the server has received the change task, but the task has not been completed.Completed: All associated PVCs are changed.Rollback: When associated PVCs are partially changed, a user deletes PVCs.Deleting: When all associated PVCs are changed, a user deletes PVCs. READY\nRatio of the number of changed PVCs to the total number of PVCs that need to be changed.\nSOURCEKIND\nData source type, for example, StorageClass.\nSOURCENAME\nData source name, for example, StorageClass name.\nSTARTEDAT\nChange start time, that is, the timestamp when the server receives the task and starts to process the task.\nCOMPLETEDAT\nChange completion time, that is, the timestamp when the changes of all associated PVCs are complete. This parameter exists only when STATUS is Completed.\nAGE\nLifetime of a VolumeModifyClaim from the time when it is created to the current time.\nYou can use kubectl to view the Events information of a VolumeModifyClaim. If a VolumeModifyClaim cannot meet the creation requirements or an error occurs during the creation, the server will record the Events information. The following command is used as an example:\nkubectl describe volumemodifyclaims local-to-hypermetro Querying a VolumeModifyContent A VolumeModifyContent is created using a VolumeModifyClaim and records the change details of a single PVC. To query a VolumeModifyContent using kubectl, perform the following steps:\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to query a PVC change. In the command, myvmc-uid indicates the VolumeModifyContent resource name.\nkubectl get volumemodifycontents myvmc-uid -owide The following is an example of the command output.\nNAME STATUS MODIFYCLAIMNAME SOURCEVOLUME STARTEDAT COMPLETEDAT AGE myvmc-uid Completed myvmc default/mypvc 2024-06-06T03:19:07Z 2024-06-06T03:19:09Z 36m Table 2 Command output description\nParameter\nDescription\nNAME\nVolumeModifyContent resource name. The format is VolumeModifyClaim name-UID of the associated PVC.\nSTATUS\nVolumeModifyContent resource status. The value can be:\nPending: initial status.Creating: The VolumeModifyContent has completed basic verification and the server has received the change task, but the task has not been completed.Completed: The associated PVC is changed.Rollback: The PVC change is being rolled back. MODIFYCLAIMNAME\nName of the associated VolumeModifyClaim.\nSOURCEVOLUME\nInformation about the associated PVC. The format is Namespace name/PVC name.\nSTARTEDAT\nPVC change start time, that is, the timestamp when the server receives the task and starts to process the task.\nCOMPLETEDAT\nPVC change completion time, that is, the timestamp when the changes of all associated PVCs are complete. This parameter exists only when STATUS is Completed.\nAGE\nLifetime of a VolumeModifyContent from the time when it is created to the current time.\nYou can use kubectl to view the Events information of a VolumeModifyContent. If a VolumeModifyContent cannot meet the creation requirements or an error occurs during the PVC change, the server will record the Events information. The following command is used as an example:\nkubectl describe volumemodifycontents myvmc-uid ","categories":"","description":"","excerpt":"This section describes how to use Kubectl to query the PVC change …","ref":"/css-docs/en/docs/advanced-features/pvc-change/configuring-pvc-changes/querying-a-pvc-change/","tags":"","title":"Querying a PVC Change"},{"body":"Run the oceanctl commands in Querying a Storage Backend to query the storage backend information.\n","categories":"","description":"","excerpt":"Run the oceanctl commands in Querying a Storage Backend to query the …","ref":"/css-docs/en/docs/storage-backend-management/managing-storage-backends/querying-a-storage-backend/","tags":"","title":"Querying a Storage Backend"},{"body":"Query storage backend certificates using the commands in Querying a Storage Backend Certificate.\n","categories":"","description":"","excerpt":"Query storage backend certificates using the commands in Querying a …","ref":"/css-docs/en/docs/storage-backend-management/optional-adding-a-certificate-to-a-storage-backend/querying-a-storage-backend-certificate/","tags":"","title":"Querying a Storage Backend Certificate"},{"body":"Uninstall CSI by referring to Manually Uninstalling Huawei CSI, and then download and install CSI of the source version.\nDuring the upgrade or rollback, the existing resources such as PVCs, snapshots, and Pods will run properly and will not affect your service access. During the upgrade or rollback, you cannot use Huawei CSI to create new resources or mount or unmount an existing PVC. During the upgrade or rollback, do not uninstall the snapshot-dependent component service. Prerequisites You have downloaded the CSI software package of the source version.\nProcedure Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address. Uninstall CSI. For details, see Manually Uninstalling Huawei CSI. Reinstall CSI of the source version. For details, see Manually Installing Huawei CSI. ","categories":"","description":"","excerpt":"Uninstall CSI by referring to Manually Uninstalling Huawei CSI, and …","ref":"/css-docs/en/docs/installation-and-deployment/upgrading-or-rolling-back-huawei-csi/manual-upgrade-rollback/rolling-back-huawei-csi-1/","tags":"","title":"Rolling Back Huawei CSI"},{"body":" During the upgrade or rollback, the existing resources such as PVCs, snapshots, and Pods will run properly and will not affect your service access. During the upgrade or rollback, you cannot use Huawei CSI to create new resources or mount or unmount an existing PVC. During the upgrade or rollback, do not uninstall the snapshot-dependent component service. Prerequisites You have downloaded the CSI software package of the source version.\nProcedure Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address. Uninstall CSI. For details, see Procedure. Reinstall CSI of the source version. For details, see Installing Huawei CSI on the CCE or CCE Agile Platform. ","categories":"","description":"","excerpt":" During the upgrade or rollback, the existing resources such as PVCs, …","ref":"/css-docs/en/docs/installation-and-deployment/upgrading-or-rolling-back-huawei-csi/upgrading-or-rolling-back-huawei-csi-using-helm/rolling-back-huawei-csi/rolling-back-huawei-csi-on-cce-or-cce-agile/","tags":"","title":"Rolling Back Huawei CSI on CCE or CCE Agile"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/en/docs/troubleshooting/storage-backend-issues/","tags":"","title":"Storage Backend Issues"},{"body":"An example template of the backend configuration file is /examples/backend/backend.yaml. The following table lists the parameters.\nTable 1 backend parameters\nParameter\nDescription\nMandatory\nDefault Value\nRemarks\nstorage\nStorage service type.\nIf enterprise storage provides SAN, set this parameter to oceanstor-san.If enterprise storage provides NAS, set this parameter to oceanstor-nas.If enterprise storage provides NAS of the Dtree type, set this parameter to oceanstor-dtree.If distributed storage provides SAN, set this parameter to fusionstorage-san.If distributed storage provides NAS, set this parameter to fusionstorage-nas. Yes\noceanstor-nas\nOne backend can provide only one storage service. If a single Huawei storage system can provide both SAN and NAS storage services, you can configure multiple backends and use different storage service types for each backend.\nname\nStorage backend name. The value can contain a maximum of 63 characters, including lowercase letters, digits, and hyphens (-). It must start with a letter or digit.\nYes\n-\nEnsure that the storage backend name is unique.\nnamespace\nNamespace.\nNo\n-\nThe storage backend must be in the same namespace as Huawei CSI.\nvstoreName\nvStore name on the storage side. This parameter needs to be specified when the connected backend is OceanStor V5 and resources need to be provisioned under a specified vStore.\nConditionally mandatory\n-\nThis parameter needs to be specified only when the backend is OceanStor V5 and vStores need to be supported.\naccountName\nAccount name on the storage side. This parameter is mandatory when OceanStor Pacific series NAS is connected and NAS resources need to be provisioned under a specified account.\nConditionally mandatory\n-\nThis parameter needs to be specified only when the backend is OceanStor Pacific series NAS and accounts need to be supported.\nurls\nManagement URLs of storage device. The value format is a list. The value can be a domain name or an IP address + port number. Only IPv4 addresses are supported.\nYes\n-\nIf the connected backend is OceanStor or OceanStor Dorado storage and resources need to be provisioned under a specified vStore, set this parameter to the URL of the logical management port of the vStore.\npools\nStorage pools of storage devices. The value format is a list.\nConditionally mandatory\n-\nThis parameter is optional when storage is set to oceanstor-dtree.\nparameters.protocol\nStorage protocol. The value is a character string.\niscsifcrocefc-nvmenfsdpcscsi Yes\n-\nIf the value is set to iscsi, ensure that an iSCSI client has been installed on the connected compute node.If the value is set to nfs, ensure that an NFS client tool has been installed on the connected compute node.If the value is set to fc-nvme or roce, ensure that the nvme-cli tool has been installed on the connected compute node. The tool version must be 1.x and not earlier than 1.9. If the value is set to dpc, ensure that DPC has been installed on the connected compute node and the node has been added as a DPC compute node on the storage device to be connected.If the value is set to scsi, ensure that a distributed storage VBS client has been installed on the connected compute node. parameters.portals\nService access port. Nodes will use this port to read and write storage resources. The value format is a list.\nMultiple ports can be configured if the protocol is iscsi or roce. Only one port can be configured if the protocol is nfs. Service ports do not need to be configured if the protocol is fc, fc-nvme, or dpc. If the protocol is scsi, the port is in dictionary format where the key indicates the host name and the value indicates the IP address (only IPv4 addresses are supported).\nConditionally mandatory\n-\nIf a vStore or account is used to connect to a backend, portals must be set to the logical port information of the vStore or account.If nfs is used, the value can be a domain name. parameters.ALUA\nALUA configuration of the storage backend. If the worker node uses the native multipathing software provided by the OS and ALUA is enabled, you need to configure this parameter.\nConditionally mandatory\n-\nIf ALUA is enabled for the host multipathing software, ensure that the backend ALUA configuration is the same as that of the host ALUA configuration.\nFor details about the ALUA configuration, see Configuring ALUA Using Helm.\nparameters.parentname\nName of a file system on the current storage device. Dtree is created in the file system.\nThis parameter is mandatory when storage is set to oceanstor-dtree.\nConditionally mandatory\n-\nQuery the name on the File Systems page of DeviceManager.\nmetrovStorePairID\nHyperMetro vStore pair ID.\nThis parameter is mandatory when a PV to be created on the storage side needs to support the NAS HyperMetro feature. In this case, you need to enter the ID of the HyperMetro vStore pair to which the PV to be created belongs.\nConditionally mandatory\n-\nYou can query the HyperMetro vStore pair ID on DeviceManager.\nmetroBackend\nBackend name of the HyperMetro peer. The value is a character string.\nThis parameter is mandatory when a PV to be created on the storage side needs to support the NAS HyperMetro feature. In this case, you need to enter the name of the other backend to form a HyperMetro pair with the current backend.\nConditionally mandatory\n-\nThe names of the two backends in the pair must be entered. After the two backends form a HyperMetro relationship, they cannot form a HyperMetro relationship with other backends.\nsupportedTopologies\nStorage topology awareness configuration. The parameter format is JSON of the list type.\nConditionally mandatory\n-\nThis parameter is mandatory if storage topology awareness is enabled. For details, see Configuring Storage Topology Awareness Using Helm.\nmaxClientThreads\nMaximum number of concurrent connections to a storage backend.\nNo\n30\nIf this parameter is not specified, the default maximum number of connections is 30.\n","categories":"","description":"","excerpt":"An example template of the backend configuration file is …","ref":"/css-docs/en/docs/storage-backend-management/managing-storage-backends/creating-a-storage-backend/storage-backend-parameters/","tags":"","title":"Storage Backend Parameters"},{"body":"Table 1 StorageClass configuration parameters\nParameter\nDescription\nMandatory\nDefault Value\nRemarks\nmetadata.name\nUser-defined name of a StorageClass object.\nYes\n-\nTake Kubernetes v1.22.1 as an example. The value can contain digits, lowercase letters, hyphens (-), and periods (.), and must start and end with a letter or digit.\nprovisioner\nName of the provisioner.\nYes\ncsi.huawei.com\nSet this parameter to the driver name set during Huawei CSI installation.\nThe value is the same as that of driverName in the values.yaml file.\nreclaimPolicy\nReclamation policy. The following types are supported:\nDelete: Resources are automatically reclaimed.Retain: Resources are manually reclaimed. No\nDelete\nDelete: When a PV/PVC is deleted, resources on the storage device are also deleted.Retain: When a PV/PVC is deleted, resources on the storage device are not deleted. allowVolumeExpansion\nWhether to allow volume expansion. If this parameter is set to true, the capacity of the PV that uses the StorageClass can be expanded.\nNo\nfalse\nThis function can only be used to expand PV capacity but cannot be used to reduce PV capacity.\nThe PV capacity expansion function is supported in Kubernetes 1.14 (alpha) and later versions.\nparameters.backend\nName of the backend where the resource to be created is located.\nNo\n-\nIf this parameter is not set, Huawei CSI will randomly select a backend that meets the capacity requirements to create resources.\nYou are advised to specify a backend to ensure that the created resource is located on the expected backend.\nparameters.pool\nName of the storage resource pool where the resource to be created is located. If this parameter is set, parameters.backend must also be specified.\nNo\n-\nIf this parameter is not set, Huawei CSI will randomly select a storage pool that meets the capacity requirements from the selected backend to create resources. You are advised to specify a storage pool to ensure that the created resource is located in the expected storage pool.\nparameters.volumeType\nType of the volume to be created. The following types are supported:\nlun: A LUN is provisioned on the storage side.fs: A file system is provisioned on the storage side.dtree: A volume of the Dtree type is provisioned on the storage side. Yes\n-\nIf NAS storage is used, this parameter must be set to fs.If SAN storage is used, this parameter must be set to lun.If NAS storage of the Dtree type is used, this parameter must be set to dtree. parameters.allocType\nAllocation type of the volume to be created. The following types are supported:\nthin: Not all required space is allocated during creation. Instead, the space is dynamically allocated based on the usage.thick: All required space is allocated during creation. No\n-\nIf this parameter is not specified, thin will be used. Not all required space is allocated during creation. Instead, the space is dynamically allocated based on the usage.\nOceanStor Dorado/OceanStor Dorado V3 does not support thick.\nparameters.fsType\nType of a host file system. The supported types are:\next2ext3ext4xfs No\next4\nThis parameter is valid only when volumeType of a StorageClass is set to lun and volumeMode of a PVC is set to Filesystem.\nparameters.authClient\nIP address of the NFS client that can access the volume. This parameter is mandatory when volumeType is set to fs.\nYou can enter the client host name (a full domain name is recommended), client IP address, or client IP address segment.\nConditionally mandatory\n-\nThe asterisk (*) can be used to indicate any client. If you are not sure about the IP address of the access client, you are advised to use the asterisk (*) to prevent the client access from being rejected by the storage system.\nIf the client host name is used, you are advised to use the full domain name.\nThe IP addresses can be IPv4 addresses, IPv6 addresses, or a combination of IPv4 and IPv6 addresses.\nYou can enter multiple host names, IP addresses, or IP address segments and separate them with semicolons (;) or spaces or by pressing Enter. Example: 192.168.0.10;192.168.0.0/24;myserver1.test\nparameters.cloneSpeed\nCloning speed. The value ranges from 1 to 4.\nNo\n3\n4 indicates the highest speed. This parameter is available when you clone a PVC or create a PVC using a snapshot. For details, see Cloning a PVC or Creating a PVC Using a Snapshot.\nparameters.applicationType\nApplication type name for creating a LUN or NAS when the backend is OceanStor Dorado.\nNo\n-\nIf the value of volumeType is lun, log in to DeviceManager and choose Services \u003e Block Service \u003e LUN Groups \u003e LUNs \u003e Create to obtain the application type name.If the value of volumeType is fs, log in to DeviceManager and choose Services \u003e File Service \u003e File Systems \u003e Create to obtain the application type name. parameters.qos\nLUN/NAS QoS settings of the PV on the storage side.\nThe value of the parameter is JSON character strings in dictionary format. A character string is enclosed by single quotation marks and the dictionary key by double quotation marks. Example: '{\"maxMBPS\": 999, \"maxIOPS\": 999}'\nNo\n-\nFor details about the supported QoS configurations, see Table 2.\nparameters.storageQuota\nQuota of a PV on the storage device. This parameter is valid only when NAS is used for connecting to OceanStor Pacific series storage.\nThe value of the parameter is JSON character strings in dictionary format. A character string is enclosed by single quotation marks and the dictionary key by double quotation marks. Example: '{\"spaceQuota\": \"softQuota\", \"gracePeriod\": 100}'\nNo\n-\nFor details about the supported quota configurations, see Table 3.\nparameters.hyperMetro\nWhether a HyperMetro volume is to be created. This parameter needs to be configured when the backend is of the HyperMetro type.\n\"true\": The created volume is a HyperMetro volume. If the storage backend is a HyperMetro backend, the value must be true.\"false\": The created volume is a common volume. Conditionally mandatory\nfalse\nWhen the used backend is a HyperMetro backend and a HyperMetro volume needs to be provisioned, set this parameter to true. If this parameter is set to false, services may be interrupted if the logical management port connected to the backend fails over.\nparameters.metroPairSyncSpeed\nData synchronization speed of a HyperMetro pair. The value ranges from 1 to 4.\nThe value can be:\n1: low2: medium3: high4: highest No\n-\nThe configuration takes effect when a HyperMetro volume is created.\nNote:\nIf this parameter is not configured, the storage speed of the HyperMetro pair is determined by the storage device.The highest synchronization speed may increase the host latency. parameters.fsPermission\nPermission on the directory mounted to a container.\nNo\n-\nFor details about the configuration format, refer to the Linux permission settings, for example, 777 and 755.\nAll SAN storage devices are supported. Only the following NAS storage devices are supported: OceanStor Dorado, OceanStor, and OceanStor Pacific 8.1.2 and later versions.\nparameters.rootSquash\nControls the root permission of the client.\nThe value can be:\nroot_squash: The client cannot access the storage system as user root. If a client accesses the storage system as user root, the client will be mapped as an anonymous user.no_root_squash: A client can access the storage system as user root and has the permission of user root. No\n-\nOnly NAS storage is supported.\nparameters.allSquash\nWhether to retain the user ID (UID) and group ID (GID) of a shared directory.\nThe value can be:\nall_squash: The UID and GID of the shared directory are mapped to anonymous users.no_all_squash: The UID and GID of the shared directory are retained. No\n-\nOnly NAS storage is supported.\nparameters.accesskrb5\nConfigures the krb5 security protocol.\nread_only: read-onlyread_write: read and writenone: no permission No\n-\nDuring mounting, you can specify the sec parameter in mountOptions.\nparameters.accesskrb5i\nConfigures the krb5i security protocol.\nread_only: read-onlyread_write: read and writenone: no permission No\n-\nDuring mounting, you can specify the sec parameter in mountOptions.\nparameters.accesskrb5p\nConfigures the krb5p security protocol.\nread_only: read-onlyread_write: read and writenone: no permission No\n-\nDuring mounting, you can specify the sec parameter in mountOptions.\nparameters.snapshotDirectoryVisibility\nWhether the snapshot directory is visible.\nThe value can be:\nvisible: The snapshot directory is visible.invisible: The snapshot directory is invisible. No\n-\nOnly NAS storage is supported.\nparameters.reservedSnapshotSpaceRatio\nConfigures reserved snapshot space.\nValue type: character string\nValue range: 0 to 50\nNo\n-\nOceanStor Dorado 6.1.5+ and OceanStor 6.1.5+ NAS storage devices are supported.\nparameters.description\nConfigures the description of the created file system or LUN.\nValue type: character string\nThe value contains 0 to 255 characters.\nNo\n-\nOnly enterprise storage file systems and LUNs are supported.\nmountOptions.nfsvers\nNFS mount option on the host. The following mount option is supported:\nnfsvers: protocol version for NFS mounting. The value can be 3, 4, 4.0, 4.1, or 4.2.\nNo\n-\nThis parameter is optional after the -o parameter when the mount command is executed on the host. The value is in list format.\nIf the NFS version is specified for mounting, NFS 3, 4.0, 4.1, and 4.2 protocols are supported (the protocol must be supported and enabled on storage devices). If nfsvers is set to 4, the latest protocol version NFS 4 may be used for mounting due to different OS configurations, for example, 4.2. If the 4.0 protocol is required, you are advised to set nfsvers to 4.0.\nmountOptions.acl\nThe DPC namespace supports the ACL function. The DPC client supports POSIX ACL, NFSv4 ACL, and NT ACL authentication.\nNo\n-\nThe descriptions of acl, aclonlyposix, cnflush, and cflush are for reference only. For details about the parameters, see OceanStor Pacific Series Product Documentation and choose Configuration \u003e Basic Service Configuration Guide for File \u003e Configuring Basic Services (DPC Scenario) \u003e Accessing a DPC Share on a Client \u003e Step 2.\nmountOptions.aclonlyposix\nThe DPC namespace supports POSIX ACL, and the DPC client supports POSIX ACL authentication.\nThe following protocols support POSIX ACL: DPC, NFSv3, and HDFS. If NFSv4 ACL or NT ACL is used, the DPC client cannot identify the ACL of this type. As a result, the ACL of this type does not take effect.\nNo\n-\nIf aclonlyposix and acl are used together, only acl takes effect. That is, the namespace supports the ACL function.\nmountOptions.cnflush\nAsynchronous disk flushing mode. That is, data is not flushed to disks immediately when files in the namespace are closed.\nNo\n-\nAsynchronous flushing mode: When a file is closed, data in the cache is not flushed to storage media in synchronous mode. Instead, data is written from the cache to the storage media in asynchronous flushing mode. After the write service is complete, data is flushed from the cache to disks periodically based on the flushing period. In a multi-client scenario, if concurrent operations are performed on the same file, the file size update is affected by the disk flushing period. That is, the file size is updated only after the disk flushing is complete. Generally, the update is completed within several seconds. Synchronous I/Os are not affected by the disk flushing period.\nmountOptions.cflush\nSynchronous disk flushing mode. That is, data is flushed to disks immediately when files in the namespace are closed.\nNo\n-\nBy default, the synchronous disk flushing mode is used.\nmountOptions.sec\nKerberos 5 protocol for mounting NFS file systems.\nNo\n-\nIf Kerberos 5 is used, set this parameter to krb5.If Kerberos 5i is used, set this parameter to krb5i.If Kerberos 5p is used, set this parameter to krb5p.Kerberos supports only NFSv4.0 or NFSv4.1. mountOptions.proto\nTransmission protocol used for NFS mounting.\nThe value can be rdma.\nNo\n-\nEnsure that NFS over RDMA is enabled on the storage system.NAS storage of OceanStor Dorado 6.1.7 or later is supported. mountOptions.port\nProtocol port used for NFS mounting.\nConditionally mandatory\n-\nIf the transmission protocol is rdma, set this parameter to 20049.\nmountOptions.discard\nAutomatically triggers the Trim or Discard operation when a file system is mounted. This operation instructs a block device to release unused blocks.\nNo\n-\nThe xfs and ext4 file systems are supported.\nTable 2 Supported QoS configurations\nStorage Type\nParameter\nDescription\nRemarks\nOceanStor V5\nIOTYPE\nRead/write type.\nThis parameter is optional. If it is not specified, the default value of the storage backend is used. For details, see related storage documents.\nThe value can be:\n0: read I/O1: write I/O2: read and write I/Os MAXBANDWIDTH\nMaximum bandwidth. This is a restriction policy parameter.\nThe value is an integer greater than 0, expressed in MB/s.\nMINBANDWIDTH\nMinimum bandwidth. This is a protection policy parameter.\nThe value is an integer greater than 0, expressed in MB/s.\nMAXIOPS\nMaximum IOPS. This is a restriction policy parameter.\nThe value is an integer greater than 0.\nMINIOPS\nMinimum IOPS. This is a protection policy parameter.\nThe value is an integer greater than 0.\nLATENCY\nMaximum latency. This is a protection policy parameter.\nThe value is an integer greater than 0, expressed in ms.\nOceanStor Dorado V3\nIOTYPE\nRead/write type.\nThe value can be:\n2: read and write I/Os MAXBANDWIDTH\nMaximum bandwidth. This is a restriction policy parameter.\nThe value is an integer ranging from 1 to 999999999, expressed in MB/s.\nMAXIOPS\nMaximum IOPS. This is a restriction policy parameter.\nThe value is an integer ranging from 100 to 999999999.\nOceanStor Dorado/OceanStor\nIOTYPE\nRead/write type.\nThe value can be:\n2: read and write I/Os MAXBANDWIDTH\nMaximum bandwidth. This is a restriction policy parameter.\nThe value is an integer ranging from 1 to 999999999, expressed in MB/s.\nMINBANDWIDTH\nMinimum bandwidth. This is a protection policy parameter.\nThe value is an integer ranging from 1 to 999999999, expressed in MB/s.\nMAXIOPS\nMaximum IOPS. This is a restriction policy parameter.\nThe value is an integer ranging from 100 to 999999999.\nMINIOPS\nMinimum IOPS. This is a protection policy parameter.\nThe value is an integer ranging from 100 to 999999999.\nLATENCY\nMaximum latency. This is a protection policy parameter.\nThe value can be 0.5 or 1.5, expressed in ms.\nFusionStorage/OceanStor Pacific series\nmaxMBPS\nMaximum bandwidth. This is a restriction policy parameter.\nThis parameter is mandatory. The value is an integer greater than 0, expressed in MB/s. For details about the maximum value, see the actual limit of the storage device. For example, the maximum value of OceanStor Pacific NAS is 1073741824.\nmaxIOPS\nMaximum IOPS. This is a restriction policy parameter.\nThis parameter is mandatory. The value is an integer greater than 0. For details about the maximum value, see the actual limit of the storage device. For example, the maximum value of OceanStor Pacific NAS is 1073741824000.\nTable 3 Supported quota configurations\nParameter\nDescription\nRemarks\nspaceQuota\nFile quota type.\nThis parameter is mandatory. Only softQuota or hardQuota can be configured.\ngracePeriod\nGrace period allowed when the soft quota is configured.\nThis parameter is conditionally optional only when spaceQuota is set to softQuota.\nThe value is an integer ranging from 0 to 4294967294.\n","categories":"","description":"","excerpt":"Table 1 StorageClass configuration parameters\nParameter\nDescription …","ref":"/css-docs/en/docs/using-huawei-csi/managing-a-pvc/creating-a-pvc/dynamic-volume-provisioning/storageclass-parameters-for-dynamic-volume-provisioning/","tags":"","title":"StorageClass Parameters for Dynamic Volume Provisioning"},{"body":"A StorageClass provides administrators with methods to describe a storage “class”. Different types may map to a different group of capability definitions. Kubernetes cluster users can dynamically provision volumes based on a StorageClass.\nA StorageClass supports the following parameters.\nIf SAN storage is used, refer to example file /examples/sc-lun.yaml. If NAS storage is used, refer to example file /examples/sc-fs.yaml.\nTable 1 StorageClass configuration parameters\nParameter\nDescription\nMandatory\nDefault Value\nRemarks\nmetadata.name\nUser-defined name of a StorageClass object.\nYes\n-\nTake Kubernetes v1.22.1 as an example. The value can contain digits, lowercase letters, hyphens (-), and periods (.), and must start and end with a letter or digit.\nprovisioner\nName of the provisioner.\nYes\ncsi.huawei.com\nSet this parameter to the driver name set during Huawei CSI installation.\nThe value is the same as that of driverName in the values.yaml file.\nreclaimPolicy\nReclamation policy. The following types are supported:\nDelete: Resources are automatically reclaimed.Retain: Resources are manually reclaimed. Yes\n-\nDelete: When a PV/PVC is deleted, resources on the storage device are also deleted.Retain: When a PV/PVC is deleted, resources on the storage device are not deleted. allowVolumeExpansion\nWhether to allow volume expansion. If this parameter is set to true, the capacity of the PV that uses the StorageClass can be expanded.\nNo\nfalse\nThis function can only be used to expand PV capacity but cannot be used to reduce PV capacity.\nThe PV capacity expansion function is supported in Kubernetes 1.14 (alpha) and later versions.\nparameters.backend\nName of the backend where the resource to be created is located.\nNo\n-\nIf this parameter is not set, Huawei CSI will randomly select a backend that meets the capacity requirements to create resources.\nYou are advised to specify a backend to ensure that the created resource is located on the expected backend.\nparameters.volumeType\nType of the volume to be created. The following types are supported:\nlun: A LUN is provisioned on the storage side.fs: A file system is provisioned on the storage side. Yes\n-\nIf NAS storage is used, this parameter must be set to fs.If SAN storage is used, this parameter must be set to lun. parameters.fsType\nType of a host file system. The supported types are:\next2ext3ext4xfs No\next4\nThis parameter is valid only when volumeType of a StorageClass is set to lun and volumeMode of a PVC is set to Filesystem.\nparameters.applicationType\nApplication type name for creating a LUN or NAS when the backend is OceanStor Dorado.\nNOTE: If an application type has been configured before a volume is managed, the value of applicationType must be the same as the configured application type.\nNo\n-\nIf the value of volumeType is lun, log in to DeviceManager and choose Services \u003e Block Service \u003e LUN Groups \u003e LUNs \u003e Create to obtain the application type name.If the value of volumeType is fs, log in to DeviceManager and choose Services \u003e File Service \u003e File Systems \u003e Create to obtain the application type name. parameters.fsPermission\nPermission on the directory mounted to a container.\nNo\n-\nFor details about the configuration format, refer to the Linux permission settings, for example, 777 and 755.\nThis parameter is available when volumeType is set to lun.\nmountOptions.nfsvers\nNFS mount option on the host. The following mount option is supported:\nnfsvers: protocol version for NFS mounting. The value can be 3, 4, 4.0, 4.1, or 4.2.\nNo\n-\nThis parameter is optional after the -o parameter when the mount command is executed on the host. The value is in list format.\nIf the NFS version is specified for mounting, NFS 3, 4.0, 4.1, and 4.2 protocols are supported (the protocol must be supported and enabled on storage devices). If nfsvers is set to 4, the latest protocol version NFS 4 may be used for mounting due to different OS configurations, for example, 4.2. If the 4.0 protocol is required, you are advised to set nfsver:ws to 4.0.\nmountOptions.acl\nThe DPC namespace supports the ACL function. The DPC client supports POSIX ACL, NFSv4 ACL, and NT ACL authentication.\nNo\n-\nThe descriptions of acl, aclonlyposix, cnflush, and cflush are for reference only. For details about the parameters, see OceanStor Pacific Series Product Documentation and choose Configuration \u003e Basic Service Configuration Guide for File \u003e Configuring Basic Services (DPC Scenario) \u003e Accessing a DPC Share on a Client \u003e Step 2.\nmountOptions.aclonlyposix\nThe DPC namespace supports POSIX ACL, and the DPC client supports POSIX ACL authentication.\nThe following protocols support POSIX ACL: DPC, NFSv3, and HDFS. If NFSv4 ACL or NT ACL is used, the DPC client cannot identify the ACL of this type. As a result, the ACL of this type does not take effect.\nNo\n-\nIf aclonlyposix and acl are used together, only acl takes effect. That is, the namespace supports the ACL function.\nmountOptions.cnflush\nAsynchronous disk flushing mode. That is, data is not flushed to disks immediately when files in the namespace are closed.\nNo\n-\nAsynchronous flushing mode: When a file is closed, data in the cache is not flushed to storage media in synchronous mode. Instead, data is written from the cache to the storage media in asynchronous flushing mode. After the write service is complete, data is flushed from the cache to disks periodically based on the flushing period. In a multi-client scenario, if concurrent operations are performed on the same file, the file size update is affected by the disk flushing period. That is, the file size is updated only after the disk flushing is complete. Generally, the update is completed within several seconds. Synchronous I/Os are not affected by the disk flushing period.\nmountOptions.cflush\nSynchronous disk flushing mode. That is, data is flushed to disks immediately when files in the namespace are closed.\nNo\n-\nBy default, the synchronous disk flushing mode is used.\nmountOptions.sec\nKerberos 5 protocol for mounting NFS file systems.\nNo\n-\nIf Kerberos 5 is used, set this parameter to krb5.If Kerberos 5i is used, set this parameter to krb5i.If Kerberos 5p is used, set this parameter to krb5p.Kerberos supports only NFSv4.0 or NFSv4.1. mountOptions.proto\nTransmission protocol used for NFS mounting.\nThe value can be rdma.\nNo\n-\nEnsure that NFS over RDMA is enabled on the storage system.NAS storage of OceanStor Dorado 6.1.7 or later is supported. mountOptions.port\nProtocol port used for NFS mounting.\nConditionally mandatory\n-\nIf the transmission protocol is rdma, set this parameter to 20049.\nmountOptions.discard\nAutomatically triggers the Trim or Discard operation when a file system is mounted. This operation instructs a block device to release unused blocks.\nNo\n-\nThe xfs and ext4 file systems are supported.\n","categories":"","description":"","excerpt":"A StorageClass provides administrators with methods to describe a …","ref":"/css-docs/en/docs/using-huawei-csi/managing-a-pvc/creating-a-pvc/manage-volume-provisioning/storageclass-parameters-for-manage-volume-provisioning/","tags":"","title":"StorageClass Parameters for Manage Volume Provisioning"},{"body":"This section describes how to uninstall Huawei CSI on the CCE or CCE Agile platform. The following uses CCE Agile v22.3.2 as an example.\nProcedure Log in to the CCE Agile platform.\nOn the home page, choose Charts \u003e Releases. The Releases page is displayed.\nSelect a Huawei CSI release and click Uninstall. In the displayed dialog box, click OK.\nUninstall the huawei-csi-host-info object. For details, see Uninstalling the huawei-csi-host-info Object.\nUninstall the webhook resource. For details, see Uninstalling a Webhook Resource.\n(Optional) Uninstall the snapshot-dependent component service. For details, see Uninstalling the Snapshot-Dependent Component Service.\n","categories":"","description":"","excerpt":"This section describes how to uninstall Huawei CSI on the CCE or CCE …","ref":"/css-docs/en/docs/installation-and-deployment/uninstalling-huawei-csi/uninstalling-huawei-csi-using-helm/uninstalling-huawei-csi-on-cce-or-cce-agile/","tags":"","title":"Uninstalling Huawei CSI on CCE or CCE Agile"},{"body":"Prerequisites Huawei CSI of an earlier version is installed using Helm. A Huawei CSI image of a new version has been created and uploaded to the image repository or imported to all nodes by following the instructions provided in Uploading a Huawei CSI Image. Upgrading Huawei CSI If CSI of an earlier version is deployed using Helm, perform the following steps to upgrade Huawei CSI.\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nCopy the CSI component package of the target version to any directory on the master node.\nGo to the helm/esdk working directory. For the directory path, see Table 1.\ncd helm/esdk Run the kubectl apply -f ./crds/backend/ command to update the storage backend CRD.\nkubectl apply -f ./crds/backend/ (Optional) Check snapshot-dependent components by following the instructions provided in Checking Volume Snapshot-Dependent Components. After confirming that the components are correct, run the kubectl apply -f ./crds/snapshot-crds/ –validate=false command to update the snapshot CRD. If controller.snapshot.enabled is set to false or the Kubernetes version is earlier than v1.17, you can skip this step. For details, see Table 2.\nkubectl apply -f ./crds/snapshot-crds/ --validate=false Run the following command to obtain the original service configuration file. helm-huawei-csi indicates the Helm chart name specified during the installation of the earlier version, and huawei-csi indicates the Helm chart namespace specified during the installation of the earlier version.\nhelm get values helm-huawei-csi -n huawei-csi -a \u003e ./update-values.yaml Run the vi update-values.yaml command to open the file obtained in 6, modify the images configuration items, and update the image to the latest version. For details about the parameters to be modified, see Table 1.\nTable 1 images configuration items\nParameter\nDescription\nNew Value\nimages.huaweiCSIService\nhuawei-csi image.\nhuawei-csi:4.5.0\nimages.storageBackendSidecar\nImage used by Huawei backends to manage storageBackendContent resources.\nstorage-backend-sidecar:4.5.0\nimages.storageBackendController\nImage used by Huawei backends to manage storageBackendClaim resources.\nstorage-backend-controller:4.5.0\nimages.huaweiCSIExtender\nhuawei-csi-extender image.\nhuawei-csi-extender:4.5.0\nimages.sidecar.livenessProbe\nlivenessprobe sidecar image.\nk8s.gcr.io/sig-storage/livenessprobe:v2.5.0\nimages.sidecar.provisioner\ncsi-provisioner sidecar image.\nk8s.gcr.io/sig-storage/csi-provisioner:v3.0.0\nimages.sidecar.attacher\ncsi-attacher sidecar image.\nk8s.gcr.io/sig-storage/csi-attacher:v3.4.0\nimages.sidecar.resizer\ncsi-resizer sidecar image.\nk8s.gcr.io/sig-storage/csi-resizer:v1.4.0\nimages.sidecar.snapshotter\ncsi-snapshotter sidecar image.\nk8s.gcr.io/sig-storage/csi-snapshotter:v4.2.1\nimages.sidecar.snapshotController\nsnapshot-controller sidecar image.\nk8s.gcr.io/sig-storage/snapshot-controller:v4.2.1\nimages.sidecar.registrar\ncsi-node-driver-registrar sidecar image.\nk8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.3.0\n(Optional) If you need to update configuration items or add configuration information during the upgrade, modify the configuration information in the update-values.yaml file by referring to Parameters in the values.yaml File of Helm.\nDuring the upgrade, if the update-values.yaml and values.yaml configuration files contain the same configuration item, the configuration in the update-values.yaml file takes effect preferentially.\nRun the following command to upgrade Huawei CSI. In the following command, helm-huawei-csi indicates the specified Helm chart name, huawei-csi indicates the specified Helm chart namespace, and update-values.yaml indicates the file obtained in 6.\nhelm upgrade helm-huawei-csi ./ -n huawei-csi -f ./values.yaml -f ./update-values.yaml After the huawei-csi service is deployed, run the following command to check whether the service is started.\nkubectl get pod -n huawei-csi The following is an example of the command output. If the Pod status is Running, the service is started successfully.\nNAME READY STATUS RESTARTS AGE huawei-csi-controller-6dfcc4b79f-9vjtq 9/9 Running 0 24m huawei-csi-controller-6dfcc4b79f-csphc 9/9 Running 0 24m huawei-csi-node-g6f4k 3/3 Running 0 20m huawei-csi-node-tqs87 3/3 Running 0 20m ","categories":"","description":"","excerpt":"Prerequisites Huawei CSI of an earlier version is installed using …","ref":"/css-docs/en/docs/installation-and-deployment/upgrading-or-rolling-back-huawei-csi/upgrading-or-rolling-back-huawei-csi-using-helm/upgrading-huawei-csi/upgrading-huawei-csi-on-kubernetes-openshift-and-tanzu/","tags":"","title":"Upgrading Huawei CSI on Kubernetes, OpenShift, and Tanzu"},{"body":"Huawei provides the huawei-csi image for users. For details about how to obtain the image file, see Downloading the Huawei CSI Software Package.\nTo use the CSI image on the container management platform, you need to import the CSI image to the cluster in advance using either of the following methods:\n(Recommended) Use Docker to upload the CSI image to the image repository. Manually import the CSI image to all nodes where Huawei CSI needs to be deployed. Uploading an Image to the Image Repository The installation of Huawei CSI depends on the following image files provided by Huawei. Import and upload the image files in sequence. For details about how to obtain the image files, see Downloading the Huawei CSI Software Package.\nhuawei-csi-v4.5.0-arch.tar storage-backend-controller-v4.5.0-arch.tar storage-backend-sidecar-v4.5.0-arch.tar huawei-csi-extender-v4.5.0-arch.tar Prerequisites\nA Linux host with Docker installed is available, and the host can access the image repository.\nProcedure\nRun the docker load -i huawei-csi-v4.5.0-arch.tar command to import the CSI image to the current node.\ndocker load -i huawei-csi-v4.5.0-arch.tar Run the docker tag huawei-csi:4.5.0 repo.huawei.com/huawei-csi:4.5.0 command to add the image repository address to the image tag. repo.huawei.com indicates the image repository address.\ndocker tag huawei-csi:4.5.0 repo.huawei.com/huawei-csi:4.5.0 Run the docker push repo.huawei.com/huawei-csi:4.5.0 command to upload the CSI image to the image repository. repo.huawei.com indicates the image repository address.\ndocker push repo.huawei.com/huawei-csi:4.5.0 You can also use containerd to import and upload the images. For details about how to import and upload images to the CCE or CCE Agile platform, see the user manual of the platform. Uploading an Image to a Local Node If the image has been uploaded to the image repository, skip this section.\nPrerequisites\nThe node has the corresponding Huawei CSI image file. For details about how to obtain the image file, see Downloading the Huawei CSI Software Package. Docker or another container engine has been installed on the node. Procedure\nUse a remote access tool, such as PuTTY, to log in to the node where the image is to be imported through the management IP address.\nCopy the image directory in the Kubernetes CSI component package to any directory on the current node.\nRun the cd image command to go to the image working directory. For details about the tool path, see Table 1.\nRun the following commands in sequence to import all Huawei CSI images in the image directory to the local node. In the commands, name indicates the name of a .tar image package.\nRun the following command using the Docker container engine:\ndocker load -i \u003cname\u003e.tar Run the following command using the containerd container engine:\nctr -n k8s.io image import \u003cname\u003e.tar Run the following command using the Podman container engine:\npodman load -i \u003cname\u003e.tar If another container engine is installed on the node, use the image import command for the corresponding container engine.\n","categories":"","description":"","excerpt":"Huawei provides the huawei-csi image for users. For details about how …","ref":"/css-docs/en/docs/installation-and-deployment/installation-preparations/uploading-a-huawei-csi-image/","tags":"","title":"Uploading a Huawei CSI Image"},{"body":"Viewing Logs of the huawei-csi-controller Service Run the following command to obtain the node where huawei-csi-controller is located.\nkubectl get pod -A -o wide | grep huawei The following is an example of the command output, where IP indicates the node IP address and NODE indicates the node name.\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES huawei-csi-controller-695b84b4d8-tg64l 9/9 Running 0 14s \u003chost1-ip\u003e \u003chost1-name\u003e \u003cnone\u003e \u003cnone\u003e Use a remote access tool, such as PuTTY, to log in to the node where the huawei-csi-controller service resides in the Kubernetes cluster through the management IP address.\nGo to the log directory.\ncd /var/log/huawei Run the following command to view the customized output logs of the container.\nvi huawei-csi-controller Go to the container directory.\ncd /var/log/containers Run the following command to view the standard output logs of the container.\nvi huawei-csi-controller-\u003cname\u003e_huawei-csi_huawei-csi-driver-\u003ccontrainer-id\u003e.log Viewing Logs of the huawei-csi-node Service Run the following command to obtain the node where huawei-csi-node is located.\nkubectl get pod -A -o wide | grep huawei The following is an example of the command output, where IP indicates the node IP address and NODE indicates the node name.\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES huawei-csi-node-g6f7z 3/3 Running 0 14s \u003chost2-ip\u003e \u003chost2-name\u003e \u003cnone\u003e \u003cnone\u003e Use a remote access tool, such as PuTTY, to log in to the node where the huawei-csi-node service resides in the Kubernetes cluster through the management IP address.\nGo to the log directory.\ncd /var/log/huawei Run the following command to view the customized output logs of the container.\nvi huawei-csi-node Go to the container directory.\ncd /var/log/containers Run the following command to view the standard output logs of the container.\nvi huawei-csi-node-\u003cname\u003e_huawei-csi_huawei-csi-driver-\u003ccontrainer-id\u003e.log ","categories":"","description":"","excerpt":"Viewing Logs of the huawei-csi-controller Service Run the following …","ref":"/css-docs/en/docs/common-operations/collecting-information/viewing-huawei-csi-logs/","tags":"","title":"Viewing Huawei CSI Logs"},{"body":"Symptom A Pod is created. After a period of time, the Pod is still in the ContainerCreating state. Check the log information (for details, see Viewing Huawei CSI Logs). The error message “Fibre Channel volume device not found” is displayed.\nRoot Cause Analysis This problem occurs because residual disks exist on the host node. As a result, disks fail to be found when a Pod is created next time.\nSolution or Workaround Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to query information about the node where the Pod resides.\nkubectl get pod -o wide The following is an example of the command output.\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES mypod 0/1 ContainerCreating 0 51s 10.244.1.224 node1 \u003cnone\u003e \u003cnone\u003e Delete the Pod.\nUse a remote access tool, such as PuTTY, to log in to the node1 node in the Kubernetes cluster through the management IP address. node1 indicates the node queried in 2.\nClear the residual drive letters. For details, see Solution or Workaround.\n","categories":"","description":"","excerpt":"Symptom A Pod is created. After a period of time, the Pod is still in …","ref":"/css-docs/en/docs/troubleshooting/pod-issues/when-a-pod-is-created-the-pod-is-in-the-containercreating-state/","tags":"","title":"When a Pod Is Created, the Pod Is in the ContainerCreating State"},{"body":"本章节介绍如何安装华为CSI。\n当前版本华为CSI添加了资源请求和限制，具体详情请参考华为CSI资源管理。\n前提条件 已完成安装前准备。 集群的所有worker节点与待接入的存储设备的业务组网通信正常，iSCSI场景下允许使用ping命令进行连通性校验。 集群的所有worker节点已安装对应协议所需要的软件客户端，如iSCSI客户端、NFS客户端等。 ","categories":"","description":"","excerpt":"本章节介绍如何安装华为CSI。\n当前版本华为CSI添加了资源请求和限制，具体详情请参考华为CSI资源管理。\n前提条件 已完成安装前准备。 集 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%AE%89%E8%A3%85%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"安装华为CSI"},{"body":"本章节介绍如何使用Kubectl查询PVC变更状态，当前华为CSI通过CRD提供以下API。\n查询VolumeModifyClaim 使用kubectl查询VolumeModifyClaim步骤如下。\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令，查询PVC变更。其中 vmc-name 为VolumeModifyClaim资源名称。\nkubectl get volumemodifyclaims \u003cvmc-name\u003e -owide 命令结果示例如下：\nNAME STATUS READY SOURCEKIND SOURCENAME STARTEDAT COMPLETEDAT AGE myvmc Completed 1/1 StorageClass mysc 2024-06-06T03:19:13Z 2024-06-06T03:19:16Z 2m2s 表 1 回显说明\n名称\n说明\nNAME\nVolumeModifyClaim资源名称。\nSTATUS\nVolumeModifyClaim资源状态，可取值如下：\nPending：初始状态。Creating：VolumeModifyClaim完成基本校验，且服务端已经接收变更任务，但是该任务还未执行完成。Completed：所有关联的PVC均完成变更。Rollback：关联的PVC部分完成变更时，用户执行了删除PVC变更操作。Deleting：关联的PVC全部完成变更时，用户执行了删除PVC变更操作。 READY\n完成变更PVC数量/全部待变更PVC数量。\nSOURCEKIND\n数据源类型，例如StorageClass。\nSOURCENAME\n数据源名称，例如StorageClass名称。\nSTARTEDAT\n变更开始时间，指服务端接收该任务并开始处理的时间戳。\nCOMPLETEDAT\n变更完成时间，指所有关联的PVC均完成变更后的时时间戳，仅STATUS为Completed时，存在该值。\nAGE\nVolumeModifyClaim从创建至当前的存活时间。\nVolumeModifyClaim支持使用kubectl查看Events信息，当VolumeModifyClaim无法满足创建要求，或者创建过程中出现错误时，服务端将记录Events信息。参考命令如下：\nkubectl describe volumemodifyclaims local-to-hypermetro 查询VolumeModifyContent VolumeModifyContent由VolumeModifyClaim资源创建，记录了单个PVC的变更详情，使用kubectl查询VolumeModifyContent步骤如下。\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行命令，查询PVC变更。其中myvmc-uid为VolumeModifyContent资源名称。\nkubectl get volumemodifycontents myvmc-uid -owide 命令结果示例如下：\nNAME STATUS MODIFYCLAIMNAME SOURCEVOLUME STARTEDAT COMPLETEDAT AGE myvmc-uid Completed myvmc default/mypvc 2024-06-06T03:19:07Z 2024-06-06T03:19:09Z 36m 表 2 回显说明\n名称\n说明\nNAME\nVolumeModifyContent资源名称，格式为：VolumeModifyClaim名称-关联PVC的UID。\nSTATUS\nVolumeModifyContent资源状态，可取值如下：\nPending：初始状态。Creating：VolumeModifyContent完成基本校验，且服务端已经接收变更任务，但是该任务还未执行完成。Completed：关联的PVC完成变更。Rollback：正在回滚PVC变更。 MODIFYCLAIMNAME\n关联的VolumeModifyClaim名称。\nSOURCEVOLUME\n关联的PVC信息，格式为：命名空间名称/PVC名称。\nSTARTEDAT\nPVC变更开始时间，指服务端接收该任务并开始处理的时间戳。\nCOMPLETEDAT\nPVC变更完成时间，指所有关联的PVC均完成变更后的时时间戳，仅STATUS为Completed时，存在该值。\nAGE\n即VolumeModifyContent从创建至当前的存活时间。\nVolumeModifyContent支持使用kubectl查看Events信息，当VolumeModifyContent无法满足创建要求，或者变更PVC出现错误时，服务端将记录Events信息。参考命令如下：\nkubectl describe volumemodifycontents myvmc-uid ","categories":"","description":"","excerpt":"本章节介绍如何使用Kubectl查询PVC变更状态，当前华为CSI通过CRD提供以下API。\n查询VolumeModifyClaim 使 …","ref":"/css-docs/docs/%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/pvc%E5%8F%98%E6%9B%B4/%E9%85%8D%E7%BD%AEpvc%E5%8F%98%E6%9B%B4/%E6%9F%A5%E8%AF%A2pvc%E5%8F%98%E6%9B%B4/","tags":"","title":"查询PVC变更"},{"body":"请参考查询存储后端节，使用oceanctl命令查询存储后端信息。\n","categories":"","description":"","excerpt":"请参考查询存储后端节，使用oceanctl命令查询存储后端信息。\n","ref":"/css-docs/docs/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%AE%A1%E7%90%86/%E7%AE%A1%E7%90%86%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/%E6%9F%A5%E8%AF%A2%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/","tags":"","title":"查询存储后端"},{"body":"请根据查询存储后端证书所示命令对存储后端证书进行查询。\n","categories":"","description":"","excerpt":"请根据查询存储后端证书所示命令对存储后端证书进行查询。\n","ref":"/css-docs/docs/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%AE%A1%E7%90%86/%E6%96%B0%E5%A2%9E%E8%AF%81%E4%B9%A6%E5%88%B0%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E5%8F%AF%E9%80%89/%E6%9F%A5%E8%AF%A2%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E8%AF%81%E4%B9%A6/","tags":"","title":"查询存储后端证书"},{"body":"现象描述 执行完成Pod的创建操作，一段时间后，Pod的状态仍然处于ContainerCreating，查看具体日志信息（详情请参考如何查看华为CSI日志），报错“Fibre Channel volume device not found”。\n根因分析 该问题是因为在主机节点有磁盘残留，导致下次创建Pod时，查找磁盘失败。\n解决措施或规避方法 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令，查看Pod所在节点信息。\nkubectl get pod -o wide 命令结果示例如下。\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES mypod 0/1 ContainerCreating 0 51s 10.244.1.224 node1 \u003cnone\u003e \u003cnone\u003e 删除Pod。\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的 node1 节点。node1 节点为2中查询的节点。\n移除盘符残留，详情请参考解决措施或规避方法。\n","categories":"","description":"","excerpt":"现象描述 执行完成Pod的创建操作，一段时间后，Pod的状态仍然处于ContainerCreating，查看具体日志信息（详情请参考如何查看 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/pod%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/%E5%88%9B%E5%BB%BApod%E6%97%B6-pod%E7%9A%84%E7%8A%B6%E6%80%81%E4%B8%BAcontainercreating/","tags":"","title":"创建Pod时，Pod的状态为ContainerCreating"},{"body":"本章节介绍如何基于已配置的PVC变更文件创建PVC变更资源。\n仅支持双活AA模式。 如果变更场景为普通卷变更为双活卷，则仅支持变更主站点端存储卷。 创建PVC变更资源期间，请勿使用华为CSI管理PVC。 不支持对同一个PVC创建多个VolumeModifyClaim资源，若存在对目标PVC的多次变更，请在单次变更完成之后再执行。 操作步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令，创建PVC变更。\nkubectl create -f volumemodifyclaim.yaml 参考查询PVC变更查询创建结果。\n","categories":"","description":"","excerpt":"本章节介绍如何基于已配置的PVC变更文件创建PVC变更资源。\n仅支持双活AA模式。 如果变更场景为普通卷变更为双活卷，则仅支持变更主站点端存 …","ref":"/css-docs/docs/%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/pvc%E5%8F%98%E6%9B%B4/%E9%85%8D%E7%BD%AEpvc%E5%8F%98%E6%9B%B4/%E5%88%9B%E5%BB%BApvc%E5%8F%98%E6%9B%B4/%E5%88%9B%E5%BB%BApvc%E5%8F%98%E6%9B%B4%E8%B5%84%E6%BA%90/","tags":"","title":"创建PVC变更资源"},{"body":"在Kubernetes中，卷快照（VolumeSnapshot）是一个存储系统上卷的快照。VolumeSnapshot能力为Kubernetes用户提供了一种标准的方式来在指定时间点复制卷的内容，并且不需要创建全新的卷。 例如，这一功能使得数据库管理员能够在执行编辑或删除之类的修改之前对数据库执行备份。\n本章将介绍如何使用华为CSI创建VolumeSnapshot。为了完成创建VolumeSnapshot，需要完成如下三步：\n检查卷快照依赖组件信息 配置VolumeSnapshotClass 配置VolumeSnapshot ","categories":"","description":"","excerpt":"在Kubernetes中，卷快照（VolumeSnapshot）是一个存储系统上卷的快照。VolumeSnapshot能力 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/%E5%88%9B%E5%BB%BAvolumesnapshot/","tags":"","title":"创建VolumeSnapshot"},{"body":"后端配置文件样例模板为/examples/backend/backend.yaml，该文件为一个示例文件，具体配置项如下表所示：\n表 1 backend配置项说明\n参数\n描述\n必选参数\n默认值\n备注\nstorage\n存储服务类型。\n企业存储提供SAN存储时填写oceanstor-san。企业存储提供NAS存储时填写oceanstor-nas。企业存储提供Dtree类型的NAS存储时填写oceanstor-dtree。分布式存储提供SAN存储时填写fusionstorage-san。分布式存储提供NAS存储时填写fusionstorage-nas。 是\noceanstor-nas\n一个后端只允许提供一种存储服务。如果单套华为存储系统可以同时提供SAN和NAS的存储服务时，可以配置创建多个后端，每个后端使用不同的存储服务类型。\nname\n存储后端名称。支持小写字母、数字和特殊字符\"-\"，且需要以字母或数字开头，最多63个字符。\n是\n-\n请保证存储后端名称唯一。\nnamespace\n命名空间。\n否\n-\n存储后端必须与华为CSI在相同的命名空间中。\nvstoreName\n存储侧的租户名称。当对接后端是OceanStor V5存储，需要在指定租户下发放资源时，需要指定该参数。\n条件必选\n-\n仅对接后端是OceanStor V5且需要支持租户时，需要指定该参数。\naccountName\n存储侧的账户名称。当对接资源是OceanStor Pacific NAS存储，需要在指定账户下发放NAS资源时，需要指定该参数。\n条件必选\n-\n仅对接后端是OceanStor Pacific NAS存储且需要支持账号时，需要指定该参数。\nurls\n存储设备的管理URL。参数格式为列表。支持按照域名或者IP+端口的方式进行配置。仅支持IPv4。\n是\n-\n当对接后端是OceanStor或OceanStor Dorado存储，需要在指定租户下发放资源时，该参数配置为指定租户的逻辑管理端口URL。\npools\n存储设备的存储池。参数格式为列表。\n条件必选\n-\nstorage为oceanstor-dtree时， 可以不填。\nparameters.protocol\n存储协议。参数格式为字符串。\niscsifcrocefc-nvmenfsdpcscsi 是\n-\n使用iscsi时，请确保对接的计算节点已安装iSCSI客户端。使用nfs时，请确保对接的计算节点已安装NFS客户端工具。使用fc-nvme/roce时，请确保对接的计算节点已安装nvme-cli工具，工具版本仅支持1.x且版本不低于1.9。使用dpc时，请确保对接的计算节点已安装DPC客户端，并已在待接入存储上添加为DPC计算节点。使用scsi时，请确保对接的计算节点已安装分布式存储VBS客户端。 parameters.portals\n业务访问端口。节点会使用该端口对存储资源进行读写访问。参数格式为一个列表\niscsi，roce协议支持配置多个端口，nfs协议仅支持配置一个端口，fc、fc-nvme、dpc协议无需配置业务端口，scsi协议的端口形式为字典格式，key为主机名称，value为IP地址，仅支持IPv4。\n条件必选\n-\n使用租户/账户对接后端时，此时portals必须配置为租户/账户所拥有的逻辑端口信息。如果使用nfs协议，支持填写为域名地址。 parameters.ALUA\n存储后端ALUA参数配置。当工作节点使用操作系统原生多路径，且启用了ALUA时，需要进行配置。\n条件必选\n-\n如果主机多路径配置启用了ALUA，请确保后端ALUA配置和主机的ALUA配置一致。\nALUA详细配置请参考通过Helm配置ALUA特性。\nparameters.parentname\n当前存储上的某一个文件系统名称，在此文件系统下创建Dtree。\nstorage为oceanstor-dtree时必选。\n条件必选\n-\n请到DeviceManager文件系统界面查询。\nmetrovStorePairID\n双活租户Pair ID。\n当需要创建PV在存储侧支持NAS双活特性时，该字段必填。此时需要填入待创建的PV所归属的存储侧双活租户Pair ID。\n条件必选\n-\n双活租户Pair ID请到DeviceManager界面查询。\nmetroBackend\n双活对端的后端名称。参数格式为字符串。\n当需要创建PV在存储侧支持NAS双活特性时，该字段必填。此时需要填入准备和当前后端组成双活的另一个后端名称。\n条件必选\n-\n组对的两个后端都必须将对方名称填入。这两个后端组成双活关系后，不允许再和其他后端组成双活关系。\nsupportedTopologies\n存储拓扑感知配置。参数格式为列表类型的JSON。\n条件必选\n-\n如果启用存储拓扑感知，需要配置该参数。具体请参考通过Helm配置存储拓扑感知。\nmaxClientThreads\n同时连接到存储后端的最大连接数。\n否\n30\n如果不配置该参数，则默认最大连接数为30。\n","categories":"","description":"","excerpt":"后端配置文件样例模板为/examples/backend/backend.yaml，该文件为一个示例文件，具体配置项如下表所示：\n表 1 …","ref":"/css-docs/docs/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%AE%A1%E7%90%86/%E7%AE%A1%E7%90%86%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/%E5%88%9B%E5%BB%BA%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E9%85%8D%E7%BD%AE%E9%A1%B9%E8%AF%B4%E6%98%8E/","tags":"","title":"存储后端配置项说明"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/","tags":"","title":"存储后端相关问题"},{"body":"表 1 StorageClass配置参数说明\n参数\n说明\n必选参数\n默认值\n备注\nmetadata.name\n自定义的StorageClass对象名称。\n是\n-\n以Kubernetes v1.22.1为例，支持数字、小写字母、中划线（-）和点（.）的组合，并且必须以字母数字开头和结尾。\nprovisioner\n制备器名称。\n是\ncsi.huawei.com\n该字段需要指定为安装华为CSI时设置的驱动名称。\n取值和values.yaml文件中driverName一致。\nreclaimPolicy\n回收策略。支持如下类型：\nDelete：自动回收资源。Retain：手动回收资源。 否\nDelete\nDelete：删除PV/PVC时会关联删除存储上的资源。Retain：删除PV/PVC时不会删除存储上的资源。 allowVolumeExpansion\n是否允许卷扩展。参数设置为true 时，使用该StorageClass的PV可以进行扩容操作。\n否\nfalse\n此功能仅可用于扩容PV，不能用于缩容PV。\n扩容PV功能在Kubernetes 1.14 (alpha)后才支持。\nparameters.backend\n待创建资源所在的后端名称。\n否\n-\n如果不设置，华为CSI随机选择一个满足容量要求的后端创建资源。\n建议指定后端，确保创建的资源在预期的后端上。\nparameters.pool\n待创建资源所在的存储资源池名称。如果设置，则必须设置parameters.backend。\n否\n-\n如果不设置，华为CSI会在所选后端上随机选择一个满足容量要求的存储池创建资源。建议指定存储池，确保创建的资源在预期的存储池上。\nparameters.volumeType\n待创建卷类型。支持如下类型：\nlun：存储侧发放的资源是LUN。fs：存储侧发放的资源是文件系统。dtree：存储侧发放的资源是Dtree类型的卷 是\n-\n使用NAS存储时，必须配置为fs。使用SAN存储时，必须配置为lun。使用Dtree类型的NAS存储时，必须配置为dtree parameters.allocType\n待创建卷的分配类型。支持如下类型：\nthin：创建时不会分配所有需要的空间，而是根据使用情况动态分配。thick：创建时分配所有需要的空间。 否\n-\n传空相当于传thin，创建时不会分配所有需要的空间，而是根据使用情况动态分配。\nOceanStor Dorado/OceanStor Dorado V3 不支持thick\nparameters.fsType\n主机文件系统类型。支持类型为：\next2ext3ext4xfs 否\next4\n仅当StorageClass的volumeType设置为“lun”，且PVC的volumeMode配置为“Filesystem”时生效。\nparameters.authClient\n可访问该卷的NFS客户端IP地址信息，在指定volumeType为“fs”时必选。\n支持输入客户端主机名称（建议使用全称域名）、客户端IP地址、客户端IP地址段。\n条件必选\n-\n可以使用“*”表示任意客户端。当您不确定访问客户端IP信息时，建议使用“*”防止客户端访问被存储拒绝。\n当使用客户端主机名称时建议使用全称域名。\nIP地址支持IPv4、IPv6地址或两者的混合IP地址。\n可以同时输入多个主机名称、IP地址或IP地址段，以英文分号，空格或按回车键隔开。如示例：\"192.168.0.10;192.168.0.0/24;myserver1.test\"\nparameters.cloneSpeed\n克隆速度。支持配置为1~4。\n否\n3\n4速度最快。配置克隆PVC或从快照创建PVC时生效，参考克隆PVC或从快照创建PVC。\nparameters.applicationType\n后端为OceanStor Dorado存储时，指定创建LUN/NAS时的应用类型名称。\n否\n-\n“volumeType”为“lun”时，在DeviceManager管理界面，选择“服务 \u003e 块服务 \u003e LUN组 \u003e LUN \u003e 创建 \u003e 应用类型”，获取应用类型名称。“volumeType”为“fs”时，在DeviceManager管理界面，选择“服务 \u003e 文件服务 \u003e 文件系统 \u003e 创建 \u003e 应用类型”，获取应用类型名称。 parameters.qos\nPV在存储侧的LUN/NAS的QoS设置。\n配置项值是字典格式的JSON字符串（字符串两边由单引号修饰，字典key由双引号修饰）。如：'{\"maxMBPS\": 999, \"maxIOPS\": 999}'\n否\n-\n支持的QoS配置请参考表2说明。\nparameters.storageQuota\nPV在存储侧配额设置。仅在对接OceanStor Pacific系列存储使用NAS时生效。\n配置项值是字典格式的JSON字符串（字符串两边由单引号修饰，字典key由双引号修饰）。如：'{\"spaceQuota\": \"softQuota\", \"gracePeriod\": 100}'\n否\n-\n支持的配额配置请参考表3说明。\nparameters.hyperMetro\n是否创建双活卷。当使用的后端是双活类型的后端需要配置。\n\"true\"：创建的卷为双活卷。对接存储后端为双活后端时，该值必须为true。\"false\"：创建的卷为普通卷。 条件必选\nfalse\n当使用的后端是双活类型的后端，且需要发放双活卷时，设置该参数为\"true\"，若设置为\"false\"，在后端对接的逻辑管理端口漂移的场景下，有业务中断的风险。\nparameters.metroPairSyncSpeed\n双活Pair同步速率。支持配置为1~4。\n可选值：\n1：低2：中3：高4：最高 否\n-\n配置创建双活卷时生效。\n注意：\n未配置该参数时，双活Pair存储速率由存储决定。最高速率同步时可能导致主机时延增大。 parameters.fsPermission\n挂载到容器内的目录权限。\n否\n-\n配置格式参考Linux权限设置，如“777”、“755”等。\n支持所有的SAN存储，NAS存储仅支持OceanStor Dorado 、OceanStor、OceanStor Pacific 8.1.2及之后版本的存储设备。\nparameters.rootSquash\n用于设置是否允许客户端的root权限。\n可选值：\nroot_squash：表示不允许客户端以root用户访问，客户端使用root用户访问时映射为匿名用户。no_root_squash：表示允许客户端以root用户访问，保留root用户的权限。 否\n-\n仅支持NAS存储。\nparameters.allSquash\n用于设置是否保留共享目录的UID和GID。\n可选值：\nall_squash：表示共享目录的UID和GID映射为匿名用户。no_all_squash：表示保留共享目录的UID和GID。 否\n-\n仅支持NAS存储。\nparameters.accesskrb5\n用于配置krb5安全协议。\nread_only：只读read_write：读写none：无权限 否\n-\n挂载时，可以在mountOptions中指定参数sec。\nparameters.accesskrb5i\n用于配置krb5i安全协议。\nread_only：只读read_write：读写none：无权限 否\n-\n挂载时，可以在mountOptions中指定参数sec。\nparameters.accesskrb5p\n用于配置krb5p安全协议。\nread_only：只读read_write：读写none：无权限 否\n-\n挂载时，可以在mountOptions中指定参数sec。\nparameters.snapshotDirectoryVisibility\n用于设置快照目录是否可见。\n可选值：\nvisible：表示快照目录可见。invisible：表示快照目录不可见。 否\n-\n仅支持NAS存储。\nparameters.reservedSnapshotSpaceRatio\n用于配置快照预留空间。\n参数类型：字符串\n取值范围：\"0\"~\"50\"\n否\n-\n支持OceanStor Dorado 6.1.5+、OceanStor 6.1.5+的NAS存储。\nparameters.description\n用于配置创建的文件系统/LUN的描述信息。\n参数类型：字符串\n长度限制：0-255\n否\n-\n仅支持企业存储文件系统及LUN。\nmountOptions.nfsvers\n主机侧NFS挂载选项。支持如下挂载选项：\nnfsvers：挂载NFS时的协议版本。支持配置的参数值为“3”，“4”，“4.0”，“4.1”和”4.2”。\n否\n-\n在主机执行mount命令时-o参数后的可选选项。列表格式。\n指定NFS版本挂载时，当前支持NFS 3/4.0/4.1/4.2协议（需存储设备支持且开启）。当配置参数为nfsvers=4时，因为操作系统配置的不同，实际挂载可能为NFS 4的最高版本协议，如4.2，当需要使用4.0协议时，建议配置nfsvers=4.0。\nmountOptions.acl\nDPC命名空间支持ACL功能。DPC客户端支持POSIX ACL、NFSv4 ACL、NT ACL的鉴权行为。\n否\n-\nacl、aclonlyposix、cnflush、cflush参数描述仅供参考，详细参数说明请参考《OceanStor Pacific系列 产品文档》 \u003e 配置 \u003e 文件服务基础业务配置指南 \u003e 配置基础业务（DPC场景） \u003e 客户端访问DPC共享 \u003e 步骤2。\nmountOptions.aclonlyposix\nDPC命名空间支持POSIX ACL功能，DPC客户端支持POSIX ACL的鉴权行为。\n支持POSIX ACL的协议有：DPC、NFSv3、HDFS。如使用NFSv4 ACL或NT ACL，会导致DPC客户端无法识别该类型的ACL，从而导致该类型的ACL不会生效。\n否\n-\naclonlyposix与acl参数同时使用时，仅acl参数生效，即命名空间支持ACL功能。\nmountOptions.cnflush\n异步刷盘模式，即关闭命名空间下的文件时不会立即刷盘。\n否\n-\n异步刷盘模式，当文件关闭时不会同步将Cache的数据持久化到存储介质中，而是通过Cache异步刷盘的方式将数据写入存储介质，Cache的后台刷盘将在写业务完成后根据刷盘周期定时刷盘。在多客户端场景下，对同一文件进行并行操作，文件Size的更新会受刷盘周期的影响，即当刷盘动作完成后才会更新文件的Size，更新通常会在数秒内完成。同步I/O不受刷盘周期影响。\nmountOptions.cflush\n同步刷盘模式，即关闭命名空间下的文件时立即刷盘。\n否\n-\n默认使用同步刷盘模式。\nmountOptions.sec\n用于指定Kerberos 5协议挂载NFS文件系统。\n否\n-\n使用Kerberos 5协议时，请配置krb5。使用Kerberos 5i协议时，请配置krb5i。使用Kerberos 5p协议时，请配置krb5p。Kerberos仅支持NFSv4.0或NFSv4.1 mountOptions.proto\n指定NFS挂载时使用的传输协议。\n支持配置参数值为：“rdma”。\n否\n-\n确保存储系统已启用NFS over RDMA。支持OceanStor Dorado 6.1.7及以上的NAS存储。 mountOptions.port\n指定NFS挂载时使用的协议端口。\n条件必选\n-\n传输协议方式使用“rdma”时，请设置为：20049。\nmountOptions.discard\n挂载文件系统时自动触发Trim/Discard操作。该操作会通知块设备释放未使用的块。\n否\n-\n支持xfs、ext4文件系统。\n表 2 支持的QoS配置\n存储类型\n参数名\n参数描述\n备注\nOceanStor V5\nIOTYPE\n控制读写类型。\n可选参数（未明确指定将使用后端存储默认值，具体参考相关存储资料）。\n有效值如下：\n0：读I/O1：写I/O2：读写I/O MAXBANDWIDTH\n最大带宽限制策略。\n单位MB/s，有效值为\u003e0的整数。\nMINBANDWIDTH\n最小带宽保护策略。\n单位MB/s，有效值为\u003e0的整数。\nMAXIOPS\n最大IOPS限制策略。\n有效值为\u003e0的整数。\nMINIOPS\n最小IOPS保护策略。\n有效值为\u003e0的整数。\nLATENCY\n最大时延保护策略。\n单位ms，有效值为\u003e0的整数。\nOceanStor Dorado V3\nIOTYPE\n控制读写类型。\n有效值如下：\n2：读写I/O MAXBANDWIDTH\n最大带宽限制策略。\n单位MB/s，整数， 范围1~999999999。\nMAXIOPS\n最大IOPS限制策略。\n类型为整数， 范围100~999999999。\nOceanStor Dorado/OceanStor\nIOTYPE\n控制读写类型。\n有效值如下：\n2：读写I/O MAXBANDWIDTH\n最大带宽限制策略。\n单位MB/s，类型为整数， 范围1~999999999。\nMINBANDWIDTH\n最小带宽保护策略。\n单位MB/s，类型为整数， 范围1~999999999。\nMAXIOPS\n最大IOPS限制策略。\n类型为整数， 范围100~999999999。\nMINIOPS\n最小IOPS保护策略。\n类型为整数， 范围100~999999999。\nLATENCY\n最大时延保护策略。\n单位ms，仅支持配置0.5或1.5。\nFusionStorage/OceanStor Pacific系列\nmaxMBPS\n最大带宽限制策略。\n必填。有效值为大于0的整数，单位MB/s。最大值请参考存储设备实际限制，如OceanStor Pacific NAS最大值为1073741824。\nmaxIOPS\n最大IOPS限制策略。\n必填。有效值为大于0的整数。最大值请参考存储设备实际限制，如OceanStor Pacific NAS最大值为1073741824000。\n表 3 支持的配额配置\n参数名\n参数描述\n备注\nspaceQuota\n文件配额类型。\n必选。仅支持配置“softQuota”或者“hardQuota”。\ngracePeriod\n配置软配额时，允许的超限天数。\n条件可选，当“spaceQuota”配置为“softQuota”时可选。\n类型为整数，支持范围为0～4294967294。\n","categories":"","description":"","excerpt":"表 1 StorageClass配置参数说明\n参数\n说明\n必选参数\n默认值\n备注\nmetadata.name\n自定义 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/pvc%E7%AE%A1%E7%90%86/%E5%88%9B%E5%BB%BApvc/%E5%8A%A8%E6%80%81%E5%8D%B7%E4%BE%9B%E5%BA%94/%E5%8A%A8%E6%80%81%E5%8D%B7%E4%BE%9B%E5%BA%94storageclass%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E/","tags":"","title":"动态卷供应StorageClass参数说明"},{"body":"容器存储接口（Container Storage Interface），简称 CSI，是一种行业标准，用于将块和文件存储系统暴露给 Kubernetes 等容器编排系统 (CO) 上的容器工作负载。华为CSI插件用于和华为企业存储和分布式存储产品进行通信，为Kubernetes的容器工作负载提供存储服务。是华为企业存储和分布式存储在Kubernetes环境中使用的必须插件。\nKubernetes通过其官方维护的一系列sidecar组件负责注册监听Kubernetes对象资源，并在需要的时候通过gRPC发起对CSI Driver调用，华为CSI Driver将sidecar发起的调用在华为存储上实施，如创建一个持久卷（Persistent Volume，PV）的操作被实施为在华为存储上创建一个LUN/文件系统。Kubernetes、华为CSI以及华为存储的整体结构如下图所示：\n图 1 CSI整体架构\n华为CSI主要有两大组件，分别为huawei-csi-controller和huawei-csi-node：\nhuawei-csi-controller：包含Controller Service和Identity Service，以Deployment方式运行的一个或多个Pod，主要负责与华为存储交互，使用RESTful方式进行通信，因此运行huawei-csi-controller组件的节点需要连通存储的管理面网络。 huawei-csi-node：包含Node Service和Identity Service，以DaemonSet方式运行在Kubernetes工作节点上的Pod，用于在工作节点上对华为存储提供的LUN/文件系统资源进行挂载和卸载等操作，因此运行huawei-csi-node组件的节点需要连通存储的业务面网络。 华为CSI的部署模型如下所示：\n图 2 CSI部署模型\n本文档主要介绍华为CSI V4.5.0插件的安装部署和使用。\n","categories":"","description":"","excerpt":"容器存储接口（Container Storage Interface），简称 CSI，是一种行业标准， …","ref":"/css-docs/docs/%E6%A6%82%E8%BF%B0/","tags":"","title":"概述"},{"body":"如果您从2.x和3.x版本的CSI升级至4.5.0版本失败，需要回退时，请参考Helm卸载华为CSI卸载CSI，然后下载安装升级之前版本的CSI。\n在升级/回退过程中，已经存在的PVC/快照/Pod等资源会正常运行，不会影响您的业务访问。 在升级/回退过程中，不能使用华为CSI创建新的资源，或者对已有的PVC做挂载/卸载操作。 在升级/回退过程中，请勿卸载Snapshot依赖组件服务。 ","categories":"","description":"","excerpt":"如果您从2.x和3.x版本的CSI升级至4.5.0版本失败，需要回退时，请参考Helm卸载华为CSI卸载CSI，然后下载安装升级之前版本 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E4%BD%BF%E7%94%A8helm%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"回退华为CSI"},{"body":"请参考手动卸载华为CSI卸载CSI，然后下载安装升级之前版本的CSI。\n在升级/回退过程中，已经存在的PVC/快照/Pod等资源会正常运行，不会影响您的业务访问。 在升级/回退过程中，不能使用华为CSI创建新的资源，或者对已有的PVC做挂载/卸载操作。 在升级/回退过程中，请勿卸载Snapshot依赖组件服务。 前提条件 已下载原版本CSI的软件包。\n操作步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。 参考手动卸载华为CSI卸载CSI。 参考手动安装华为CSI重新安装原版本的CSI。 ","categories":"","description":"","excerpt":"请参考手动卸载华为CSI卸载CSI，然后下载安装升级之前版本的CSI。\n在升级/回退过程中，已经存在的PVC/快照/Pod等资源会正常运行， …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E6%89%8B%E5%8A%A8%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80/%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi-1/","tags":"","title":"回退华为CSI"},{"body":"表 1 PVC参数说明\n参数\n说明\n必选参数\n默认值\n备注\nmetadata.name\n自定义的PVC对象名称。\n是\n-\n以Kubernetes v1.22.1为例，支持数字、小写字母、中划线（-）和点（.）的组合，并且必须以字母数字开头和结尾。\nspec.accessModes\n指定卷访问模式。\nRWO（ReadWriteOnce）：卷可以被一个节点以读写方式挂载。 该模式也允许运行在同一节点上的多个 Pod 访问卷。ROX（ReadOnlyMany）：卷可以被多个节点以只读方式挂载。RWX（ReadWriteMany）：卷可以被多个节点以读写方式挂载。RWOP（ReadWriteOncePod）：卷只能被单个 Pod 以读写方式挂载。该特性需要 Kubernetes 1.22 以上版本。 是\nReadWriteOnce\nRWO/ROX/RWOP：所有类型卷均支持，RWOP需Kubernetes 1.22版本以上支持。请参考开启ReadWriteOncePod功能门章节，检查您的Kubernetes集群是否开启该特性。RWX支持情况如下：NAS存储：所有卷均支持。SAN存储：仅volumeMode设置为Block的卷支持。 spec.volumeMode\n卷模式。\n否\nFilesystem\n可选， 支持Filesystem或Block， 默认为Filesystem。该参数在创建Pod时生效，其中Filesystem表示在PVC上创建一个文件系统访问存储， Block表示使用裸卷的方式访问存储。\nspec.resources.requests.storage\n指定待创建卷大小。\n是\n-\n指定待创建卷大小，格式为***Gi，单位为GiB。\nPVC容量的规格取决于存储规格限制和主机规格限制。以OceanStor Dorado 6.1.2/OceanStor Pacific系列 8.1.0对接CentOS 7为例，当使用的是ext4文件系统时，容量限制见表 ext4容量的规格；当使用的是XFS文件系统时，容量限制见表 XFS容量的规格。如果使用的是NFS或者裸设备，容量需满足使用的华为存储设备型号和版本所要求的规格约束。\n如果PVC容量不在规格范围内，可能会由于存储规格限制或主机文件系统规格限制导致创建PVC或Pod失败。\n在通过静态PV创建PVC时，若PVC容量小于绑定PV容量，最终PVC容量大小为绑定PV容量，若PVC容量大于绑定PV容量，PVC将无法被创建。\nspec.volumeName\nPV对象名称。\n是\n-\n静态创建PVC时必选。\nspec.storageClassName\nStorageClass对象名称。\n是\n-\n创建PVC时传空字符串，不设置该参数会使用默认的StorageClass对象名称。\n","categories":"","description":"","excerpt":"表 1 PVC参数说明\n参数\n说明\n必选参数\n默认值\n备注\nmetadata.name\n自定义的PVC对象名称。\n是\n-\n …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/pvc%E7%AE%A1%E7%90%86/%E5%88%9B%E5%BB%BApvc/%E9%9D%99%E6%80%81%E5%8D%B7%E4%BE%9B%E5%BA%94/%E9%9D%99%E6%80%81%E5%8D%B7%E4%BE%9B%E5%BA%94pvc%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E/","tags":"","title":"静态卷供应PVC参数说明"},{"body":"当容器使用的PVC容量不足时，需要对该PVC进行扩容操作。\n前提条件 PVC已创建，所在的backend存在且支持扩容。\n支持扩容的存储请参考表 华为企业存储支持的特性及约束和表 华为分布式存储支持的特性及约束，支持扩容的Kubernetes版本请参考Kubernetes特性矩阵。\nhuawei-csi-controller启用了csi-resizer服务。\nkubectl describe deploy huawei-csi-controller -n huawei-csi | grep csi-resizer 命令回显示例如下则说明已启用csi-resizer服务。\ncsi-resizer: Image: k8s.gcr.io/sig-storage/csi-resizer:v1.4.0 操作步骤 执行命令，查询StorageClass是否支持扩容。其中，mysc 为需要查看的StorageClass名称。\nkubectl get sc mysc 命令结果示例如下：\nNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE mysc csi.huawei.com Delete Immediate true 172m 如果ALLOWVOLUMEEXPANSION的值为true，表示当前StorageClass已经支持扩容，请跳转至步骤3。\n执行以下命令，将“allowVolumeExpansion“的值修改为“true“。其中，mysc 为需要修改的StorageClass名称。\nkubectl patch sc mysc --patch '{\"allowVolumeExpansion\":true}' 执行命令，查询PVC的StorageClass名称。其中，mypvc 为需要扩容的PVC名称。\nkubectl get pvc mypvc 命令结果示例如下：\nNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE mypvc Bound pvc-3383be36-537c-4cb1-8f32-a415fa6ba384 2Gi RW0 mysc 145m 执行以下命令进行扩容。\nkubectl patch pvc mypvc -p '{\"spec\":{\"resources\":{\"requests\":{\"storage\":\"120Gi\"}}}}' 其中，\"mypvc“是需要扩容的PVC名称，“120Gi”是扩容后的容量大小。请根据实际情况进行替换。\nPVC容量的规格取决于存储规格限制和主机规格限制。以OceanStor Dorado 6.1.2/OceanStor Pacific系列 8.1.0对接CentOS 7为例，当使用的是ext4文件系统时，容量限制见表 ext4容量的规格；当使用的是XFS文件系统时，容量限制见表 XFS容量的规格。如果使用的是NFS或者裸设备，容量需满足使用的华为存储设备型号和版本所要求的规格约束。 如果PVC容量不在规格范围内，可能会由于存储规格限制或主机文件系统规格限制导致创建PVC或Pod失败。 如果扩容的目标容量超过存储池容量导致扩容失败，请参考PVC扩容的目标容量超过存储池容量导致扩容失败。 执行命令，检查容量修改是否生效。\nkubectl get pvc 命令结果示例如下，如果CAPACITY字段已变更为指定容量，说明扩容成功。\nNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE mypvc Bound pvc-3383be36-537c-4cb1-8f32-a415fa6ba384 120Gi RWO mysc 24s ","categories":"","description":"","excerpt":"当容器使用的PVC容量不足时，需要对该PVC进行扩容操作。\n前提条件 PVC已创建，所在的backend存在且支持扩容。\n支持扩容的存储请参 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/pvc%E7%AE%A1%E7%90%86/%E6%89%A9%E5%AE%B9pvc/","tags":"","title":"扩容PVC"},{"body":"纳管卷供应（Manage Volume Provisioning）允许管理员使用已经在存储侧创建的资源做为PV，并能够支持动态卷的特性，例如：扩容，快照，克隆等，属于华为CSI自定义能力。使用该特性可满足如下场景：\n容器化应用的改造场景，需要使用已有的存储卷。 重建Kubernetes集群。 容灾场景下，对存储数据进行迁移。 在多Kubernetes集群场景下，使用纳管卷特性对同一存储资源进行管理时，在任一集群中对该资源对应的PVC进行管理操作后，不会同步到其他集群中。 例如：在某一集群中对PVC进行扩容时，其他集群对应的PVC不会自动扩容，需要在其他集群中手动根据扩容PVC中的扩容命令进行扩容。\n前提条件 已在CSI中注册需要纳管卷所在存储。 已登录存储设备获取需要纳管卷的名称和容量。 配置StorageClass 根据业务需要，参考动态卷供应典型场景StorageClass配置示例和动态卷供应StorageClass参数说明，创建StorageClass配置文件，如本例从的mysc.yaml文件。\n执行命令，使用配置文件创建StorageClass。\nkubectl apply -f mysc.yaml 执行命令，查看已创建的StorageClass信息。\nkubectl get sc mysc 命令结果示例如下：\nNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE mysc csi.huawei.com Delete Immediate true 8s 配置PVC 根据业务需要，参考本节描述和PVC配置文件示例，修改具体参数，生成本次需要创建的PVC配置文件，如本例中mypvc.yaml文件。\nkind: PersistentVolumeClaim apiVersion: v1 metadata: name: mypvc annotations: csi.huawei.com/manageVolumeName: \"*\" # 存储资源名称 csi.huawei.com/manageBackendName: \"*\" # 存储后端名称 labels: provisioner: csi.huawei.com spec: accessModes: - ReadWriteOnce volumeMode: Filesystem storageClassName: mysc resources: requests: storage: 100Gi 执行命令，使用配置文件创建PVC。\nkubectl create -f mypvc.yaml 等待一段时间后，执行以下命令，查看已经创建的PVC信息。\nkubectl get pvc mypvc 命令结果示例如下。如果PVC的状态是“Bound”时，则说明该PVC已经创建成功，后续可以被Pod使用。\nNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE mypvc Bound pvc-840054d3-1d5b-4153-b73f-826f980abf9e 100Gi RWO mysc 12s 完成创建PVC操作后，如果长时间后（如一分钟后）PVC的状态是Pending，请参考创建PVC时， PVC的状态为Pending。 建议每批次最多批量创建/删除100个PVC。 使用PVC 与动态卷供应使用PVC方式相同。\n","categories":"","description":"","excerpt":"纳管卷供应（Manage Volume Provisioning）允许管理员使用已经在存储侧创建的资源做为PV，并能够支持动态卷的特性，例 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/pvc%E7%AE%A1%E7%90%86/%E5%88%9B%E5%BB%BApvc/%E7%BA%B3%E7%AE%A1%E5%8D%B7%E4%BE%9B%E5%BA%94/","tags":"","title":"纳管卷供应"},{"body":"存储类（StorageClass）为管理员提供了描述存储 “类” 的方法。 不同的类型可能会映射到一组不同的能力定义。Kubernetes集群用户可基于StorageClass进行动态卷制备。\nStorageClass支持配置如下参数信息。\n使用SAN存储时可参考示例文件/examples/sc-lun.yaml，使用NAS存储时可参考示例文件/examples/sc-fs.yaml。\n表 1 StorageClass配置参数说明\n参数\n说明\n必选参数\n默认值\n备注\nmetadata.name\n自定义的StorageClass对象名称。\n是\n-\n以Kubernetes v1.22.1为例，支持数字、小写字母、中划线（-）和点（.）的组合，并且必须以字母数字开头和结尾。\nprovisioner\n制备器名称。\n是\ncsi.huawei.com\n该字段需要指定为安装华为CSI时设置的驱动名。\n取值和values.yaml文件中driverName一致。\nreclaimPolicy\n回收策略。支持如下类型：\nDelete：自动回收资源。Retain：手动回收资源。 是\n-\nDelete：删除PV/PVC时会关联删除存储上的资源。Retain：删除PV/PVC时不会删除存储上的资源。 allowVolumeExpansion\n是否允许卷扩展。参数设置为true 时，使用该StorageClass的PV可以进行扩容操作。\n否\nfalse\n此功能仅可用于扩容PV，不能用于缩容PV。\n扩容PV功能在Kubernetes 1.14 (alpha)后才支持。\nparameters.backend\n待创建资源所在的后端名称。\n否\n-\n如果不设置，华为CSI随机选择一个满足容量要求的后端创建资源。\n建议指定后端，确保创建的资源在预期的后端上。\nparameters.volumeType\n待创建卷类型。支持如下类型：\nlun：存储侧发放的资源是LUN。fs：存储侧发放的资源是文件系统。 是\n-\n使用NAS存储时，必须配置为fs。使用SAN存储时，必须配置为lun。 parameters.fsType\n主机文件系统类型。支持类型为：\next2ext3ext4xfs 否\next4\n仅当StorageClass的volumeType设置为“lun”，且PVC的volumeMode配置为“Filesystem”时生效。\nparameters.applicationType\n后端为OceanStor Dorado存储时，指定创建LUN/NAS时的应用类型名称。\n说明： 若卷纳管前已配置应用类型，applicationType必须与已配置的应用类型保持一致。\n否\n-\n“volumeType”为“lun”时，在DeviceManager管理界面，选择“服务 \u003e 块服务 \u003e LUN组 \u003e LUN \u003e 创建 \u003e 应用类型”，获取应用类型名称。“volumeType”为“fs”时，在DeviceManager管理界面，选择“服务 \u003e 文件服务 \u003e 文件系统 \u003e 创建 \u003e 应用类型”，获取应用类型名称。 parameters.fsPermission\n挂载到容器内的目录权限。\n否\n-\n配置格式参考Linux权限设置，如“777”、“755”等。\n当volumeType为lun时，支持配置该字段。\nmountOptions.nfsvers\n主机侧NFS挂载选项。支持如下挂载选项：\nnfsvers：挂载NFS时的协议版本。支持配置的参数值为“3”，“4”，“4.0”，“4.1”和”4.2”。\n否\n-\n在主机执行mount命令时-o参数后的可选选项。列表格式。\n指定NFS版本挂载时，当前支持NFS 3/4.0/4.1/4.2协议（需存储设备支持且开启）。当配置参数为nfsvers=4时，因为操作系统配置的不同，实际挂载可能为NFS 4的最高版本协议，如4.2，当需要使用4.0协议时，建议配置nfsver:ws=4.0。\nmountOptions.acl\nDPC命名空间支持ACL功能。DPC客户端支持POSIX ACL、NFSv4 ACL、NT ACL的鉴权行为。\n否\n-\nacl、aclonlyposix、cnflush、cflush参数描述仅供参考，详细参数说明请参考《OceanStor Pacific系列 产品文档》 \u003e 配置 \u003e 文件服务基础业务配置指南 \u003e 配置基础业务（DPC场景） \u003e 客户端访问DPC共享 \u003e 步骤2。\nmountOptions.aclonlyposix\nDPC命名空间支持POSIX ACL功能，DPC客户端支持POSIX ACL的鉴权行为。\n支持POSIX ACL的协议有：DPC、NFSv3、HDFS。如使用NFSv4 ACL或NT ACL，会导致DPC客户端无法识别该类型的ACL，从而导致该类型的ACL不会生效。\n否\n-\naclonlyposix与acl参数同时使用时，仅acl参数生效，即命名空间支持ACL功能。\nmountOptions.cnflush\n异步刷盘模式，即关闭命名空间下的文件时不会立即刷盘。\n否\n-\n异步刷盘模式，当文件关闭时不会同步将Cache的数据持久化到存储介质中，而是通过Cache异步刷盘的方式将数据写入存储介质，Cache的后台刷盘将在写业务完成后根据刷盘周期定时刷盘。在多客户端场景下，对同一文件进行并行操作，文件Size的更新会受刷盘周期的影响，即当刷盘动作完成后才会更新文件的Size，更新通常会在数秒内完成。同步I/O不受刷盘周期影响。\nmountOptions.cflush\n同步刷盘模式，即关闭命名空间下的文件时立即刷盘。\n否\n-\n默认使用同步刷盘模式。\nmountOptions.sec\n用于指定Kerberos 5协议挂载NFS文件系统。\n否\n-\n使用Kerberos 5协议时，请配置krb5。使用Kerberos 5i协议时，请配置krb5i。使用Kerberos 5p协议时，请配置krb5p。Kerberos仅支持NFSv4.0或NFSv4.1 mountOptions.proto\n指定NFS挂载时使用的传输协议。\n支持配置参数值为：“rdma”。\n否\n-\n确保存储系统已启用NFS over RDMA。支持OceanStor Dorado 6.1.7及以上的NAS存储 mountOptions.port\n指定NFS挂载时使用的协议端口。\n条件必选\n-\n传输协议方式使用“rdma”时，请设置为：20049。\nmountOptions.discard\n挂载文件系统时自动触发Trim/Discard操作。该操作会通知块设备释放未使用的块。\n否\n-\n支持xfs、ext4文件系统。\n","categories":"","description":"","excerpt":"存储类（StorageClass）为管理员提供了描述存储 “类” 的方法。 不同的类型可能会映射到一组不同的能力定义。Kubernetes集 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/pvc%E7%AE%A1%E7%90%86/%E5%88%9B%E5%BB%BApvc/%E7%BA%B3%E7%AE%A1%E5%8D%B7%E4%BE%9B%E5%BA%94/%E7%BA%B3%E7%AE%A1%E5%8D%B7%E4%BE%9B%E5%BA%94storageclass%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E/","tags":"","title":"纳管卷供应StorageClass参数说明"},{"body":"PVC变更特性使用CRD实现，当前资源说明如下。\n表 1 资源说明\nNAME\nAPIVERSION\nNAMESPACED\nKIND\nvolumemodifyclaims\nxuanwu.huawei.io/v1\nfalse\nVolumeModifyClaim\nvolumemodifycontents\nxuanwu.huawei.io/v1\nfalse\nVolumeModifyContent\nVolumeModifyClaim资源支持创建/删除/查询，不支持更新。 VolumeModifyContent资源仅支持查询，用于展示单个PVC变更详情，请勿手动创建/删除/修改。 VolumeModifyContent资源被VolumeModifyClaim管理，请勿手动管理VolumeModifyContent资源。 ","categories":"","description":"","excerpt":"PVC变更特性使用CRD实现，当前资源说明如下。\n表 1 资源说明\nNAME\nAPIVERSION\nNAMESPACED\nKIND …","ref":"/css-docs/docs/%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/pvc%E5%8F%98%E6%9B%B4/%E9%85%8D%E7%BD%AEpvc%E5%8F%98%E6%9B%B4/","tags":"","title":"配置PVC变更"},{"body":"卷快照类（VolumeSnapshotClass）提供了一种在配置VolumeSnapshot时描述存储“类”的方法。每个VolumeSnapshotClass都包含“driver”、“deletionPolicy” 和“parameters”字段， 在需要动态配置属于该类的VolumeSnapshot时使用。\nVolumeSnapshotClass对象的名称很重要，是用户可以请求特定类的方式。 管理员在首次创建VolumeSnapshotClass对象时设置类的名称和其他参数， 对象一旦创建就无法更新。\n华为CSI使用的VolumeSnapshotClass示例如下：\n如果您的环境中api-versions支持v1，请使用以下示例：\napiVersion: snapshot.storage.k8s.io/v1 kind: VolumeSnapshotClass metadata: name: mysnapclass driver: csi.huawei.com deletionPolicy: Delete 如果您的环境中api-versions支持v1beta1，请使用以下示例：\napiVersion: snapshot.storage.k8s.io/v1beta1 kind: VolumeSnapshotClass metadata: name: mysnapclass driver: csi.huawei.com deletionPolicy: Delete 如果您的环境中api-versions同时支持v1和v1beta1，我们推荐您使用v1版本。\n实际参数可以参考表 VolumeSnapshotClass参数说明中的说明修改。由于当前华为CSI还不支持在VolumeSnapshotClass中设置自定义参数（parameters），因此建议只创建一个VolumeSnapshotClass，供所有快照使用。\n表 1 VolumeSnapshotClass参数说明\n参数\n说明\n备注\nmetadata.name\n自定义的VolumeSnapshotClass对象名称。\n以Kubernetes v1.22.1为例，支持数字、小写字母、中划线（-）和点（.）的组合，并且必须以字母数字字符开头和结尾。\ndriver\ndriver标识。必填参数。\n该字段需要指定为安装华为CSI时设置的驱动名。默认的驱动名为“csi.huawei.com”。\ndeletionPolicy\n快照删除策略。必填参数。可选值为：\nDeleteRetain 如果删除策略是 Delete，那么存储设备上的快照会和VolumeSnapshotContent对象一起删除如果删除策略是Retain，那么存储设备上的快照和VolumeSnapshotContent对象都会被保留。 前提条件 华为CSI支持快照且运行所依赖的卷快照组件CRD已经安装。具体CRD信息请参考检查卷快照依赖组件章节说明，支持创建VolumeSnapshot的Kubernetes版本请参考表 Kubernetes版本与支持的特性。\n操作步骤 执行以下命令，使用已经创建的VolumeSnapshotClass配置文件创建VolumeSnapshotClass。\nkubectl create -f mysnapclass.yaml 执行以下命令，查看已创建的VolumeSnapshotClass信息。\nkubectl get volumesnapshotclass 命令结果示例如下：\nNAME DRIVER DELETIONPOLICY AGE mysnapclass csi.huawei.com Delete 25s ","categories":"","description":"","excerpt":"卷快照类（VolumeSnapshotClass）提供了一种在配置VolumeSnapshot时描述存储“类”的方法。每 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/%E5%88%9B%E5%BB%BAvolumesnapshot/%E9%85%8D%E7%BD%AEvolumesnapshotclass/","tags":"","title":"配置VolumeSnapshotClass"},{"body":"在Kubernetes集群中，可以根据节点的拓扑标签以及存储后端支持的拓扑能力调度和发放资源。\n前提条件 需要在集群中的worker节点完成拓扑的标签配置，标签配置方法如下：\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令，查看当前集群中的worker节点信息。\nkubectl get node 命令结果示例如下：\nNAME STATUS ROLES AGE VERSION node01 Ready controlplane,etcd,worker 42d v1.22.3 node02 Ready worker 42d v1.22.3 node03 Ready worker 42d v1.22.3 执行以下命令，给worker节点配置拓扑标签。其中 nodename 为worker节点名称, key 和 value 参数说明请参考表 参数说明。\nkubectl label node \u003cnodename\u003e \u003ckey\u003e=\u003cvalue\u003e 表 1 参数说明\n参数名\n参数描述\n备注\n\u003ckey\u003e\n拓扑标签的唯一标识。\n可支持配置：zone，region，protocol.\u003cprotocol\u003e\n其中\u003cprotocol\u003e可支持配置iscsi, nfs, fc, roce。\n\u003cvalue\u003e\n拓扑标签的参数值。\n“key”如果是“zone”，“region”，“value”值为自定义参数。\n“key”如果是protocol.\u003cprotocol\u003e， “value”值固定为“csi.huawei.com”。\n拓扑标签必须以topology.kubernetes.io开头。拓扑标签示例： 示例1：topology.kubernetes.io/region=China-west 示例2：topology.kubernetes.io/zone=ChengDu 示例3：topology.kubernetes.io/protocol.iscsi=csi.huawei.com 示例4：topology.kubernetes.io/protocol.fc=csi.huawei.com 同一节点上拓扑标签中同一个key只能支持一个value值。 如果同一节点上拓扑标签中同时配置多个protocol，配置StorageClass时，StorageClass只需要满足其中一个protocol即可。 如果同一节点上拓扑标签中同时配置region和zone，配置StorageClass时，StorageClass需要满足全部筛选条件。 执行命令， 查看当前集群中所有worker节点的标签信息。\nkubectl get nodes -o=jsonpath='{range .items[*]}[{.metadata.name}, {.metadata.labels}]{\"\\n\"}{end}' | grep --color \"topology.kubernetes.io\" 命令结果示例如下：\n[node01,\"beta.kubernetes.io/arch\":\"amd64\",\"beta.kubernetes.io/os\":\"linux\",\"kubernetes.io/arch\":\"amd64\",\"kubernetes.io/hostname\":\"node01\",\"kubernetes.io/os\":\"linux\",\"node-role.kubernetes.io/controlplane\":\"true\",\"node-role.kubernetes.io/etcd\":\"true\",\"node-role.kubernetes.io/worker\":\"true\",\"topology.kubernetes.io/zone\":\"ChengDu\"}] ","categories":"","description":"","excerpt":"在Kubernetes集群中，可以根据节点的拓扑标签以及存储后端支持的拓扑能力调度和发放资源。\n前提条件 需要在集群中的worker节点完成 …","ref":"/css-docs/docs/%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/%E9%85%8D%E7%BD%AE%E5%AD%98%E5%82%A8%E6%8B%93%E6%89%91%E6%84%9F%E7%9F%A5/","tags":"","title":"配置存储拓扑感知"},{"body":"华为分布式存储针对ALUA的配置请参考产品对应的主机连通性指南文档说明。\n针对不同的操作系统，ALUA配置可能有所不同。进入华为技术支持，在搜索输入框中输入“主机连通性指南”，单击搜索。在搜索结果中，选择对应操作系统的主机连通性指南。结合实际需要根据指南的说明进行ALUA配置。华为CSI将在华为存储上对该主机的启动器应用您设置的配置项。\n已经发放的Pod的节点不会主动更改ALUA信息，需要通过在该节点重新发放Pod才会变更主机ALUA配置。 分布式存储非双活场景，存储系统自身为Active/Active模式，选择“启用ALUA”没有实际意义，建议选择存储默认的“禁用ALUA”。因此不建议对分布式存储配置ALUA参数。\n华为CSI支持的分布式存储的ALUA参数见表 分布式存储ALUA参数说明。\n表 1 分布式存储ALUA参数说明\n参数名\n参数描述\n备注\nHostName\nHostName的值为worker节点的主机名，如HostName1、HostName2。\n主机名通常使用 cat /etc/hostname 可获取。支持正则表达式方式匹配，如当HostName=“*”时，该条配置对任意主机名的主机生效。可参考《正则表达式》。\n当计算节点的主机名可已匹配多条ALUA配置选项，会根据匹配的精确度进行排序，使用第一条ALUA配置选项。排序规则见ALUA配置项匹配主机名的规则。\nswitchoverMode\n切换模式。必选，取值为：\nDisable_alua：禁用ALUAEnable_alua：启用ALUA 非双活场景，存储系统自身为Active/Active模式，选择“启用ALUA”没有实际意义，建议选择“禁用ALUA”。当前华为CSI未支持SAN双活场景，请谨慎启用ALUA。\npathType\n路径类型。条件必选，取值为：\noptimal_path：优选路径non_optimal_path：非优选路径 切换模式为启动ALUA时需要设置该选项。\nALUA配置项匹配主机名的规则 如果设置的主机名规则精确匹配的业务节点主机名，则使用该主机名规则对应的ALUA配置项。\n如配置项1中主机名规则为“*”，配置项2中的主机名规则为“^myhost01$”。当计算节点的主机名是“myhost01”时，精确匹配配置项2，华为CSI将使用配置项2中的配置应用到存储侧。\n如果设置的主机名规则无法精确匹配的业务节点主机名，则直接使用正则匹配到的第一条ALUA配置项。\n如配置项1中主机名规则为“myhost0[0-9]”，配置项2中的主机名规则为“myhost0[5-9]”，配置项1的优先级高于配置项2。当计算节点的主机名是“myhost06”时，两个配置项均可以匹配，此时华为CSI将使用配置项1中的配置应用到存储侧。\n","categories":"","description":"","excerpt":"华为分布式存储针对ALUA的配置请参考产品对应的主机连通性指南文档说明。\n针对不同的操作系统，ALUA配置可能有所不同。进入华为技术支持，在 …","ref":"/css-docs/docs/%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/%E9%85%8D%E7%BD%AEalua%E7%89%B9%E6%80%A7/%E9%80%9A%E8%BF%87helm%E9%85%8D%E7%BD%AEalua%E7%89%B9%E6%80%A7/%E9%85%8D%E7%BD%AE%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%9A%84alua%E5%8F%82%E6%95%B0/","tags":"","title":"配置分布式存储后端的ALUA参数"},{"body":"现象描述 安装部署CSI时，Pod运行不起来，处于ContainerCreating状态，查看Pod中有打印告警事件：/etc/localtime is not a file。\n根因分析 容器挂载主机/etc/localtime文件时，识别类型有误，容器挂载不上主机侧/etc/localtime文件，导致Pod运行不起来。\n操作步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行命令，查看CSI服务Pod运行状态。\nkubectl get pod -n huawei-csi 命令结果示例如下。其中，huawei-csi为CSI服务部署的命名空间。\nNAME READY STATUS RESTARTS AGE huawei-csi-controller-6dfcc4b79f-9vjtq 9/9 ContainerCreating 0 24m huawei-csi-controller-6dfcc4b79f-csphc 9/9 ContainerCreating 0 24m huawei-csi-node-g6f4k 3/3 ContainerCreating 0 20m huawei-csi-node-tqs87 3/3 ContainerCreating 0 20m 执行命令，通过查看容器的“Events”参数。\nkubectl describe pod huawei-csi-controller-6dfcc4b79f-9vjtq -n huawei-csi 命令结果示例如下。其中，huawei-csi-controller-6dfcc4b79f-9vjtq 为2中查找到的状态显示为“ContainerCreating”的Pod名称，huawei-csi为该Pod所在的命名空间。\n... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 96s default-scheduler Successfully assigned huawei-csi/huawei-csi-controller-6dfcc4b79f-9vjtq to node1 Warning FailedMount 33s (x8 over 96s) kubelet MountVolume.SetUp failed for volume \"host-time\" : hostPath type check failed: /etc/localtime is not a file 执行命令cd /helm/esdk/templates，进入到CSI的安装包路径下。路径请参见表 软件包组件描述。\n以huawei-csi-controller.yaml文件为例，执行以下命令，查看文件内容。\nvi huawei-csi-controller.yaml 找到对应volumes配置下的host-time挂载项，删除type: File这一行配置内容。对templates目录下涉及该配置项的huawei-csi-node.yaml部署文件，执行相同的操作。\n... ... volumes: - hostPath: path: /var/log/ type: Directory name: log - hostPath: path: /etc/localtime type: File name: host-time ... ... 参考Helm卸载华为CSI卸载服务后，重新安装服务。\n执行以下命令，查看华为CSI服务Pod运行状态为Running。\nkubectl get pod -n huawei-csi 命令结果示例如下。\nNAME READY STATUS RESTARTS AGE huawei-csi-controller-6dfcc4b79f-9vjts 9/9 Running 0 24m huawei-csi-controller-6dfcc4b79f-csphb 9/9 Running 0 24m huawei-csi-node-g6f41 3/3 Running 0 20m huawei-csi-node-tqs85 3/3 Running 0 20m ","categories":"","description":"","excerpt":"现象描述 安装部署CSI时，Pod运行不起来，处于ContainerCreating状态，查看Pod中有打印告警事 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%8D%8E%E4%B8%BAcsi%E6%9C%8D%E5%8A%A1%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/%E5%90%AF%E5%8A%A8%E5%8D%8E%E4%B8%BAcsi%E6%9C%8D%E5%8A%A1%E5%A4%B1%E8%B4%A5-%E6%8F%90%E7%A4%BA%E9%94%99%E8%AF%AF-etc-localtime-is-not-a-file/","tags":"","title":"启动华为CSI服务失败，提示错误：“/etc/localtime is not a file”"},{"body":"查看huawei-csi-controller服务的日志 执行以下命令，获取huawei-csi-controller所在的节点\nkubectl get pod -A -o wide | grep huawei 命令结果示例如下，其中IP为节点主机ip，NODE为节点主机名称。\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES huawei-csi-controller-695b84b4d8-tg64l 9/9 Running 0 14s \u003chost1-ip\u003e \u003chost1-name\u003e \u003cnone\u003e \u003cnone\u003e 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群中huawei-csi-controller服务所在节点\n进入日志目录。\ncd /var/log/huawei 执行以下命令，查看容器自定义输出日志。\nvi huawei-csi-controller 进入容器目录。\ncd /var/log/containers 执行以下命令， 查看容器标准输出日志。\nvi huawei-csi-controller-\u003cname\u003e_huawei-csi_huawei-csi-driver-\u003ccontrainer-id\u003e.log 查看huawei-csi-node服务的日志 执行以下命令，获取huawei-csi-node所在的节点\nkubectl get pod -A -o wide | grep huawei 命令结果示例如下，其中IP为节点主机ip，NODE为节点主机名称。\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES huawei-csi-node-g6f7z 3/3 Running 0 14s \u003chost2-ip\u003e \u003chost2-name\u003e \u003cnone\u003e \u003cnone\u003e 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群中huawei-csi-node服务所在节点\n进入日志目录。\ncd /var/log/huawei 执行以下命令，查看容器自定义输出日志。\nvi huawei-csi-node 进入容器目录。\ncd /var/log/containers 执行以下命令， 查看容器标准输出日志。\nvi huawei-csi-node-\u003cname\u003e_huawei-csi_huawei-csi-driver-\u003ccontrainer-id\u003e.log ","categories":"","description":"","excerpt":"查看huawei-csi-controller服务的日志 执行以下命令，获取huawei-csi-controller …","ref":"/css-docs/docs/%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86/%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E5%8D%8E%E4%B8%BAcsi%E6%97%A5%E5%BF%97/","tags":"","title":"如何查看华为CSI日志"},{"body":"现象描述 在执行删除PVC前，PVC的状态处于Pending。\n根因分析 原因1：由于没有提前创建指定名称的StorageClass，导致Kubernetes在创建PVC时无法找到指定StorageClass名称。\n原因2：由于存储池能力和StorageClass能力不匹配，导致huawei-csi选择存储池失败。\n原因3：由于存储RESTful接口执行返回具体错误码（例如：50331651），导致huawei-csi在执行创建PVC时失败。\n原因4：由于存储在huawei-csi设定的超时时间内没有返回，huawei-csi向Kubernetes返回超时错误。\n原因5：其他原因。\n解决措施或规避方法 删除Pending状态下的PVC，需要根据以下不同的原因采取不同的解决措施。\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令，查看PVC的详细信息。\nkubectl describe pvc mypvc 根据PVC详细信息中Events信息，执行相应操作。\n如果由原因1导致PVC处于Pending状态，可以执行 kubectl delete pvc mypvc 命令，删除PVC。\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Warning ProvisioningFailed 0s (x15 over 3m24s) persistentvolume-controller storageclass.storage.k8s.io \"mysc\" not found 如果由原因2导致PVC处于Pending状态，可以执行 kubectl delete pvc mypvc 命令，删除PVC。\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Provisioning 63s (x3 over 64s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 External provisioner is provisioning volume for claim \"default/mypvc\" Warning ProvisioningFailed 63s (x3 over 64s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 failed to provision volume with StorageClass \"mysc\": rpc error: code = Internal desc = failed to select pool, the capability filter failed, error: failed to select pool, the final filter field: replication, parameters map[allocType:thin replication:True size:1099511627776 volumeType:lun]. please check your storage class 如果由原因3导致PVC处于Pending状态，可以执行 kubectl delete pvc mypvc 命令，删除PVC。\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Provisioning 63s (x4 over 68s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 External provisioner is provisioning volume for claim \"default/mypvc\" Warning ProvisioningFailed 62s (x4 over 68s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 failed to provision volume with StorageClass \"mysc\": rpc error: code = Internal desc = Create volume map[ALLOCTYPE:1 CAPACITY:20 DESCRIPTION:Created from Kubernetes CSI NAME:pvc-63ebfda5-4cf0-458e-83bd-ecc PARENTID:0] error: 50331651 如果由原因4导致PVC处于Pending状态，请联系华为工程师处理。\nEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Provisioning 63s (x3 over 52s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 External provisioner is provisioning volume for claim \"default/mypvc\" Warning ProvisioningFailed 63s (x3 over 52s) csi.huawei.com_huawei-csi-controller-b59577886-qqzm8_58533e4a-884c-4c7f-92c3-6e8a7b327515 failed to provision volume with StorageClass \"mysc\": rpc error: code = Internal desc = context deadline exceeded (Client.Timeout exceeded while awaiting headers) 如果由原因5导致PVC处于Pending状态，请联系华为工程师处理。\n","categories":"","description":"","excerpt":"现象描述 在执行删除PVC前，PVC的状态处于Pending。\n根因分析 原因1：由于没有提前创建指定名称的StorageClass，导 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/pvc%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/%E5%88%A0%E9%99%A4pvc%E5%89%8D-pvc%E7%9A%84%E7%8A%B6%E6%80%81%E4%B8%BApending/","tags":"","title":"删除PVC前，PVC的状态为Pending"},{"body":"华为提供huawei-csi镜像供用户使用，镜像文件获取请参考下载华为CSI软件包。\n为了后续在容器管理平台中可以使用CSI镜像，需要按照以下方式中的一种提前将CSI镜像导入到集群中：\n使用Docker工具，将CSI镜像上传至镜像仓库（推荐）。 手动将CSI镜像导入到所有需要部署华为CSI的节点。 上传镜像到镜像仓库 安装华为CSI依赖如下三个华为提供的镜像文件，请按照说明依次导入并上传下列镜像文件，镜像文件获取请参考下载华为CSI软件包。\nhuawei-csi-v4.5.0-arch.tar storage-backend-controller-v4.5.0-arch.tar storage-backend-sidecar-v4.5.0-arch.tar huawei-csi-extender-v4.5.0-arch.tar 前提条件\n已准备一台已安装Docker的Linux主机，且该主机支持访问镜像仓库。\n操作步骤\n执行docker load -i huawei-csi-v4.5.0-arch.tar命令，将CSI镜像导入当前节点。\ndocker load -i huawei-csi-v4.5.0-arch.tar 执行docker tag huawei-csi:4.5.0 repo.huawei.com/huawei-csi:4.5.0命令，添加镜像仓库地址到镜像标签。其中repo.huawei.com表示镜像仓库的地址。\ndocker tag huawei-csi:4.5.0 repo.huawei.com/huawei-csi:4.5.0 执行docker push repo.huawei.com/huawei-csi:4.5.0命令，将CSI镜像上传到镜像仓库。其中repo.huawei.com表示镜像仓库的地址。\ndocker push repo.huawei.com/huawei-csi:4.5.0 也可以使用containerd来进行镜像的导入和上传。 CCE / CCE Agile平台请参考该平台用户手册完成镜像导入和上传。 上传镜像到本地节点 若镜像已上传至镜像仓库，则跳过本章节。\n前提条件\n该节点已获取对应的华为CSI镜像文件，镜像文件获取请参考下载华为CSI软件包。 该节点已经安装Docker或其他容器引擎。 操作步骤\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录需要导入镜像的节点。\n将Kubernetes CSI组件包中的\"image\"目录拷贝到当前节点的任意目录下。\n执行cd image命令，进入到image的工作目录。工具路径请参见表 软件包组件描述。\n执行命令依次将image目录下的所有华为CSI镜像导入至本地节点，其中 name 参数是镜像tar包的名字。\n使用Docker容器引擎执行：\ndocker load -i \u003cname\u003e.tar 使用containerd容器引擎执行：\nctr -n k8s.io image import \u003cname\u003e.tar 使用Podman容器引擎执行：\npodman load -i \u003cname\u003e.tar 当节点主机安装的是其他容器引擎时，请使用对应容器引擎的导入镜像命令。\n","categories":"","description":"","excerpt":"华为提供huawei-csi镜像供用户使用，镜像文件获取请参考下载华为CSI软件包。\n为了后续在容器管理平台中可以使用CSI镜像，需要按照以 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%AE%89%E8%A3%85%E5%89%8D%E5%87%86%E5%A4%87/%E4%B8%8A%E4%BC%A0%E5%8D%8E%E4%B8%BAcsi%E9%95%9C%E5%83%8F/","tags":"","title":"上传华为CSI镜像"},{"body":"现象描述 用户使用oceanctl工具创建存储后端失败，控制台回显：“failed to call webhook: xxx :context deadline exceeded; error: exist status 1”。\n根因分析 创建存储后端时，将会调用CSI提供的webhook服务校验与存储管理网络的连通性和存储账号密码信息，出现该问题原因可能是以下两种原因：\n华为CSI校验存储管理网络连通性失败。 kube-apiserver和CSI webhook通信异常。 华为CSI校验存储管理网络连通性失败 请按照以下步骤检查是否是华为CSI校验存储管理网络连通性失败。\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行命令，获取CSI服务信息。其中，huawei-csi为CSI服务部署的命名空间。\nkubectl get pod -n huawei-csi -owide 命令结果示例如下：\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES huawei-csi-controller-xxx 9/9 Running 0 19h host-ip1 host-1 \u003cnone\u003e \u003cnone\u003e huawei-csi-node-mnqbz 3/3 Running 0 19h host-ip1 host-1 \u003cnone\u003e \u003cnone\u003e 登录huawei-csi-controller所在节点，如2中的host-1。\n进入到/var/log/huawei目录。\n# cd /var/log/huawei 查看storage-backend-controller日志，以连接存储超时为例。\ntail -n 1000 storage-backend-controller 日志示例如下：\n2024-01-01 06:30:44.280661 1 [INFO]: Try to login https://192.168.129.155:8088/deviceManager/rest 2024-01-01 06:31:44.281626 1 [ERROR]: Send request method: POST, Url: https://192.168.129.155:8088/deviceManager/rest/xx/sessions, error: Post \"https://192.168.129.155:8088/deviceManager/rest/xx/sessions\": context deadline exceeded (Client.Timeout exceeded while awaiting headers) 2024-01-01 06:31:44.281793 1 [WARNING]: Login https://192.168.129.155:8088/deviceManager/rest error due to connection failure, gonna try another Url 2024-01-01 06:31:44.291668 1 [INFO]: Finished validateCreate huawei-csi/backend-test. 2024-01-01 06:31:44.291799 1 [ERROR]: Failed to validate StorageBackendClaim, error: unconnected 如果日志中有相关登录超时、登录失败或者请求耗时较长，请检查宿主机和存储连通性或网络情况。\n如果日志中没有收到任何请求，则是kube-apiserver和CSI webhook通信异常。\nkube-apiserver和CSI webhook通信异常 联系Kubernetes平台管理员查看kube-apiserver与CSI webhook网络问题。例如kube-apiserver存在HTTPS代理时可能无法访问CSI webhook服务。\n临时规避方案中，将会删除webhook资源，该资源用于在创建存储后端时校验输入的账户信息是否正确和能否和存储建立连接，因此删除该资源仅影响创建后端时的校验，无其他功能影响，但需要注意以下几点。\n请保证huawei-csi-controller服务所在宿主机能和存储通信。 请保证输入的账号密码正确。 可执行以下命令查看CSI webhook信息。\nkubectl get validatingwebhookconfiguration storage-backend-controller.xuanwu.huawei.io 命令结果如下。\nNAME WEBHOOKS AGE storage-backend-controller.xuanwu.huawei.io 1 4d22h 联系Kubernetes平台管理员检查kube-apiserver与CSI webhook是否存在通信异常。\n临时规避方案：可执行以下命令删除webhook。\nkubectl delete validatingwebhookconfiguration storage-backend-controller.xuanwu.huawei.io 创建存储后端，可参考管理存储后端。\n如果kube-apiserver与CSI webhook通信恢复正常，需要重建webhook，执行以下命令，重启CSI Controller，通过指定“–replicas=*”恢复CSI Controller的副本数，下例为恢复至1个，请根据实际情况修改。\n先将副本数修改为0。\nkubectl scale deployment huawei-csi-controller -n huawei-csi --replicas=0 再将副本数恢复为原数量。\nkubectl scale deployment huawei-csi-controller -n huawei-csi --replicas=1 ","categories":"","description":"","excerpt":"现象描述 用户使用oceanctl工具创建存储后端失败，控制台回显：“failed to call webhook: xxx …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/%E4%BD%BF%E7%94%A8oceanctl%E5%B7%A5%E5%85%B7%E5%88%9B%E5%BB%BA%E5%90%8E%E7%AB%AF%E5%A4%B1%E8%B4%A5-%E6%8A%A5%E9%94%99-context-deadline-exceeded/","tags":"","title":"使用oceanctl工具创建后端失败，报错：context deadline exceeded"},{"body":"本章节介绍如何手动安装华为CSI。\n手动安装华为CSI当前仅支持Kubernetes平台。\n安装步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录集群的任意master节点。\n将Kubernetes CSI组件包中的\"manual\"目录拷贝到master节点的任意目录下。\n执行命令创建一个命名空间。\nkubectl create ns huawei-csi 进入到manual/esdk的工作目录下。具体路径请参见表 软件包组件描述。\ncd manual/esdk 执行命令，更新存储后端CRD\nkubectl apply -f ./crds/backend/ （可选） 请务必按照检查卷快照依赖组件章节检查快照依赖组件，确认无误后执行执行命令更新快照CRD，如果Kubernetes版本低于v1.17，跳过本步骤。\nkubectl apply -f ./crds/snapshot-crds/ --validate=false （可选） 执行命令安装CSIDriver。如果不使用CSIDriver特性，可跳过本步骤，详情请参考CSIDriver特性。\nkubectl apply -f ./deploy/csidriver.yaml 执行命令安装huawei-csi-controller服务。如果Kubernetes版本低于v1.17，删除名称为csi-snapshotter和snapshot-controller的容器，并根据检查CSI依赖的镜像中的版本要求，修改其它容器镜像版本。\nkubectl apply -f ./deploy/huawei-csi-controller.yaml 执行命令安装huawei-csi-node服务。\nkubectl apply -f ./deploy/huawei-csi-node.yaml 执行命令检查服务是否启动。\nkubectl get pod -n huawei-csi 回显示例如下，Pod状态为“Running“则安装成功。\nNAME READY STATUS RESTARTS AGE huawei-csi-controller-68745d489c-v5xkj 9/9 Running 0 13m huawei-csi-node-4hbqp 3/3 Running 0 13m huawei-csi-node-f7dkf 3/3 Running 0 13m huawei-csi-node-xrntc 3/3 Running 0 13m 多副本controller部署场景下可以通过修改 ./deploy/huawei-csi-controller.yaml 文件中Deployment资源的spec.replica字段来指定副本个数，修改完成后，执行以下命令生效：\nkubectl apply -f ./deploy/huawei-csi-controller.yaml ","categories":"","description":"","excerpt":"本章节介绍如何手动安装华为CSI。\n手动安装华为CSI当前仅支持Kubernetes平台。\n安装步骤 使用远程访问工具（以PuTTY为例）， …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%AE%89%E8%A3%85%E5%8D%8E%E4%B8%BAcsi/%E6%89%8B%E5%8A%A8%E5%AE%89%E8%A3%85%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"手动安装华为CSI"},{"body":"前提条件 已使用手动方式安装华为CSI。\n操作步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n进入manual/esdk工作目录下，执行以下命令，配置卷变更CRD。\nkubectl apply -f ./crds/volume-modify/ 执行以下命令。组件包路径请参考表 软件包组件描述。\nkubectl apply -f ./deploy/huawei-csi-controller-extender.yaml 执行命令检查服务是否启动。\nkubectl get pod -n huawei-csi 命令结果示例如下，其中huawei-csi为华为CSI部署命名空间。\nNAME READY STATUS RESTARTS AGE huawei-csi-controller-6dfcc4b79f-9vjtq 10/10 Running 0 24m huawei-csi-node-tqs87 3/3 Running 0 24m ","categories":"","description":"","excerpt":"前提条件 已使用手动方式安装华为CSI。\n操作步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任 …","ref":"/css-docs/docs/%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/pvc%E5%8F%98%E6%9B%B4/%E5%BC%80%E5%90%AFpvc%E5%8F%98%E6%9B%B4%E7%89%B9%E6%80%A7/%E6%89%8B%E5%8A%A8%E6%96%B9%E5%BC%8F%E5%BC%80%E5%90%AFpvc%E5%8F%98%E6%9B%B4%E7%89%B9%E6%80%A7/","tags":"","title":"手动方式开启PVC变更特性"},{"body":" PVC发放需要基于已配置的存储后端，因此当存储后端已经发放PVC时，请勿随便修改存储后端。 名称是存储后端的唯一标识，已发放PVC的存储后端不允许修改名称。 存储后端修改后，新增配置仅作用于新发放的卷。 存储后端修改期间，请勿执行卷管理操作。 操作步骤 参考删除存储后端章节，删除待修改存储后端。 参考创建存储后端章节，创建同名存储后端，存储后端名称不可变更。 ","categories":"","description":"","excerpt":" PVC发放需要基于已配置的存储后端，因此当存储后端已经发放PVC时，请勿随便修改存储后端。 名称是存储后端的唯一标识，已发放PVC的存储后 …","ref":"/css-docs/docs/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%AE%A1%E7%90%86/%E7%AE%A1%E7%90%86%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/%E6%9B%B4%E6%96%B0%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/%E6%89%8B%E5%8A%A8%E6%9B%B4%E6%96%B0%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/","tags":"","title":"手动更新存储后端"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E6%89%8B%E5%8A%A8%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80/","tags":"","title":"手动升级/回退"},{"body":"本章节介绍如何手动卸载华为CSI。\n如果您不是出于升级的目的卸载华为CSI，请确保卸载华为CSI前已经在您的容器平台中将华为CSI发放的资源（PV、PVC、快照、存储后端等）全部清理。否则一旦您卸载华为CSI后，这些资源将无法被自动调度、管理或者清理。\n卸载huawei-csi-node服务 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令卸载 huawei-csi-node 服务，huawei-csi 替换为华为CSI所在的命名空间。\nkubectl delete daemonset huawei-csi-node -n huawei-csi 执行以下命令检查服务是否已成功卸载（如果提示NotFound错误，表示已成功卸载）。\nkubectl get daemonset huawei-csi-node -n huawei-csi 卸载huawei-csi-controller服务 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令卸载 huawei-csi-controller 服务，huawei-csi 替换为华为CSI所在的命名空间。\nkubectl delete deployment huawei-csi-controller -n huawei-csi 执行以下命令检查服务是否已成功卸载（如果提示NotFound错误，表示已成功卸载）。\nkubectl get deployment huawei-csi-controller -n huawei-csi 卸载csidriver对象 如果安装时未使用CSIDriver特性，可跳过本步骤。\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令卸载csidriver对象。\nkubectl delete csidriver csi.huawei.com 执行以下命令检查服务是否已成功卸载（如果提示NotFound错误，表示已成功卸载）。\nkubectl get csidriver csi.huawei.com 删除RBAC权限 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n删除RBAC权限。\nkubectl -n huawei-csi -l provisioner=csi.huawei.com delete ServiceAccount,Service,role,rolebinding,ClusterRole,ClusterRoleBinding 其它资源卸载 卸载huawei-csi-host-info对象，请参考卸载huawei-csi-host-info对象进行操作。 卸载webhook资源，请参考卸载Webhook资源进行操作。 （可选）卸载快照依赖组件服务，请参考卸载Snapshot依赖组件服务进行操作。 （可选）卸载Lease资源，请参考卸载Lease资源进行操作。 ","categories":"","description":"","excerpt":"本章节介绍如何手动卸载华为CSI。\n如果您不是出于升级的目的卸载华为CSI，请确保卸载华为CSI前已经在您的容器平台中将华为CSI发放的资 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%B8%E8%BD%BD%E5%8D%8E%E4%B8%BAcsi/%E6%89%8B%E5%8A%A8%E5%8D%B8%E8%BD%BD%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"手动卸载华为CSI"},{"body":"本章节介绍如何创建证书到存储后端，如果有对服务登录存储添加证书校验的需要，可以参考本章节新增证书，当前支持根据crt文件或者pem文件创建证书到存储后端。\n创建证书到存储后端前，须提前将准备好的证书导入存储阵列。\n","categories":"","description":"","excerpt":"本章节介绍如何创建证书到存储后端，如果有对服务登录存储添加证书校验的需要，可以参考本章节新增证书，当前支持根据crt文件或者pem文件创建证 …","ref":"/css-docs/docs/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%AE%A1%E7%90%86/%E6%96%B0%E5%A2%9E%E8%AF%81%E4%B9%A6%E5%88%B0%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E5%8F%AF%E9%80%89/","tags":"","title":"新增证书到存储后端（可选）"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/docs/%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86/","tags":"","title":"信息收集"},{"body":"现象描述 创建Pod时失败，华为CSI日志中报错“mount point does not exist”。\n根因分析 huawei-csi-node中的“pods-dir”目录原生Kubernetes集群与Tanzu Kubernetes集群不一致。\n解决措施或规避方法 进入helm/esdk/目录，执行vi values.yaml命令打开配置文件。\nvi values.yaml 将kubeletConfigDir参数修改为kubelet实际的安装目录。\n# Specify kubelet config dir path. # kubernetes and openshift is usually /var/lib/kubelet # Tanzu is usually /var/vcap/data/kubelet kubeletConfigDir: /var/vcap/data/kubelet ","categories":"","description":"","excerpt":"现象描述 创建Pod时失败，华为CSI日志中报错“mount point does not exist”。 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%AF%B9%E6%8E%A5tanzu-kubernetes%E9%9B%86%E7%BE%A4%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/%E4%BF%AE%E6%94%B9%E4%B8%BB%E6%9C%BA%E6%8C%82%E8%BD%BD%E7%82%B9/","tags":"","title":"修改主机挂载点"},{"body":"Symptom When a Pod is being created, the Pod is in the ContainerCreating state for a long time. Check the huawei-csi-node log (for details, see Viewing Huawei CSI Logs). No Pod creation information is recorded in the huawei-csi-node log. After the kubectl get volumeattachment command is executed, the name of the PV used by the Pod is not displayed in the PV column. After a long period of time (more than ten minutes), the Pod is normally created and the Pod status changes to Running.\nRoot Cause Analysis The kube-controller-manager component of Kubernetes is abnormal.\nSolution or Workaround Contact container platform engineers to rectify the fault.\n","categories":"","description":"","excerpt":"Symptom When a Pod is being created, the Pod is in the …","ref":"/css-docs/en/docs/troubleshooting/pod-issues/a-pod-is-in-the-containercreating-state-for-a-long-time-when-it-is-being-created/","tags":"","title":"A Pod Is in the ContainerCreating State for a Long Time When It Is Being Created"},{"body":"Symptom After a user changes the password on the storage device, the account is locked.\nRoot Cause Analysis CSI uses the account and password configured on the storage device to log in to the storage device. After the account password is changed on the storage device, CSI attempts to log in to the storage device again after the login fails. Take OceanStor Dorado as an example. The default login policy is that an account will be locked after three consecutive password verification failures. Therefore, when CSI retries for more than three times, the account will be locked.\nSolution or Workaround If the backend account is admin, run the following command to set the number of huawei-csi-controller service copies to 0. If an account other than admin is used, skip this step.\nkubectl scale deployment huawei-csi-controller -n huawei-csi --replicas=0 Log in to the storage device as user admin and modify the login policy. Take OceanStor Dorado as an example. On DeviceManager, choose Settings \u003e User and Security \u003e Security Policies \u003e Login Policy, click Modify, and disable Account Lockout.\nIf the backend account is admin, run the following command to restore the number of CSI Controller copies using –replicas=*. In the following example, the number of copies is restored to 1. Change it based on site requirements. If an account other than admin is used, skip this step.\nkubectl scale deployment huawei-csi-controller -n huawei-csi --replicas=1 Use the oceanctl tool to change the storage backend password. For details about how to change the backend password, see Updating a Storage Backend.\nLog in to the storage device as user admin and modify the login policy. Take OceanStor Dorado as an example. On DeviceManager, choose Settings \u003e User and Security \u003e Security Policies \u003e Login Policy, click Modify, and enable Account Lockout.\n","categories":"","description":"","excerpt":"Symptom After a user changes the password on the storage device, the …","ref":"/css-docs/en/docs/troubleshooting/storage-backend-issues/an-account-is-locked-after-the-password-is-updated-on-the-storage-device/","tags":"","title":"An Account Is Locked After the Password Is Updated on the Storage Device"},{"body":"前提条件 已下载新版本CSI的软件包。\n操作步骤 参考CCE和CCE Agile卸载华为CSI卸载CSI。 参考CCE和CCE Agile平台安装华为CSI安装新版本的CSI。 ","categories":"","description":"","excerpt":"前提条件 已下载新版本CSI的软件包。\n操作步骤 参考CCE和CCE Agile卸载华为CSI卸载CSI。 参考CCE和CCE Agile平 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E4%BD%BF%E7%94%A8helm%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/%E5%8D%87%E7%BA%A7%E5%8D%8E%E4%B8%BAcsi/cce%E5%92%8Ccce-agile%E5%8D%87%E7%BA%A7%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"CCE和CCE Agile升级华为CSI"},{"body":"Symptom The livenessprobe container of the huawei-csi-controller component keeps restarting.\nRoot Cause Analysis The default port (9808) of the livenessprobe container of huawei-csi-controller conflicts with the existing vSphere CSI port of Tanzu.\nSolution or Workaround Change the default port of the livenessprobe container to an idle port.\nGo to the helm/esdk directory and run the vi values.yaml command to open the configuration file.\nvi values.yaml Change the default value 9808 of controller.livenessProbePort to an idle port, for example, 9809.\ncontroller: livenessProbePort: 9809 Update Huawei CSI using Helm. For details, see Upgrading Huawei CSI.\n","categories":"","description":"","excerpt":"Symptom The livenessprobe container of the huawei-csi-controller …","ref":"/css-docs/en/docs/troubleshooting/common-problems-and-solutions-for-interconnecting-with-the-tanzu-kubernetes-cluster/changing-the-default-port-of-the-livenessprobe-container/","tags":"","title":"Changing the Default Port of the livenessprobe Container"},{"body":"After Huawei storage is connected to the container platform, Huawei CSI needs to manage storage resources on Huawei storage based on service requirements, such as creating and mapping volumes. In this case, Huawei CSI needs to use the users created on Huawei storage to communicate with Huawei storage. The following table lists the user information required for different storage devices.\nTable 1 User requirements for connecting storage to CSI\nStorage Type\nUser Type\nRole\nLevel\nType\nOceanStor V5\nSystem user\nAdministrator\nAdministrator\nLocal user\nvStore user\nvStore administrator\nAdministrator\nLocal user\nOceanStor Dorado V3\nSystem user\nAdministrator\nAdministrator\nLocal user\nOceanStor 6.1.3, 6.1.5, 6.1.6, 6.1.7, 6.1.8\nSystem user\nAdministrator/User-defined role1\nN/A\nLocal user\nOceanStor Dorado 6.1.0, 6.1.2, 6.1.3, 6.1.5, 6.1.6, 6.1.7, 6.1.8\nSystem user\nAdministrator/User-defined role1\nN/A\nLocal user\nvStore user\nvStore administrator\nN/A\nLocal user\nOceanStor Pacific series\nSystem user\nAdministrator\nN/A\nLocal user\nNote 1: If a user-defined role is used, you need to configure permissions for the role. For details about how to configure the minimum permissions, see Configuring Custom Permissions. You are advised not to use the users of the super administrator role.\n","categories":"","description":"","excerpt":"After Huawei storage is connected to the container platform, Huawei …","ref":"/css-docs/en/docs/installation-and-deployment/installation-preparations/checking-user-configurations-on-huawei-storage/","tags":"","title":"Checking User Configurations on Huawei Storage"},{"body":"This section describes how to clone a PVC.\nWhen cloning a PVC, you need to specify the data source. The following is a simple example of cloning a PVC. In this example, mypvc is used as the data source and a PVC named myclone is created.\nkind: PersistentVolumeClaim apiVersion: v1 metadata: name: myclone spec: storageClassName: mysc dataSource: name: mypvc kind: PersistentVolumeClaim volumeMode: Filesystem accessModes: - ReadWriteOnce resources: requests: storage: 2Gi The specified storageClassName must be the same as the StorageClass of the source volume in dataSource. The capacity of the clone volume must be greater than or equal to that of the source volume. Equal capacity is recommended. Prerequisites The source PVC already exists in the system, and the backend where the source PVC resides supports cloning. For details about the storage devices that support cloning, see Table 2 and Table 2. For details about the Kubernetes versions that support cloning, see Kubernetes Feature Matrix.\nProcedure Run the following command to create a PVC based on the configuration file of the clone volume.\nkubectl create -f myclone.yaml ","categories":"","description":"","excerpt":"This section describes how to clone a PVC.\nWhen cloning a PVC, you …","ref":"/css-docs/en/docs/using-huawei-csi/managing-a-pvc/cloning-a-pvc/","tags":"","title":"Cloning a PVC"},{"body":"Performing Check Before Collection Use a remote access tool, such as PuTTY, to log in to the node where the oceanctl tool is installed in the Kubernetes cluster through the management IP address.\nRun the following command. The displayed version is v4.5.0.\noceanctl version The following is an example of the command output.\nOceanctl Version: v4.5.0 Run the oceanctl collect logs –help command. The following information is displayed.\n$ oceanctl collect logs --help Collect logs of one or more nodes in specified namespace in Kubernetes Usage: oceanctl collect logs [flags] Examples: # Collect logs of all nodes in specified namespace oceanctl collect logs -n \u003cnamespace\u003e # Collect logs of specified node in specified namespace oceanctl collect logs -n \u003cnamespace\u003e -N \u003cnode\u003e # Collect logs of all nodes in specified namespace oceanctl collect logs -n \u003cnamespace\u003e -a # Collect logs of all nodes in specified namespace with a maximum of 50 nodes collected at the same time oceanctl collect logs -n \u003cnamespace\u003e -a --threads-max=50 # Collect logs of specified node in specified namespace oceanctl collect logs -n \u003cnamespace\u003e -N \u003cnode\u003e -a Flags: -a, --all Collect all nodes messages -h, --help help for logs -n, --namespace string namespace of resources -N, --nodename string Specify the node for which information is to be collected. --threads-max int set maximum number[1~1000] of threads for nodes to be collected. (default 50) Global Flags: --log-dir string Specify the directory for printing log files. (default \"/var/log/huawei\") Run the following command to check whether a Pod is started properly. In the command, huawei-csi indicates the namespace for installing CSI.\nkubectl get deployment -n huawei-csi The following is an example of the command output.\nNAME READY UP-TO-DATE AVAILABLE AGE huawei-csi-controller 1/1 1 1 21h Collecting All Logs in the CSI Namespace Using oceanctl Use a remote access tool, such as PuTTY, to log in to the node checked in Performing Check Before Collection through the management IP address.\nRun the oceanctl collect logs -n \u003cnamespace\u003e -a –threads-max=\u003cmax_node_processing_num\u003e command to collect CSI logs of all nodes where CSI containers reside in the cluster. In the command, threads-max indicates the maximum number of nodes for which logs can be collected at the same time. The default value is 50. You can set the value based on the host performance and load.\noceanctl collect logs -n huawei-csi -a --threads-max=10 Check the log package generated in the /tmp directory. You can run the unzip \u003czip_name\u003e -d collect_logs command to decompress the log package. In the preceding command, \u003czip_name\u003e indicates the package name.\n# date Wed Sep 20 02:49:24 EDT 2023 # ls huawei-csi-2023-09-20-02:48:22-all.zip Collecting the Log of a Single CSI Node Using oceanctl Use a remote access tool, such as PuTTY, to log in to the node checked in Performing Check Before Collection through the management IP address.\nRun the **oceanctl collect logs -n \u003cnamespace\u003e -N **\u003cnodeName\u003e command to collect CSI logs of all nodes where CSI containers reside in the cluster.\noceanctl collect logs -n huawei-csi -N node-1 Check the log package generated in the /tmp directory. You can run the unzip \u003czip_name\u003e -d collect_logs command to decompress the log package. In the preceding command, \u003czip_name\u003e indicates the package name.\n# date Thu Sep 21 04:08:47 EDT 2023 # ls huawei-csi-2023-09-21-04:05:15-node-1.zip ","categories":"","description":"","excerpt":"Performing Check Before Collection Use a remote access tool, such as …","ref":"/css-docs/en/docs/common-operations/collecting-information/collecting-logs/","tags":"","title":"Collecting Logs"},{"body":"Huawei CSI plug-in is compatible with Huawei OceanStor series all-flash storage and hybrid flash storage. The following table lists the supported storage versions.\nTable 1 Supported Huawei enterprise storage\nStorage Product\nVersion\nOceanStor V5\nV500R007, V500R007 Kunpeng\nOceanStor Dorado V3\nV300R002\nOceanStor\n6.1.3, 6.1.5, 6.1.6, 6.1.7, 6.1.8\nOceanStor Dorado\n6.1.0, 6.1.2, 6.1.3, 6.1.5, 6.1.6, 6.1.7, 6.1.8\nHuawei CSI plug-in supports the following features for Huawei enterprise storage.\nTable 2 Features supported by Huawei enterprise storage and constraints\nFeature\nOceanStor V5\nOceanStor Dorado V3\nOceanStor\nOceanStor Dorado\nStatic Provisioning\nSAN: FC/iSCSI2\nNAS: NFS 3\nSAN: FC/iSCSI2\nSAN: FC/iSCSI/NVMe over RoCE/NVMe over FC3\nNAS: NFS 3/4.0/4.1/4.2\nSAN: FC/iSCSI/NVMe over RoCE/NVMe over FC3\nNAS: NFS 3/4.0/4.1/4.24\nDynamic Provisioning\nManage Provisioning1\nExpand Persistent Volume5\nVolumes created in Dynamic Provisioning or Manage Provisioning mode are supported.\nCreate VolumeSnapshot\nVolumes created in Dynamic Provisioning or Manage Provisioning mode are supported.\nDelete VolumeSnapshot\nSupported\nSupported\nSupported\nSupported\nRestore VolumeSnapshot\nSupported\nSupported\nSAN: supported\nNAS: supported only in 6.1.5 and later versions\nSAN: supported\nNAS: supported only in 6.1.5 and later versions\nClone Persistent Volume\nNon-HyperMetro volumes created in Dynamic Provisioning or Manage Provisioning mode are supported.\nSAN: supports non-HyperMetro volumes created in Dynamic Provisioning or Manage Provisioning mode.\nNAS: Only 6.1.5 and later versions support volumes created in Dynamic Provisioning or Manage Provisioning mode.\nRaw Block Volume\nOnly SAN volumes are supported.\nOnly SAN volumes are supported.\nOnly SAN volumes are supported.\nOnly SAN volumes are supported.\nTopology\nSupported\nSupported\nSupported\nSupported\nGeneric Ephemeral Volumes\nSupported\nSupported\nSupported\nSupported\nAccess Mode\nRWO/ROX/RWOP: supported by all types of volumes. RWOP is supported only by Kubernetes 1.22 and later versions.\nRWX: supported only by Raw Block volumes and NFS volumes.\nQoS\nSupported6\nSupported\nSupported\nSupported\nApplication type\nN/A\nN/A\nSupported\nSupported\nVolume HyperMetro7\nNot supported\nN/A\nOnly NAS volumes are supported.\nStorage multi-tenant\nOnly NAS volumes are supported.\nN/A\nOnly NAS volumes are supported.8\nNote 1: Manage Provisioning is a volume management feature customized by Huawei CSI. This feature allows existing storage resources to be managed by Kubernetes. You are not allowed to manage a storage resource for multiple times and concurrently delete or create a storage resource. Note 2: If the user’s container platform is deployed in a virtualization environment, only iSCSI networking is supported. Note 3: If NVMe over RoCE or NVMe over FC is used, the version of the nvme-cli tool on worker nodes must be 1.9 or later. To query the version, run the nvme version command. Note 4: Only OceanStor Dorado 6.1.0 and later versions support NFS. Only OceanStor Dorado 6.1.3 and later versions support NFS 4.1. OceanStor Dorado 6.1.7 and later versions support NFS over RDMA. Only OceanStor Dorado 6.1.8 and later versions support NFS 4.2. Note 5: The provisioned PVC whose volumeType is lun and accessModes is ReadOnlyMany does not support capacity expansion. Note 6: Only system users can configure QoS. Note 7: Only the active-active (AA) mode is supported. Note 8: Only OceanStor Dorado 6.1.3 and later versions support multi-tenant. Huawei CSI plug-in supports the following Dtree features for Huawei enterprise storage.\nTable 3 Features supported by Dtree\nFeature\nSupported\nStatic Provisioning\n√\nDynamic Provisioning\n√\nExpand Persistent Volume\n√\nAccess Mode\n√ (RWX/RWO/ROX/RWOP: Kubernetes 1.22 or later supports RWOP.)\nMulti-tenancy\n√\nCreate VolumeSnapshot\nX\nDelete VolumeSnapshot\nX\nRestore VolumeSnapshot\nX\nClone Persistent Volume\nX\nQoS\nX\nVolume HyperMetro\nX\nApplication type\nX\nTable 4 Huawei storage versions supported by Dtree\nStorage Product\nVersion\nOceanStor Dorado\n6.1.0, 6.1.2, 6.1.3, 6.1.5, 6.1.6, 6.1.7, 6.1.8\n","categories":"","description":"","excerpt":"Huawei CSI plug-in is compatible with Huawei OceanStor series …","ref":"/css-docs/en/docs/compatibility-and-features/compatibility-with-huawei-enterprise-storage/","tags":"","title":"Compatibility with Huawei Enterprise Storage"},{"body":"VolumeSnapshot can be provisioned in two ways: pre-provisioning and dynamic provisioning. Currently, Huawei CSI supports only dynamic provisioning. This section describes how to dynamically provision a VolumeSnapshot using Huawei CSI.\nThe following is an example of the VolumeSnapshot configuration file:\nIf api-versions in your environment supports v1, use the following example:\napiVersion: snapshot.storage.k8s.io/v1 kind: VolumeSnapshot metadata: name: mysnapshot spec: volumeSnapshotClassName: mysnapclass source: persistentVolumeClaimName: mypvc If api-versions in your environment supports v1beta1, use the following example:\napiVersion: snapshot.storage.k8s.io/v1beta1 kind: VolumeSnapshot metadata: name: mysnapshot spec: volumeSnapshotClassName: mysnapclass source: persistentVolumeClaimName: mypvc The api-versions information in the VolumeSnapshot must be the same as the version used for creating the VolumeSnapshotClass.\nYou can modify the parameters according to Table 1.\nTable 1 VolumeSnapshot parameters\nParameter\nDescription\nRemarks\nmetadata.name\nUser-defined name of a VolumeSnapshot object.\nTake Kubernetes v1.22.1 as an example. The value can contain digits, lowercase letters, hyphens (-), and periods (.), and must start and end with a letter or digit.\nspec.volumeSnapshotClassName\nName of the VolumeSnapshotClass object.\n--\nspec.source.persistentVolumeClaimName\nName of the source PVC object.\nName of the source PVC of the snapshot\nPrerequisites The source PVC exists, and the backend where the PVC resides supports VolumeSnapshot creation. For details about the storage devices that support VolumeSnapshot creation, see Table 2 and Table 2. For details about the Kubernetes versions that support VolumeSnapshot creation, see Table 1. The volume snapshot component CRD on which the running of Huawei CSI depends has been installed. For details, see Checking Volume Snapshot-Dependent Components. A VolumeSnapshotClass that uses Huawei CSI exists in the system. Procedure Run the following command to create a VolumeSnapshot using the created VolumeSnapshot configuration file.\nkubectl create -f mysnapshot.yaml Run the following command to view the information about the created VolumeSnapshot.\nkubectl get volumesnapshot The following is an example of the command output.\nNAME READYTOUSE SOURCEPVC SOURCESNAPSHOTCONTENT RESTORESIZE SNAPSHOTCLASS SNAPSHOTCONTENT CREATIONTIME AGE mysnapshot true mypvc 100Gi mysnapclass snapcontent-1009af0a-24c2-4435-861c-516224503f2d \u003cinvalid\u003e 78s ","categories":"","description":"","excerpt":"VolumeSnapshot can be provisioned in two ways: pre-provisioning and …","ref":"/css-docs/en/docs/using-huawei-csi/creating-a-volumesnapshot/configuring-a-volumesnapshot/","tags":"","title":"Configuring a VolumeSnapshot"},{"body":" If STATUS of a VolumeModifyClaim is Creating, deleting the VolumeModifyClaim resource will delete the created resource on the storage side and then remove the cluster resource. After the deletion, if you continue to use the original StorageClass for PVC management, you need to restore the associated storage backend to a non-HyperMetro storage backend. If STATUS of a VolumeModifyClaim is Pending or Completed, deleting the VolumeModifyClaim resource will only remove the cluster resource and will not delete the created resource on the storage side (that is, there is not interaction with the storage side). VolumeModifyContent resources are managed by VolumeModifyClaim. Do not manually manage VolumeModifyContent resources. If some PVCs among the PVCs to be changed meet the change requirements and the batch change fails, all PVC changes will be removed. As a result, the PVCs that meet the change requirements will not meet the change requirements. If a PVC to be changed has been manually managed on the storage side, the change may fail. Do not manually manage storage volumes when using the change feature. This section describes how to use kubectl to delete a PVC change. The procedure is as follows.\nProcedure Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to delete a PVC change. In the command, vmc-name indicates the name of the VolumeModifyClaim resource.\nkubectl delete volumemodifyclaims \u003cvmc-name\u003e Query the deletion result by following the instructions in Creating a PVC Change Resource.\n","categories":"","description":"","excerpt":" If STATUS of a VolumeModifyClaim is Creating, deleting the …","ref":"/css-docs/en/docs/advanced-features/pvc-change/configuring-pvc-changes/deleting-a-pvc-change/","tags":"","title":"Deleting a PVC Change"},{"body":"Obtaining Help Information Obtain the oceanctl help information.\noceanctl --help Check the oceanctl version.\noceanctl version Specify the custom log file directory. The following example describes how to check the oceanctl version.\noceanctl version --log-dir=/path/to/custom Creating a Storage Backend Run the following command to obtain the help information about creating a backend.\noceanctl create backend -h Run the following command to create a storage backend based on the specified yaml file.\noceanctl create backend -f /path/to/backend.yaml -i yaml Run the following command to create a storage backend based on the specified json file. The huawei-csi-configmap file can be exported only in json format.\noceanctl create backend -f /path/to/configmap.json -i json Run the following command to create a storage backend in the specified namespace.\noceanctl create backend -f /path/to/backend.yaml -i yaml -n \u003cnamespace\u003e Run the following command to create a storage backend and ignore the storage backend name verification, for example, uppercase letters and underscores (_). Do not run this command unless necessary.\noceanctl create backend -f /path/to/backend.yaml -i yaml --not-validate-name Run the following command to create a storage backend and specify provisioner. csi.oceanstor.com is the driver name specified during installation. For details, see 4.\nThis command is used only when a backend is created on the CCE or CCE Agile platform.\noceanctl create backend -f /path/to/backend.yaml -i yaml --provisioner=csi.oceanstor.com Querying a Storage Backend Run the following command to obtain the help information about querying a backend.\noceanctl get backend -h Run the following command to query a single storage backend in the default namespace.\noceanctl get backend \u003cbackend-name\u003e Run the following command to query all storage backends in the specified namespace.\noceanctl get backend -n \u003cnamespace\u003e Run the following command to format the output. Currently, json, yaml, and wide are supported.\noceanctl get backend \u003cbackend-name\u003e -o json Updating a Storage Backend Run the following command to obtain the help information about updating a backend.\noceanctl update backend -h Run the following command to update the specified storage backend in the default namespace.\noceanctl update backend \u003cbackend-name\u003e --password Run the following command to update a storage backend in the specified namespace.\noceanctl update backend \u003cbackend-name\u003e -n \u003cnamespace\u003e --password Deleting a Storage Backend Run the following command to obtain the help information about deleting a backend.\noceanctl delete backend -h Run the following command to delete the specified storage backend in the default namespace.\noceanctl delete backend \u003cbackend-name\u003e Run the following command to delete all storage backends in the default namespace.\noceanctl delete backend --all Run the following command to delete a storage backend in the specified namespace.\noceanctl delete backend \u003cbackend-name...\u003e -n \u003cnamespace\u003e Creating a Storage Backend Certificate Run the following command to obtain the help information about querying a certificate.\noceanctl create cert -h Run the following command to create a certificate for a single storage backend in the default namespace based on the specified .crt certificate file.\noceanctl create cert \u003cname\u003e -f /path/to/cert.crt -b \u003cbackend-name\u003e Run the following command to create a certificate for a single storage backend in the specified namespace based on the specified .crt certificate file.\noceanctl create cert \u003cname\u003e -f /path/to/cert.crt -b \u003cbackend-name\u003e -n \u003cnamespace\u003e Run the following command to create a certificate for a single storage backend in the specified namespace based on the specified .pem certificate file.\noceanctl create cert \u003cname\u003e -f /path/to/cert.pem -b \u003cbackend-name\u003e -n \u003cnamespace\u003e Querying a Storage Backend Certificate Run the following command to obtain the help information about querying a certificate.\noceanctl get cert -h Run the following command to query the certificate of a specified storage backend in the default namespace.\noceanctl get cert -b \u003cbackend-name\u003e Run the following command to query the certificate of a specified storage backend in the specified namespace.\noceanctl get cert -b \u003cbackend-name\u003e -n \u003cnamespace\u003e Updating a Storage Backend Certificate Run the following command to obtain the help information about updating a certificate.\noceanctl update cert -h Run the following command to update a certificate for a specified storage backend in the default namespace based on the specified .crt certificate file.\noceanctl update cert -b \u003cbackend-name\u003e -f /path/to/cert.crt Run the following command to update a certificate for a specified storage backend in the specified namespace based on the specified .crt certificate file.\noceanctl update cert -b \u003cbackend-name\u003e -n \u003cnamespace\u003e -f /path/to/cert.crt Run the following command to update a certificate for a specified storage backend in the specified namespace based on the specified .pem certificate file.\noceanctl update cert -b \u003cbackend-name\u003e -n \u003cnamespace\u003e -f /path/to/cert.pem Deleting a Storage Backend Certificate Run the following command to obtain the help information about deleting a certificate.\noceanctl delete cert -h Run the following command to delete the certificate of a specified storage backend in the default namespace.\noceanctl delete cert -b \u003cbackend-name\u003e Run the following command to delete the certificate of a specified storage backend in the specified namespace.\noceanctl delete cert -b \u003cbackend-name\u003e -n \u003cnamespace\u003e ","categories":"","description":"","excerpt":"Obtaining Help Information Obtain the oceanctl help information. …","ref":"/css-docs/en/docs/storage-backend-management/description-of-oceanctl-commands/","tags":"","title":"Description of oceanctl Commands"},{"body":"Downloading a Container Image Using containerd Run the following command to download an image to a local path. In the command, image:tag indicates the image to be pulled and its tag.\nctr image pull \u003cimage\u003e:\u003ctag\u003e Run the following command to export the image to a file. In the command, image:tag indicates the image to be exported, and file indicates the name of the exported image file.\nctr image export \u003cfile\u003e.tar \u003cimage\u003e:\u003ctag\u003e Downloading a Container Image Using Docker Run the following command to download an image to a local path. In the command, image:tag indicates the image to be pulled.\ndocker pull \u003cimage\u003e:\u003ctag\u003e Run the following command to export the image to a file. In the command, image:tag indicates the image to be exported, and file indicates the name of the exported image file.\ndocker save \u003cimage\u003e:\u003ctag\u003e -o \u003cfile\u003e.tar Downloading a Container Image Using Podman Run the following command to download an image to a local path. In the command, image:tag indicates the image to be pulled.\npodman pull \u003cimage\u003e:\u003ctag\u003e Run the following command to export the image to a file. In the command, image:tag indicates the image to be exported, and file indicates the name of the exported image file.\npodman save \u003cimage\u003e:\u003ctag\u003e -o \u003cfile\u003e.tar ","categories":"","description":"","excerpt":"Downloading a Container Image Using containerd Run the following …","ref":"/css-docs/en/docs/common-operations/downloading-a-container-image/","tags":"","title":"Downloading a Container Image"},{"body":"Example 1: The configuration file content is as follows:\nparameters: ALUA: \"*\": switchoverMode: Enable_alua pathType: optimal_path node1: switchoverMode: Enable_alua pathType: non_optimal_path If the host name is node1, both of the preceding ALUA configuration sections can be used to configure initiators. According to the configuration policy rules in Configuring ALUA Parameters for a Distributed Storage Backend, the priority of the second configuration section (where HostName is node1) is higher than that of the first configuration section (where HostName is *).\nExample 2: The configuration file content is as follows:\nparameters: ALUA: node[0-9]: switchoverMode: Enable_alua pathType: optimal_path node[5-7]: switchoverMode: Enable_alua pathType: non_optimal_path If the host name is node6, both of the preceding ALUA configuration sections can be used to configure initiators. According to the configuration policy rules in Configuring ALUA Parameters for a Distributed Storage Backend, select the first ALUA configuration section to configure initiators.\nExample 3: The configuration file content is as follows:\nparameters: ALUA: node1$: switchoverMode: Enable_alua pathType: optimal_path node10$: switchoverMode: Enable_alua pathType: non_optimal_path According to the configuration policy rules in Configuring ALUA Parameters for a Distributed Storage Backend: For host node1, select the first ALUA configuration section to configure initiators. For host node10, select the second ALUA configuration section to configure initiators. ^ matches the beginning of a character string, and $ matches the end of a character string.\n","categories":"","description":"","excerpt":"Example 1: The configuration file content is as follows:\nparameters: …","ref":"/css-docs/en/docs/appendix/example-alua-configuration-policy-of-distributed-storage/","tags":"","title":"Example ALUA Configuration Policy of Distributed Storage"},{"body":"Symptom In an environment where the Kubernetes version is earlier than 1.25, the capacity of a generic ephemeral volume of the LUN type fails to be expanded. The system displays a message indicating that the PV capacity has been expanded, but the PVC capacity fails to be updated.\nRoot Cause Analysis This problem is caused by a Kubernetes bug, which has been resolved in Kubernetes 1.25.\n","categories":"","description":"","excerpt":"Symptom In an environment where the Kubernetes version is earlier than …","ref":"/css-docs/en/docs/troubleshooting/pvc-issues/failed-to-expand-the-capacity-of-a-generic-ephemeral-volume/","tags":"","title":"Failed to Expand the Capacity of a Generic Ephemeral Volume"},{"body":"Symptom The huawei-csi services (huawei-csi-controller or huawei-csi-node) cannot be started. After the kubectl get pod -A | grep huawei command is executed, the command output shows that the service status is InvalidImageName.\nkubectl get pod -A | grep huawei The following is an example of the command output.\nhuawei-csi huawei-csi-controller-fd5f97768-qlldc 6/9 InvalidImageName 0 16s huawei-csi huawei-csi-node-25txd 2/3 InvalidImageName 0 15s Root Cause Analysis In the .yaml configuration files of the controller and node, the Huawei CSI image version number is incorrect. For example:\n... - name: huawei-csi-driver image: huawei-csi:4.5.0 ... Solution or Workaround Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to modify the configuration file of the huawei-csi-node service. Press I or Insert to enter the insert mode and modify related parameters. After the modification is complete, press Esc and enter :wq! to save the modification.\nkubectl edit daemonset huawei-csi-node -o yaml -n=huawei-csi In huawei-csi-driver in the sample .yaml file, modify image to Huawei CSI image huawei-csi:4.5.0. containers: ... - name: huawei-csi-driver image: huawei-csi:4.5.0 Run the following command to modify the configuration file of the huawei-csi-controller service: Press I or Insert to enter the insert mode and modify related parameters. After the modification is complete, press Esc and enter :wq! to save the modification.\nkubectl edit deployment huawei-csi-controller -o yaml -n=huawei-csi In huawei-csi-driver in the sample .yaml file, modify image to Huawei CSI image huawei-csi:4.5.0. containers: ... - name: huawei-csi-driver image: huawei-csi:4.5.0 Wait until the huawei-csi-node and huawei-csi-controller services are started.\nRun the following command to check whether the huawei-csi services are started.\nkubectl get pod -A | grep huawei The following is an example of the command output. If the Pod status is Running, the services are started successfully.\nhuawei-csi huawei-csi-controller-58799449cf-zvhmv 9/9 Running 0 2m29s huawei-csi huawei-csi-node-7fxh6 3/3 Running 0 12m ","categories":"","description":"","excerpt":"Symptom The huawei-csi services (huawei-csi-controller or …","ref":"/css-docs/en/docs/troubleshooting/huawei-csi-service-issues/failed-to-start-huawei-csi-services-with-the-status-displayed-as-invalidimagename/","tags":"","title":"Failed to Start huawei-csi Services with the Status Displayed as InvalidImageName"},{"body":"在使用Helm安装CSI时，需要您根据部署时需要使用的特性准备Helm工程的values.yaml文件。华为CSI已经在软件包的helm/esdk目录下提供了values.yaml模板文件。\n本章节将详细说明values.yaml中的配置项以及典型场景下的后端配置示例。\nimages参数配置说明 values.yaml中的images配置项主要配置华为CSI运行时依赖的组件镜像信息。需要配置的参数如下：\n表 1 images配置项说明\n参数\n描述\n必选参数\n默认值\nimages.huaweiCSIService\nhuawei-csi镜像。\n是\nhuawei-csi:4.5.0\nimages.storageBackendSidecar\n华为后端管理sidecar镜像。\n是\nstorage-backend-sidecar:4.5.0\nimages.storageBackendController\n华为后端管理控制器镜像。\n是\nstorage-backend-controller:4.5.0\nimages.huaweiCSIExtender\nhuawei-csi-extender镜像\n否\nhuawei-csi-extender:4.5.0\nimages.sidecar.livenessProbe\nlivenessprobe sidecar镜像。\n是\nk8s.gcr.io/sig-storage/livenessprobe:v2.5.0\nimages.sidecar.provisioner\ncsi-provisioner sidecar镜像。\n是\nk8s.gcr.io/sig-storage/csi-provisioner:v3.0.0\nimages.sidecar.attacher\ncsi-attacher sidecar镜像。\n是\nk8s.gcr.io/sig-storage/csi-attacher:v3.4.0\nimages.sidecar.resizer\ncsi-resizer sidecar镜像。\n是\nk8s.gcr.io/sig-storage/csi-resizer:v1.4.0\nimages.sidecar.snapshotter\ncsi-snapshotter sidecar镜像。\n是\nk8s.gcr.io/sig-storage/csi-snapshotter:v4.2.1\nimages.sidecar.snapshotController\nsnapshot-controller sidecar镜像。\n是\nk8s.gcr.io/sig-storage/snapshot-controller:v4.2.1\nimages.sidecar.registrar\ncsi-node-driver-registrar sidecar镜像。\n是\nk8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.3.0\nhuaweiCSIService、storageBackendSidecar、storageBackendController、huaweiCSIExtender参数的值，请参考上传华为CSI镜像章节的说明，使用最终生成镜像的名称和版本。 其他sidecar镜像参数，请参考检查CSI依赖的镜像章节的说明，使用最终上传的镜像的名称和版本。 controller参数配置说明 controller配置项用于配置huawei-csi-controller组件的相关配置。\n表 2 controller配置项说明\n参数\n描述\n必选参数\n默认值\n备注\ncontroller.controllerCount\nhuawei-csi-controller组件的副本数\n是\n1\n-\ncontroller.volumeNamePrefix\nPV名称的前缀，默认值为pvc，即创建的PV名称为：pvc-\u003cuuid\u003e。前缀必须满足DNS 子域名的命名规则，且PV名称总长度不得超过253个字符。\n否\npvc\n对应的provisioner参数名称为：--volume-name-prefix。\n建议前缀不超过20个字符。\n详细配置请参考配置PV名称前缀。\n对接后端是OceanStor V5 SAN时，建议前缀不超过5个字符。对接后端是OceanStor V5 NAS存储时，前缀只能包含小写字母、'-'，以及数字。对接后端是OceanStor Dorado和OceanStor存储时，前缀只能包含小写字母、'-'，以及数字。对接后端是OceanStor Pacific系列存储时，前缀只能包含字母、数字、“_”、“-”和“.”，且总长度限制为58字符。对接后端是FusionStorage Block时，前缀只能包含字母、数字、“_”和“-”，且总长度限制为58字符。 controller.webhookPort\nwebhook服务使用的端口。\n是\n4433\n如果存在端口冲突可修改为其他未占用的端口。\ncontroller.snapshot.enabled\n是否开启快照特性。\n是\ntrue\n如果要使用快照相关功能，请开启该特性。\n要求Kubernetes版本高于v1.17。\ncontroller.resizer.enabled\n是否开启扩容特性。\n是\ntrue\n要求Kubernetes版本高于v1.16。\ncontroller.nodeSelector\nhuawei-csi-controller的节点选择器。配置后huawei-csi-controller仅会调度到存在该标签的节点上。\n否\n-\n节点选择器的详细说明请参考：将 Pod 分配给节点\ncontroller.tolerations\nhuawei-csi-controller的污点容忍。配置后huawei-csi-controller能够容忍节点上存在该污点。\n否\n-\n污点和容忍度的详细说明请参考：污点和容忍度\ncontroller.livenessProbePort\nhuawei-csi-controller的存活性探针端口，用于健康检查。\n是\n9808\n如果存在端口冲突可修改为其他未占用的端口\ncontroller.csiExtender.volumeModify.enabled\n是否开启PVC变更特性。\n否\nfalse\n如果要PVC变更相关功能，请开启该特性。\ncontroller.csiExtender.volumeModify.retryBaseDelay\nPVC变更创建任务失败时的最小重试间隔。\n否\n5s\n建议使用默认值。\ncontroller.csiExtender.volumeModify.retryMaxDelay\nPVC变更创建任务失败时的最大重试间隔。\n否\n5m\n建议使用默认值。\ncontroller.csiExtender.volumeModify.reconcileDelay\n调协VolumeModifyClaim对象的间隔。\n否\n1s\n建议使用默认值。\n当controller.snapshot.enabled参数配置为true时，需要安装“helm/crd/snapshot-crds”目录下的卷快照CRD资源。\nnode参数配置说明 node配置项用于配置huawei-csi-node组件的相关配置。\n表 3 node配置项说明\n参数\n描述\n必选参数\n默认值\n备注\nnode.maxVolumesPerNode\n节点可使用的华为CSI发放卷的最大数量。不定义或者配置为0时则认为不限制。\n如果创建Pod时，指定 nodeName，则会忽略该配置。\n否\n100\n详细说明请参考：Volume Limits\nnode.nodeSelector\nhuawei-csi-node的节点选择器。配置后huawei-csi-node仅会调度到存在该标签的节点上。\n否\n-\n节点选择器的详细说明请参考：将 Pod 分配给节点\nnode.tolerations\nhuawei-csi-node的污点容忍。配置后huawei-csi-node能够容忍节点上存在该污点。\n否\n- key: \"node.kubernetes.io/memory-pressure\" operator: \"Exists\" effect: \"NoExecute\" - key: \"node.kubernetes.io/disk-pressure\" operator: \"Exists\" effect: \"NoExecute\" - key: \"node.kubernetes.io/network-unavailable\" operator: \"Exists\" effect: \"NoExecute\" 污点和容忍度的详细说明请参考：污点和容忍度\nnode.livenessProbePort\nhuawei-csi-node的存活性探针端口，用于健康检查。\n是\n9800\n如果存在端口冲突可修改为其他未占用的端口\nnode.kubeletVolumeDevicesDirName\nkubelet挂载块设备时的目录名称。\n否\nvolumeDevices\n当一个块设备被成功挂载之后，挂载路径的目录结构应该如下所示：\n/var/lib/kubelet/plugins/kubernetes.io/csi/{kubeletVolumeDevicesDirName}/publish/{specName}/{podUID} csiDriver参数配置说明 csiDriver配置项包括了华为CSI运行时的基本配置，如华为驱动名称、多路径类型等配置信息。\n表 4 csiDriver配置项说明\n参数\n描述\n必选参数\n默认值\n备注\ncsiDriver.driverName\n注册的驱动名称。\n是\ncsi.huawei.com\n直接使用默认值。对于CCE Agile平台，需要修改该字段，例如：csi.oceanstor.com。 csiDriver.endpoint\n通信端点。\n是\n/csi/csi.sock\n直接使用默认值。\ncsiDriver.connectorThreads\n最大并发扫盘/卸盘数。参数格式为整型，支持范围为1~10。\n是\n4\n该值设置越大，同一时间单个节点中的针对多路径的扫盘、卸盘并发操作就越多。在使用DM-Multipath时，并发数过大可能会导致未知问题，影响整体时间。\ncsiDriver.volumeUseMultipath\n是否使用多路径软件。参数格式为布尔值。\n是\ntrue\n强烈建议开启多路径软件，以增强存储链路的冗余度和性能。\ncsiDriver.scsiMultipathType\n存储协议为fc/iscsi时，使用的多路径软件。支持配置如下参数：\nDM-multipathHW-UltraPathHW-UltraPath-NVMe 当volumeUseMultipath为true时必填。\nDM-multipath\n建议使用DM-multipath取值。\ncsiDriver.nvmeMultipathType\n存储协议为roce/fc-nvme时，使用的多路径软件。仅支持配置HW-UltraPath-NVMe。\n当volumeUseMultipath为true时必填。\nHW-UltraPath-NVMe\n-\ncsiDriver.scanVolumeTimeout\n在主机上使用DM-Multipath多路径时，等待多路径聚合的超时时间，支持范围为1~600，单位秒。\n是\n3\n-\ncsiDriver.execCommandTimeout\n在主机上执行命令的超时时间\n是\n30\nCSI插件在挂载，扩容盘符等场景下，需要运行一些主机命令，例如使用mount命令挂载文件系统。该配置用于控制执行单条命令的超时时间。\ncsiDriver.allPathOnline\n是否检查DM-Multipath软件聚合的路径数等于实际在线的路径数，支持配置如下参数：\ntrue：DM-Multipath软件聚合的路径数等于实际在线的路径数才满足盘符挂载条件。false：默认不检查DM-Multipath软件聚合的路径数量，只要聚合出虚拟盘符，即满足盘符挂载条件。 当csiDriver.scsiMultipathType为DM-multipath时必填。\nfalse\n-\ncsiDriver.backendUpdateInterval\n后端能力的更新时间间隔，支持范围60~600，单位秒。\n是\n60\n-\ncsiDriver.controllerLogging.module\ncontroller日志记录类型。支持配置如下参数：\nfileconsole 是\nfile\n使用file选项时，日志将被保留在节点指定的目录下，当CSI所在的Pod被销毁时，日志仍然被保留。\n使用console选项时，日志将被保留在CSI所在Pod的临时空间中，当CSI所在的Pod被销毁时，日志也随之被销毁。\ncsiDriver.controllerLogging.level\ncontroller日志输出级别。支持配置如下参数：\ndebuginfowarningerrorfatal 是\ninfo\n-\ncsiDriver.controllerLogging.fileDir\ncontroller日志在file输出模式下的日志目录。\n是\n/var/log/huawei\n请确保该目录下有足够的空间保留日志。空间大小建议不小于200 MB。\ncsiDriver.controllerLogging.fileSize\ncontroller日志在file输出模式下单个日志文件大小。\n是\n20M\n-\ncsiDriver.controllerLogging.maxBackups\ncontroller日志在file输出模式下日志文件备份上限。\n是\n9\n-\ncsiDriver.nodeLogging.module\nnode日志记录类型。支持配置如下参数：\nfileconsole 是\nfile\n使用file选项时，日志将被保留在节点指定的目录下，当CSI所在的Pod被销毁时，日志仍然被保留。\n使用console选项时，日志将被保留在CSI所在Pod的临时空间中，当CSI所在的Pod被销毁时，日志也随之被销毁。\ncsiDriver.nodeLogging.level\nnode日志输出级别。支持配置如下参数：\ndebuginfowarningerrorfatal 是\ninfo\n-\ncsiDriver.nodeLogging.fileDir\nnode日志在file输出模式下的日志目录。\n是\n/var/log/huawei\n请确保该目录下有足够的空间保留日志。空间大小建议不小于200 MB。\ncsiDriver.nodeLogging.fileSize\nnode日志在file输出模式下单个日志文件大小。\n是\n20M\n-\ncsiDriver.nodeLogging.maxBackups\nnode日志在file输出模式下日志文件备份上限。\n是\n9\n-\n如果您的容器环境已经部署了华为CSI，请确保csiDriver.driverName的设置和之前部署时的配置保持一致。否则会导致系统中已存在的有华为CSI发放的卷/快照无法被新部署的华为CSI管理。\n其他参数配置说明 其他配置项包括了CSI插件某些特性的开关或者镜像获取策略。\n表 5 其他配置项说明\n参数\n描述\n必选参数\n默认值\n备注\nkubernetes.namespace\n华为CSI运行时所在Kubernetes命名空间，支持用户自定义。名称必须由小写字母、数字和“-”组成，例如：my-name、123-abc。\n否\nhuawei-csi\n-\nkubeletConfigDir\nkubelet工作目录。\n是\n/var/lib/kubelet\n直接使用默认值。对于Tanzu平台，需要修改该字段为/var/vcap/data/kubelet。对于CCE Agile平台，需要修改该字段为/mnt/paas/kubernetes/kubelet。 sidecarImagePullPolicy\nsidecar镜像的拉取策略。\n是\nIfNotPresent\n-\nhuaweiImagePullPolicy\nhuawei-csi镜像的拉取策略。\n是\nIfNotPresent\n-\nCSIDriverObject.isCreate\n是否创建CSIDriver对象\n是\nfalse\nCSIDriver特性在Kubernetes v1.18成为GA版本，因此要求Kubernetes版本高于v1.18，当Kubernetes版本低于 v1.18时，请设置该参数为false。\nCSIDriverObject.attachRequired\nCSI插件是否跳过attach操作。支持配置如下参数：\ntrue：需要attach操作。false：跳过attach操作。 是\ntrue\n参数attachRequired在Kubernetes v1.18支持配置。\n如果CSIDriverObject.isCreate为true并且attachRequired参数设置为false时，huawei-csi插件将不会部署csi-attacher这个sidecar。\n使用NAS存储时支持配置为false。使用SAN存储时，请配置为true。 CSIDriverObject.fsGroupPolicy\n基础卷是否支持在装载之前更改卷的所有权和权限。支持配置如下参数：\n\"ReadWriteOnceWithFSType\"：仅当定义了fsType并且卷的accessModes包含ReadWriteOnce时，才支持卷所有权和权限更改。\"File\"：Kubernetes可以使用fsGroup更改卷的权限和所有权，以匹配Pod安全策略中用户请求的fsGroup，而不管fsGroup或accessModes如何。\"None\"：将在不进行修改的情况下装载卷。\"null\"：将不设置fsGroupPolicy参数 否\nnull\n参数fsGroupPolicy在Kubernetes v1.20支持配置，并且当CSIDriverObject.isCreate为true时该参数生效。\n该特性在Kubernetes v1.20中为Beta版本，在Kubernetes v1.23成为GA版本，因此要求Kubernetes版本高于v1.20。\nleaderElection.leaseDuration\n领导者持续时间。\n否\n8s\n仅多controller场景生效。\nleaderElection.renewDeadline\n领导者重新选举时间。\n否\n6s\n仅多controller场景生效。\nleaderElection.retryPeriod\n领导者选举重试时间。\n否\n2s\n仅多controller场景生效。\n请确保此kubernetes.namespace填入的命名空间在Kubernetes上已经存在，如果不存在请使用如下命令创建对应的命名空间。本例中，华为CSI运行的命名空间为“huawei-csi”。\nkubectl create namespace huawei-csi ","categories":"","description":"","excerpt":"在使用Helm安装CSI时，需要您根据部署时需要使用的特性准备Helm工程的values.yaml文件。华为CSI已经在软件包 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%AE%89%E8%A3%85%E5%8D%8E%E4%B8%BAcsi/%E4%BD%BF%E7%94%A8helm%E5%AE%89%E8%A3%85%E5%8D%8E%E4%B8%BAcsi/helm-values-yaml%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E/","tags":"","title":"Helm values.yaml参数说明"},{"body":"帮助说明 获取oceanctl帮助说明。\noceanctl --help 查看oceanctl版本号。\noceanctl version 指定自定义日志文件目录，以查看oceanctl版本号为例。\noceanctl version --log-dir=/path/to/custom 创建存储后端 执行以下命令获取创建后端帮助。\noceanctl create backend -h 执行以下命令根据指定的yaml文件创建存储后端。\noceanctl create backend -f /path/to/backend.yaml -i yaml 执行以下命令根据指定的json文件创建存储后端，json文件仅支持通过json格式导出huawei-csi-configmap文件。\noceanctl create backend -f /path/to/configmap.json -i json 执行以下命令在指定命名空间创建一个存储后端。\noceanctl create backend -f /path/to/backend.yaml -i yaml -n \u003cnamespace\u003e 执行以下命令创建存储后端，并忽略存储后端名称校验，例如大写和字符“_”，非必要请勿使用该命令。\noceanctl create backend -f /path/to/backend.yaml -i yaml --not-validate-name 执行以下命令创建存储后端，并指定provisioner，其中“csi.oceanstor.com”是安装时指定的驱动名称，详情可以参考4。\n仅在CCE / CCE Agile平台创建后端时使用该命令。\noceanctl create backend -f /path/to/backend.yaml -i yaml --provisioner=csi.oceanstor.com 查询存储后端 执行以下命令获取查询后端帮助。\noceanctl get backend -h 执行以下命令查询默认命名空间下单个存储后端。\noceanctl get backend \u003cbackend-name\u003e 执行以下命令查询指定命名空间下所有存储后端。\noceanctl get backend -n \u003cnamespace\u003e 执行以下命令格式化输出，当前支持json，yaml和wide。\noceanctl get backend \u003cbackend-name\u003e -o json 更新存储后端 执行以下命令获取更新后端帮助。\noceanctl update backend -h 执行以下命令更新默认命名空间下指定存储后端信息。\noceanctl update backend \u003cbackend-name\u003e --password 执行以下命令更新指定命名空间存储后端信息。\noceanctl update backend \u003cbackend-name\u003e -n \u003cnamespace\u003e --password 删除存储后端 执行以下命令获取删除后端帮助。\noceanctl delete backend -h 执行以下命令删除默认命名空间下指定存储后端。\noceanctl delete backend \u003cbackend-name\u003e 执行以下命令删除默认命名空间下所有存储后端。\noceanctl delete backend --all 执行以下命令删除指定命名空间下存储后端。\noceanctl delete backend \u003cbackend-name...\u003e -n \u003cnamespace\u003e 创建存储后端证书 执行以下命令获取查询证书帮助。\noceanctl create cert -h 执行以下命令根据指定的crt证书文件为默认命名空间单个存储后端创建证书。\noceanctl create cert \u003cname\u003e -f /path/to/cert.crt -b \u003cbackend-name\u003e 执行以下命令根据指定的crt证书文件为指定命名空间单个存储后端创建证书。\noceanctl create cert \u003cname\u003e -f /path/to/cert.crt -b \u003cbackend-name\u003e -n \u003cnamespace\u003e 执行以下命令根据指定的pem证书文件为指定命名空间单个存储后端创建证书。\noceanctl create cert \u003cname\u003e -f /path/to/cert.pem -b \u003cbackend-name\u003e -n \u003cnamespace\u003e 查询存储后端证书 执行以下命令获取查询证书帮助。\noceanctl get cert -h 执行以下命令查询默认命名空间指定存储后端的证书。\noceanctl get cert -b \u003cbackend-name\u003e 执行以下命令查询指定命名空间下指定存储后端的证书。\noceanctl get cert -b \u003cbackend-name\u003e -n \u003cnamespace\u003e 更新存储后端证书 执行以下命令获取更新证书帮助。\noceanctl update cert -h 执行以下命令根据指定的crt证书文件为默认命名空间指定存储后端更新证书。\noceanctl update cert -b \u003cbackend-name\u003e -f /path/to/cert.crt 执行以下命令根据指定的crt证书文件为指定命名空间指定存储后端更新证书。\noceanctl update cert -b \u003cbackend-name\u003e -n \u003cnamespace\u003e -f /path/to/cert.crt 执行以下命令根据指定的pem证书文件为指定命名空间指定存储后端更新证书。\noceanctl update cert -b \u003cbackend-name\u003e -n \u003cnamespace\u003e -f /path/to/cert.pem 删除存储后端证书 执行以下命令获取删除证书帮助。\noceanctl delete cert -h 执行以下命令删除默认命名空间指定存储后端的证书。\noceanctl delete cert -b \u003cbackend-name\u003e 执行以下命令删除指定命名空间指定存储后端的证书。\noceanctl delete cert -b \u003cbackend-name\u003e -n \u003cnamespace\u003e ","categories":"","description":"","excerpt":"帮助说明 获取oceanctl帮助说明。\noceanctl --help 查看oceanctl版本号。\noceanctl version 指 …","ref":"/css-docs/docs/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%AE%A1%E7%90%86/oceanctl%E5%91%BD%E4%BB%A4%E8%AF%B4%E6%98%8E/","tags":"","title":"oceanctl命令说明"},{"body":"When using Helm to install CSI, you need to prepare the values.yaml file of the Helm project based on the features required during deployment. Huawei CSI provides the values.yaml template file in the helm/esdk directory of the software package.\nThis section describes the configuration items in the values.yaml file and backend configuration examples in typical scenarios.\nimages Parameters The images parameters in the values.yaml file are used to configure the component image information on which Huawei CSI depends during running. Set the following parameters:\nTable 1 images parameters\nParameter\nDescription\nMandatory\nDefault Value\nimages.huaweiCSIService\nhuawei-csi image.\nYes\nhuawei-csi:4.5.0\nimages.storageBackendSidecar\nHuawei back-end management sidecar image.\nYes\nstorage-backend-sidecar:4.5.0\nimages.storageBackendController\nHuawei back-end management controller image.\nYes\nstorage-backend-controller:4.5.0\nimages.huaweiCSIExtender\nhuawei-csi-extender image.\nNo\nhuawei-csi-extender:4.5.0\nimages.sidecar.livenessProbe\nlivenessprobe sidecar image.\nYes\nk8s.gcr.io/sig-storage/livenessprobe:v2.5.0\nimages.sidecar.provisioner\ncsi-provisioner sidecar image.\nYes\nk8s.gcr.io/sig-storage/csi-provisioner:v3.0.0\nimages.sidecar.attacher\ncsi-attacher sidecar image.\nYes\nk8s.gcr.io/sig-storage/csi-attacher:v3.4.0\nimages.sidecar.resizer\ncsi-resizer sidecar image.\nYes\nk8s.gcr.io/sig-storage/csi-resizer:v1.4.0\nimages.sidecar.snapshotter\ncsi-snapshotter sidecar image.\nYes\nk8s.gcr.io/sig-storage/csi-snapshotter:v4.2.1\nimages.sidecar.snapshotController\nsnapshot-controller sidecar image.\nYes\nk8s.gcr.io/sig-storage/snapshot-controller:v4.2.1\nimages.sidecar.registrar\ncsi-node-driver-registrar sidecar image.\nYes\nk8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.3.0\nFor details about the values of huaweiCSIService, storageBackendSidecar, storageBackendController, and huaweiCSIExtender, see Uploading a Huawei CSI Image. Use the name and version of the finally generated image. For details about other sidecar image parameters, see Checking the Images on Which CSI Depends. Use the name and version of the finally uploaded image. controller Parameters The controller parameters are used to configure the huawei-csi-controller component.\nTable 2 controller parameters\nParameter\nDescription\nMandatory\nDefault Value\nRemarks\ncontroller.controllerCount\nNumber of huawei-csi-controller component copies.\nYes\n1\nIf the Kubernetes version is earlier than v1.17, the huawei-csi-controller component can be deployed only in single-copy mode because the csi-provisioner sidecar image provided by the Kubernetes community does not support the --leader-election parameter.\nTherefore, if the Kubernetes version is earlier than v1.17, this parameter can only be set to 1.\ncontroller.volumeNamePrefix\nPV name prefix. The default value is pvc, that is, the name of a created PV is pvc-\u003cuuid\u003e. The prefix must comply with the naming rules of a DNS subdomain name, and the total length of the PV name cannot exceed 253 characters.\nNo\npvc\nThe corresponding provisioner parameter name is --volume-name-prefix.\nIt is recommended that the prefix contain no more than 20 characters.\nFor details, see Configuring the PV Name Prefix.\nIf the connected backend is OceanStor V5 SAN storage, it is recommended that the prefix contain a maximum of 5 characters.If the connected backend is OceanStor V5 NAS storage, the prefix can contain only lowercase letters, hyphens (-), and digits.If the connected backend is OceanStor Dorado or OceanStor storage, the prefix can contain only lowercase letters, hyphens (-), and digits.If the connected backend is OceanStor Pacific series storage, the prefix can contain a maximum of 58 characters, including only letters, digits, underscores (_), hyphens (-), and periods (.).If the connected backend is FusionStorage Block, the prefix can contain a maximum of 58 characters, including only letters, digits, underscores (_), and hyphens (-). controller.webhookPort\nPort used by the webhook service.\nYes\n4433\nIf a port conflict occurs, change the port number to an idle one.\ncontroller.snapshot.enabled\nWhether to enable the snapshot feature.\nYes\ntrue\nIf you want to use snapshot-related functions, enable this feature.\nThe Kubernetes version must be later than v1.17.\ncontroller.resizer.enabled\nWhether to enable the capacity expansion feature.\nYes\ntrue\nThe Kubernetes version must be later than v1.16.\ncontroller.nodeSelector\nNode selector of huawei-csi-controller. After this parameter is set, huawei-csi-controller will be scheduled only to a node with the label.\nNo\n-\nFor details about the node selector, see Assign Pods to Nodes.\ncontroller.tolerations\nTaint toleration of huawei-csi-controller. After this parameter is set, huawei-csi-controller can tolerate taints on a node.\nNo\n-\nFor details about taints and tolerations, see Taints and Tolerations.\ncontroller.livenessProbePort\nLiveness probe port of huawei-csi-controller, used for health check.\nYes\n9808\nIf a port conflict occurs, change the port number to an idle one.\ncontroller.csiExtender.volumeModify.enabled\nWhether to enable the PVC change feature.\nNo\nfalse\nIf you want to use PVC change-related functions, enable this feature.\ncontroller.csiExtender.volumeModify.retryBaseDelay\nMinimum retry interval when a PVC change fails to be created.\nNo\n5s\nThe default value is recommended.\ncontroller.csiExtender.volumeModify.retryMaxDelay\nMaximum retry interval when a PVC change fails to be created.\nNo\n5m\nThe default value is recommended.\ncontroller.csiExtender.volumeModify.reconcileDelay\nInterval for reconciling VolumeModifyClaim objects.\nNo\n1s\nThe default value is recommended.\nIf controller.snapshot.enabled is set to true, you need to install the volume snapshot CRD resource in the helm/crd/snapshot-crds directory.\nnode Parameters The node parameters are used to configure the huawei-csi-node component.\nTable 3 node parameters\nParameter\nDescription\nMandatory\nDefault Value\nRemarks\nnode.maxVolumesPerNode\nMaximum number of volumes provisioned by Huawei CSI that can be used by a node. If this parameter is not specified or is set to 0, the number is unlimited.\nIf nodeName is specified during Pod creation, this configuration will be ignored.\nNo\n100\nFor details, see Volume Limits.\nnode.nodeSelector\nNode selector of huawei-csi-node. After this parameter is set, huawei-csi-node will be scheduled only to a node with the label.\nNo\n-\nFor details about the node selector, see Assign Pods to Nodes.\nnode.tolerations\nTaint toleration of huawei-csi-node. After this parameter is set, huawei-csi-node can tolerate taints on a node.\nNo\n- key: \"node.kubernetes.io/memory-pressure\" operator: \"Exists\" effect: \"NoExecute\" - key: \"node.kubernetes.io/disk-pressure\" operator: \"Exists\" effect: \"NoExecute\" - key: \"node.kubernetes.io/network-unavailable\" operator: \"Exists\" effect: \"NoExecute\" For details about taints and tolerations, see Taints and Tolerations.\nnode.livenessProbePort\nLiveness probe port of huawei-csi-node, used for health check.\nYes\n9800\nIf a port conflict occurs, change the port number to an idle one.\nnode.kubeletVolumeDevicesDirName\nName of the directory where a block device is mounted to kubelet.\nNo\nvolumeDevices\nAfter a block device is successfully mounted, the directory structure of the mount path is as follows:\n/var/lib/kubelet/plugins/kubernetes.io/csi/{kubeletVolumeDevicesDirName}/publish/{specName}/{podUID} csiDriver Parameters The csiDriver parameters include the basic configurations for running Huawei CSI, such as Huawei driver name and multipathing type.\nTable 4 csiDriver parameters\nParameter\nDescription\nMandatory\nDefault Value\nRemarks\ncsiDriver.driverName\nRegistered driver name.\nYes\ncsi.huawei.com\nUse the default value.For the CCE Agile platform, modify this field. For example, csi.oceanstor.com. csiDriver.endpoint\nCommunication endpoint.\nYes\n/csi/csi.sock\nUse the default value.\ncsiDriver.connectorThreads\nMaximum number of disks that can be concurrently scanned/detached. The value is an integer ranging from 1 to 10.\nYes\n4\nA larger value indicates that more concurrent disk scanning and detaching operations are performed on a single node at the same time. When DM-Multipath is used, a large number of concurrent requests may cause unknown problems and affect the overall time.\ncsiDriver.volumeUseMultipath\nWhether to use multipathing software. The value is a Boolean value.\nYes\ntrue\nIt is strongly recommended that multipathing software be enabled to enhance the redundancy and performance of storage links.\ncsiDriver.scsiMultipathType\nMultipathing software used when the storage protocol is fc or iscsi. The following parameter values can be configured:\nDM-multipathHW-UltraPathHW-UltraPath-NVMe Mandatory when volumeUseMultipath is set to true.\nDM-multipath\nThe DM-multipath value is recommended.\ncsiDriver.nvmeMultipathType\nMultipathing software used when the storage protocol is roce or fc-nvme. Only HW-UltraPath-NVMe is supported.\nMandatory when volumeUseMultipath is set to true.\nHW-UltraPath-NVMe\n-\ncsiDriver.scanVolumeTimeout\nTimeout interval for waiting for multipathing aggregation when DM-Multipath is used on the host. The value ranges from 1 to 600 seconds.\nYes\n3\n-\ncsiDriver.execCommandTimeout\nTimeout interval for running commands on the host.\nYes\n30\nIn scenarios such as mounting and capacity expansion, the CSI plug-in needs to run some host commands, for example, running the mount command to mount a file system. This parameter is used to control the timeout interval for running a single command.\ncsiDriver.allPathOnline\nWhether to check whether the number of paths aggregated by DM-Multipath is equal to the actual number of online paths. The following parameter values can be configured:\ntrue: The drive letter mounting condition is met only when the number of paths aggregated by DM-Multipath is equal to the actual number of online paths.false: By default, the number of paths aggregated by DM-Multipath is not checked. As long as virtual drive letters are generated upon aggregation, the drive letter mounting condition is met. This parameter is mandatory when csiDriver.scsiMultipathType is set to DM-multipath.\nfalse\n-\ncsiDriver.backendUpdateInterval\nInterval for updating backend capabilities. The value ranges from 60 to 600 seconds.\nYes\n60\n-\ncsiDriver.controllerLogging.module\nRecord type of the controller log. The following parameter values can be configured:\nfileconsole Yes\nfile\nWhen the value is file, logs are retained in the specified directory of the node. When the Pod where CSI is located is destroyed, logs are still retained.\nWhen the value is console, logs are retained in the temporary space of the Pod where CSI is located. When the Pod where CSI is located is destroyed, the logs are also destroyed.\ncsiDriver.controllerLogging.level\nOutput level of the controller log. The following parameter values can be configured:\ndebuginfowarningerrorfatal Yes\ninfo\n-\ncsiDriver.controllerLogging.fileDir\nDirectory of the controller log in file output mode.\nYes\n/var/log/huawei\nEnsure that the directory has sufficient space for storing logs. It is recommended that the space be greater than or equal to 200 MB.\ncsiDriver.controllerLogging.fileSize\nSize of a single controller log file in file output mode.\nYes\n20M\n-\ncsiDriver.controllerLogging.maxBackups\nMaximum number of controller log file backups in file output mode.\nYes\n9\n-\ncsiDriver.nodeLogging.module\nRecord type of the node log. The following parameter values can be configured:\nfileconsole Yes\nfile\nWhen the value is file, logs are retained in the specified directory of the node. When the Pod where CSI is located is destroyed, logs are still retained.\nWhen the value is console, logs are retained in the temporary space of the Pod where CSI is located. When the Pod where CSI is located is destroyed, the logs are also destroyed.\ncsiDriver.nodeLogging.level\nOutput level of the node log. The following parameter values can be configured:\ndebuginfowarningerrorfatal Yes\ninfo\n-\ncsiDriver.nodeLogging.fileDir\nDirectory of the node log in file output mode.\nYes\n/var/log/huawei\nEnsure that the directory has sufficient space for storing logs. It is recommended that the space be greater than or equal to 200 MB.\ncsiDriver.nodeLogging.fileSize\nSize of a single node log file in file output mode.\nYes\n20M\n-\ncsiDriver.nodeLogging.maxBackups\nMaximum number of node log file backups in file output mode.\nYes\n9\n-\nIf Huawei CSI has been deployed in your container environment, ensure that the value of csiDriver.driverName is the same as that configured during previous deployment. Otherwise, existing volumes or snapshots provisioned by Huawei CSI in the system cannot be managed by the newly deployed Huawei CSI.\nOther Parameters Other parameters include some features of the CSI plug-in or the policies for obtaining images.\nTable 5 Other parameters\nParameter\nDescription\nMandatory\nDefault Value\nRemarks\nkubernetes.namespace\nKubernetes namespace where Huawei CSI is running, which can be customized. The name must consist of lowercase letters, digits, and hyphens (-), for example, my-name and 123-abc.\nNo\nhuawei-csi\n-\nkubeletConfigDir\nWorking directory of kubelet.\nYes\n/var/lib/kubelet\nUse the default value.For the Tanzu platform, change the value of this field to /var/vcap/data/kubelet.For the CCE Agile platform, change the value of this field to /mnt/paas/kubernetes/kubelet. sidecarImagePullPolicy\nPull policy of the sidecar image.\nYes\nIfNotPresent\n-\nhuaweiImagePullPolicy\nPull policy of the huawei-csi image.\nYes\nIfNotPresent\n-\nCSIDriverObject.isCreate\nWhether to create the CSIDriver object.\nYes\nfalse\nThe CSIDriver feature is a GA version in Kubernetes v1.18. Therefore, to use this feature, the Kubernetes version must be later than v1.18. If the Kubernetes version is earlier than v1.18, set this parameter to false.\nCSIDriverObject.attachRequired\nWhether the CSI plug-in skips the attach operation. The following parameter values can be configured:\ntrue: The attach operation is required.false: The attach operation is skipped. Yes\ntrue\nThe attachRequired parameter can be configured in Kubernetes v1.18.\nIf CSIDriverObject.isCreate is set to true and attachRequired is set to false, the huawei-csi plug-in will not deploy the csi-attacher sidecar.\nIf NAS storage is used, this parameter can be set to false.If SAN storage is used, set this parameter to true. CSIDriverObject.fsGroupPolicy\nWhether the ownership and permissions of a basic volume can be changed before the volume is mounted. The following parameter values can be configured:\n\"ReadWriteOnceWithFSType\": The volume ownership and permission can be changed only when fsType is specified and accessModes of the volume contains ReadWriteOnce.\"File\": Kubernetes can use fsGroup to change the permissions and ownership of a volume to match fsGroup requested by a user in the Pod security policy, regardless of fsGroup or accessModes.\"None\": A volume is mounted without any change.\"null\": The fsGroupPolicy parameter is not set. No\nnull\nThe fsGroupPolicy parameter can be configured in Kubernetes v1.20, and takes effect only when CSIDriverObject.isCreate is set to true.\nThis feature is a Beta version in Kubernetes v1.20 but a GA version in Kubernetes v1.23. Therefore, the Kubernetes version must be later than v1.20.\nleaderElection.leaseDuration\nLeader duration.\nNo\n8s\nThis parameter takes effect only in the multi-controller scenario.\nleaderElection.renewDeadline\nTime for the leader to be re-elected.\nNo\n6s\nThis parameter takes effect only in the multi-controller scenario.\nleaderElection.retryPeriod\nLeader election retry time.\nNo\n2s\nThis parameter takes effect only in the multi-controller scenario.\nEnsure that the namespace entered in kubernetes.namespace exists on Kubernetes. If the namespace does not exist, run the following command to create it. In this example, the namespace for running Huawei CSI is huawei-csi.\nkubectl create namespace huawei-csi ","categories":"","description":"","excerpt":"When using Helm to install CSI, you need to prepare the values.yaml …","ref":"/css-docs/en/docs/installation-and-deployment/installing-huawei-csi/installing-huawei-csi-using-helm/parameters-in-the-values-yaml-file-of-helm/","tags":"","title":"Parameters in the values.yaml File of Helm"},{"body":"This section describes how to use Huawei CSI to complete a PVC change.\n","categories":"","description":"","excerpt":"This section describes how to use Huawei CSI to complete a PVC change. …","ref":"/css-docs/en/docs/advanced-features/pvc-change/","tags":"","title":"PVC Change"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/en/docs/troubleshooting/pvc-issues/","tags":"","title":"PVC Issues"},{"body":"After configuring a StorageClass, you can use the StorageClass to configure a PVC. For details about the PVC configuration template, see example file pvc*.yaml in the examples directory in Huawei CSI software package.\nTable 1 Parameters in the pvc*.yaml file\nParameter\nDescription\nMandatory\nDefault Value\nRemarks\nmetadata.name\nUser-defined name of a PVC object.\nYes\n-\nTake Kubernetes v1.22.1 as an example. The value can contain digits, lowercase letters, hyphens (-), and periods (.), and must start and end with a letter or digit.\nspec.volumeMode\nVolume mode. This parameter is optional. When LUN volumes are used, the following types are supported:\nFilesystem: local file system.Block: raw device. No\nFilesystem\nThis parameter takes effect when a PV is mounted. The default value is Filesystem.\nFilesystem indicates that a container accesses a PV using a local file system. The local file system type is specified by the fsType field in the specified StorageClass. Storage of the Dtree type also uses this parameter.Block indicates that a PV is accessed in raw volume mode. spec.storageClassName\nName of the StorageClass object.\nYes\n-\nName of the StorageClass object required by services.\nspec.resources.requests.storage\nSize of the volume to be created. The format is ***Gi and the unit is GiB. The size must be an integer multiple of 512 bytes.\nYes\n10Gi\nThe PVC capacity depends on storage specifications and host specifications. For example, OceanStor Dorado 6.1.2 or OceanStor Pacific series 8.1.0 is connected to CentOS 7. If ext4 file systems are used, see Table 2. If XFS file systems are used, see Table 3. If NFS or raw devices are used, the capacity must meet the specifications of the used Huawei storage device model and version.\nIf the PVC capacity does not meet the specifications, a PVC or Pod may fail to be created due to the limitations of storage specifications or host file system specifications.\nspec.accessModes\nAccess mode of the volume.\nRWO (ReadWriteOnce): A volume can be mounted to a node in read/write mode. This mode also allows multiple Pods running on the same node to access the volume.ROX (ReadOnlyMany): A volume can be mounted to multiple nodes in read-only mode.RWX (ReadWriteMany): A volume can be mounted to multiple nodes in read/write mode.RWOP (ReadWriteOncePod): A volume can only be mounted to a single Pod in read/write mode. Kubernetes 1.22 and later versions support this feature. Yes\nReadWriteOnce\nRWO/ROX/RWOP: supported by all types of volumes. RWOP is supported only by Kubernetes 1.22 and later versions. Check whether this feature is enabled for your Kubernetes cluster by referring to Enabling the ReadWriteOncePod Feature Gate.The support for RWX is as follows:NAS storage: supported by all volumesSAN storage: supported only by volumes whose volumeMode is set to Block Table 2 ext4 capacity specifications\nStorage Type\nStorage Specifications\next4 Specifications\nCSI Specifications\nOceanStor Dorado 6.1.2\n512 Ki to 256 Ti\n50 Ti\n512 Ki to 50 Ti\nOceanStor Pacific series 8.1.0\n64 Mi to 512 Ti\n50 Ti\n64 Mi to 50 Ti\nTable 3 XFS capacity specifications\nStorage Type\nStorage Specifications\nXFS Specifications\nCSI Specifications\nOceanStor Dorado 6.1.2\n512 Ki to 256 Ti\n500 Ti\n512 Ki to 500 Ti\nOceanStor Pacific series 8.1.0\n64 Mi to 512 Ti\n500 Ti\n64 Mi to 500 Ti\n","categories":"","description":"","excerpt":"After configuring a StorageClass, you can use the StorageClass to …","ref":"/css-docs/en/docs/using-huawei-csi/managing-a-pvc/creating-a-pvc/dynamic-volume-provisioning/pvc-parameters-for-dynamic-volume-provisioning/","tags":"","title":"PVC Parameters for Dynamic Volume Provisioning"},{"body":"After configuring a StorageClass, you can use the StorageClass to configure a PVC. For details about the PVC configuration template, see example file pvc-manager.yaml in the examples directory in Huawei CSI software package.\nTable 1 Parameters in the pvc-manager.yaml file\nParameter\nDescription\nMandatory\nDefault Value\nRemarks\nmetadata.annotations\nPVC object annotations. Set the following parameters:\nDriver name/manageVolumeName: volume name on the storage.Driver name/manageBackendName: name of the backend to which the volume belongs. Yes\ncsi.huawei.com/manageVolumeName: * csi.huawei.com/manageBackendName: *\nFor details about how to obtain Driver name, see Table 4.Driver name/manageVolumeName: name of an existing volume on the storage. Only English characters are supported.Driver name/manageBackendName: name of the storage backend in CSI. You can run the oceanctl get backend -n huawei-csi command to obtain the backend name.\nmetadata.labels\nPVC object labels.\nNo\n-\nFormat: provisioner: Driver name specified during installation\nExample: provisioner: csi.huawei.com\nThis parameter takes effect when a PVC is created. It is used to listen to PVC resources and obtain information about metadata.annotations.\nmetadata.name\nUser-defined name of a PVC object.\nYes\n-\nTake Kubernetes v1.22.1 as an example. The value can contain digits, lowercase letters, hyphens (-), and periods (.), and must start and end with a letter or digit.\nspec.volumeMode\nVolume mode. This parameter is optional. When LUN volumes are used, the following types are supported:\nFilesystem: local file system.Block: raw device. NOTE: This parameter takes effect when a PV is mounted. The use method of this parameter must be the same as that of the managed volume.\nIf a volume is used as a raw volume before being managed, volumeMode must be set to Block.If a volume is used in ext2, ext3, or ext4 mode before being managed, volumeMode must be set to Filesystem and fsType in the StorageClass must be set to ext2, ext3, or ext4.If a volume is used in XFS mode before being managed, volumeMode must be set to Filesystem and fsType in the StorageClass must be set to xfs. No\nFilesystem\nThis parameter takes effect when a PV is mounted.\nFilesystem indicates that a container accesses a PV using a local file system. The local file system type is specified by the fsType field in the specified StorageClass.Block indicates that a PV is accessed in raw volume mode. spec.storageClassName\nName of the StorageClass object.\nYes\n-\nThe configuration of the StorageClass must be the same as that of the managed volume.\nspec.resources.requests.storage\nSize of the volume to be created. The format is ***Gi and the unit is GiB. The size must be an integer multiple of 512 bytes.\nYes\n-\nThe PVC capacity depends on storage specifications and host specifications. For example, OceanStor Dorado 6.1.2 or OceanStor Pacific series 8.1.0 is connected to CentOS 7. If ext4 file systems are used, see Table 2. If XFS file systems are used, see Table 3. If NFS or raw devices are used, the capacity must meet the specifications of the used Huawei storage device model and version.\nIf the PVC capacity does not meet the specifications, a PVC or Pod may fail to be created due to the limitations of storage specifications or host file system specifications.\nspec.accessModes\nAccess mode of the volume.\nRWO (ReadWriteOnce): A volume can be mounted to a node in read/write mode. This mode also allows multiple Pods running on the same node to access the volume.ROX (ReadOnlyMany): A volume can be mounted to multiple nodes in read-only mode.RWX (ReadWriteMany): A volume can be mounted to multiple nodes in read/write mode.RWOP (ReadWriteOncePod): A volume can only be mounted to a single Pod in read/write mode. Kubernetes 1.22 and later versions support this feature. Yes\nReadWriteOnce\nRWO/ROX/RWOP: supported by all types of volumes. RWOP is supported only by Kubernetes 1.22 and later versions. Check whether this feature is enabled for your Kubernetes cluster by referring to Enabling the ReadWriteOncePod Feature Gate.The support for RWX is as follows:NAS storage: supported by all volumesSAN storage: supported only by volumes whose volumeMode is set to Block Table 2 ext4 capacity specifications\nStorage Type\nStorage Specifications\next4 Specifications\nCSI Specifications\nOceanStor Dorado 6.1.2\n512 Ki to 256 Ti\n50 Ti\n512 Ki to 50 Ti\nOceanStor Pacific series 8.1.0\n64 Mi to 512 Ti\n50 Ti\n64 Mi to 50 Ti\nTable 3 XFS capacity specifications\nStorage Type\nStorage Specifications\nXFS Specifications\nCSI Specifications\nOceanStor Dorado 6.1.2\n512 Ki to 256 Ti\n500 Ti\n512 Ki to 500 Ti\nOceanStor Pacific series 8.1.0\n64 Mi to 512 Ti\n500 Ti\n64 Mi to 500 Ti\n","categories":"","description":"","excerpt":"After configuring a StorageClass, you can use the StorageClass to …","ref":"/css-docs/en/docs/using-huawei-csi/managing-a-pvc/creating-a-pvc/manage-volume-provisioning/pvc-parameters-for-manage-volume-provisioning/","tags":"","title":"PVC Parameters for Manage Volume Provisioning"},{"body":"本章节介绍如何使用华为CSI完成PVC变更。\n","categories":"","description":"","excerpt":"本章节介绍如何使用华为CSI完成PVC变更。\n","ref":"/css-docs/docs/%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/pvc%E5%8F%98%E6%9B%B4/","tags":"","title":"PVC变更"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/pvc%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/","tags":"","title":"PVC相关问题"},{"body":"This chapter describes how to quickly install and use Huawei CSI to manage Persistent Volume Claims (PVCs).\nHuawei CSI Use Process Figure 1 CSI installation and use process\nCompatibility and Features Before using this plug-in, learn about its compatibility with Huawei storage, container platforms, and host operating systems (OSs), as well as supported features.\nCompatibility and Features\nInstallation Preparations Before installing Huawei CSI, you need to prepare the configurations of related environments such as container platforms and hosts.\nInstallation Preparations\nInstallation and Deployment Huawei CSI provides two installation modes: installation using Helm and manual installation, which are suitable for different container platforms such as Kubernetes and OpenShift.\nInstallation and Deployment\nCreating a Storage Backend Before using Huawei CSI, you need to create storage backend resources.\nCreating a Storage Backend\nUsing Huawei CSI Now, you can use Huawei CSI to manage PVCs.\nUsing Huawei CSI\n","categories":"","description":"","excerpt":"This chapter describes how to quickly install and use Huawei CSI to …","ref":"/css-docs/en/docs/quick-start/","tags":"","title":"Quick Start"},{"body":"Static volume provisioning allows administrators to use a resource created on the storage side as a PV for containers in the cluster.\nTo implement static volume provisioning, perform the following steps:\nConfiguring a PV Configuring a PVC Prerequisites A storage resource, such as a LUN or file system, required by the PV to be created exists on the storage device. If the storage resource is a file system, you also need to create the share and client information of the file system.\nConfiguring a PV Prepare the PV configuration file mypv.yaml. The following is an example. For details about other parameters, see PV Parameters for Static Volume Provisioning.\nkind: PersistentVolume apiVersion: v1 metadata: name: mypv spec: volumeMode: Filesystem storageClassName: \"\" # The value must be to \"\". accessModes: - ReadWriteOnce csi: driver: csi.huawei.com # Enter the CSI driver name. volumeHandle: iscsi-dorado-181.lun0001 # Enter the volume name. fsType: xfs # Set the file system type. capacity: storage: 100Gi In the configuration file for static volume provisioning, storageClassName must be set to \"\". Otherwise, Kubernetes will use the default StorageClass.\nRun the following command to create a PV based on the prepared .yaml file.\nkubectl create -f mypv.yaml After a period of time, run the following command to view the information about the created PV.\nkubectl get pv The following is an example of the command output. If the PV status is Available, the PV is successfully created.\nNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE mypv 100Gi RWO Retain Available 4s Configuring a PVC After a PV is created in static volume provisioning mode, you can create a PVC based on the PV for containers.\nPrepare the PVC configuration file. The following example is a PVC configuration file for static volume provisioning.\nkind: PersistentVolumeClaim apiVersion: v1 metadata: name: mypvc spec: storageClassName: \"\" accessModes: - ReadWriteOnce volumeMode: Filesystem resources: requests: storage: 100Gi volumeName: mypv # Enter the name of the corresponding PV. Run the following command to create a PVC based on the configured .yaml file.\nkubectl create -f mypvc.yaml After a period of time, run the following command to view the information about the created PVC.\nkubectl get pvc The following is an example of the command output. If the PVC status is Bound, the PVC is successfully created.\nNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE mypvc Bound pvc-840054d3-1d5b-4153-b73f-826f980abf9e 100Gi RWO 12s After the PVC is created, if the PVC is in the Pending state after a long time (for example, one minute), refer to When a PVC Is Created, the PVC Is in the Pending State. You are advised to create or delete a maximum of 100 PVCs in a batch. Using a PVC The use method is the same as that for dynamic volume provisioning in Using a PVC.\n","categories":"","description":"","excerpt":"Static volume provisioning allows administrators to use a resource …","ref":"/css-docs/en/docs/using-huawei-csi/managing-a-pvc/creating-a-pvc/static-volume-provisioning/","tags":"","title":"Static Volume Provisioning"},{"body":"This section describes how to uninstall the CSI-dependent component services.\nUninstalling the huawei-csi-host-info Object Secret object huawei-csi-host-info stores the initiator information about each node in the cluster, for example, iSCSI initiators. When you run the helm uninstall command, the resource will not be uninstalled. To uninstall the resource, perform the following steps:\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to delete the Secret object. huawei-csi-host-info is the name of the Secret object, and huawei-csi is the namespace where the Secret object is located.\nkubectl delete secret huawei-csi-host-info -n huawei-csi Run the following command to check whether the Secret object is successfully uninstalled.\nkubectl get secret huawei-csi-host-info -n huawei-csi The following is an example of the command output. If NotFound is displayed in the command output, the huawei-csi-host-info object is successfully uninstalled.\nError from server (NotFound): secrets \"huawei-csi-host-info\" not found Uninstalling a Webhook Resource The webhook resource named storage-backend-controller.xuanwu.huawei.io is used to verify the backend key information and connectivity with the storage. When you run the helm uninstall command, the resource will not be uninstalled. To uninstall the resource, perform the following steps:\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to query the webhook-dependent component service.\nkubectl get validatingwebhookconfigurations.admissionregistration.k8s.io storage-backend-controller.xuanwu.huawei.io The following is an example of the command output.\nNAME WEBHOOKS AGE storage-backend-controller.xuanwu.huawei.io 1 12d Run the following command to uninstall the webhook-dependent component service.\nkubectl delete validatingwebhookconfigurations.admissionregistration.k8s.io storage-backend-controller.xuanwu.huawei.io Run the following command to check whether the service is successfully uninstalled. If the command output is empty, the uninstallation is successful.\nkubectl get validatingwebhookconfigurations.admissionregistration.k8s.io storage-backend-controller.xuanwu.huawei.io Uninstalling the Snapshot-Dependent Component Service Do not uninstall the snapshot-dependent component service when snapshots exist. Otherwise, Kubernetes will automatically delete all user snapshots and they cannot be restored. Exercise caution when performing this operation. For details, see Delete a CustomResourceDefinition. Do not uninstall the snapshot-dependent component service during the CSI upgrade. Scenario Description\nCurrently, Huawei CSI uses the snapshot feature. Currently, only Huawei CSI is available in the Kubernetes cluster, and Huawei CSI is no longer used. Before the uninstallation, ensure that no VolumeSnapshot resource managed by Huawei CSI exists in the Kubernetes cluster. Procedure\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to uninstall the snapshot-dependent component service.\nkubectl delete crd volumesnapshotclasses.snapshot.storage.k8s.io volumesnapshotcontents.snapshot.storage.k8s.io volumesnapshots.snapshot.storage.k8s.io Run the following command to check whether the service is successfully uninstalled. If the command output is empty, the uninstallation is successful.\nkubectl get crd | grep snapshot.storage.k8s.io Uninstalling a Lease Resource If the value of the controller.controllerCount configuration item in the values.yaml file is greater than 1, huawei-csi-controller will be deployed in multi-copy mode. The multiple copies of huawei-csi-controller are implemented using the LeaderElection mechanism of Kubernetes. This mechanism creates a Lease object to store the current Holder information. When you run the helm uninstall command, the resource will not be uninstalled. To uninstall the resource, perform the following steps. If the value of controller.controllerCount is 1, you can skip the following steps. For details about the configuration item, see Table 2.\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to query the Lease information.\nkubectl get lease -n huawei-csi The following is an example of the command output.\nNAME HOLDER AGE csi-huawei-com node-1 24d external-attacher-leader-csi-huawei-com node-1 24d external-resizer-csi-huawei-com node-1 24d external-snapshotter-leader-csi-huawei-com node-1 24d snapshot-controller-leader node-1 24d storage-backend-controller node-1 24d huawei-csi-extender node-1 24d Run the following command to uninstall the Lease resource.\nkubectl delete lease -n huawei-csi csi-huawei-com external-attacher-leader-csi-huawei-com external-resizer-csi-huawei-com external-snapshotter-leader-csi- Run the following command to check whether the uninstallation is successful.\nkubectl get lease -n huawei-csi The following is an example of the command output. If the command output is empty, the uninstallation is successful.\nNo resources found in huawei-csi namespace. ","categories":"","description":"","excerpt":"This section describes how to uninstall the CSI-dependent component …","ref":"/css-docs/en/docs/installation-and-deployment/uninstalling-huawei-csi/uninstalling-huawei-csi-using-helm/uninstalling-csi-dependent-component-services/","tags":"","title":"Uninstalling CSI-Dependent Component Services"},{"body":"This chapter describes how to uninstall Huawei CSI. The uninstallation method varies according to the installation mode.\nIf you do not uninstall Huawei CSI for the purpose of an upgrade, ensure that all resources (such as PV, PVC, snapshot, and storage backend resources) provisioned by Huawei CSI have been cleared on your container platform before uninstalling Huawei CSI. Otherwise, once you uninstall Huawei CSI, these resources cannot be automatically scheduled, managed, or cleared.\n","categories":"","description":"","excerpt":"This chapter describes how to uninstall Huawei CSI. The uninstallation …","ref":"/css-docs/en/docs/installation-and-deployment/uninstalling-huawei-csi/","tags":"","title":"Uninstalling Huawei CSI"},{"body":" When oceanctl is used to update storage backend information, only the storage backend password can be updated. If the backend account password is updated on the storage device, the CSI plug-in will retry due to login failures. As a result, the account may be locked. If the account is locked, change the password by referring to An Account Is Locked After the Password Is Updated on the Storage Device. ","categories":"","description":"","excerpt":" When oceanctl is used to update storage backend information, only the …","ref":"/css-docs/en/docs/storage-backend-management/managing-storage-backends/updating-a-storage-backend/","tags":"","title":"Updating a Storage Backend"},{"body":"Before updating a certificate, prepare a new certificate file and update the storage backend certificate by following the instructions provided in this section. If the certificate is no longer used, delete the certificate from the storage backend by referring to Deleting a Storage Backend Certificate.\nProcedure Run the following command to obtain information about a storage backend.\noceanctl get backend The following is an example of the command output.\nNAMESPACE NAME PROTOCOL STORAGETYPE SN STATUS ONLINE URL huawei-csi backend-1 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.157:8088 huawei-csi backend-2 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.158:8088 Run the following command to check whether the specified storage backend has a certificate.\noceanctl get cert -b backend-1 The following is an example of the command output.\nNAMESPACE NAME BOUNDBACKEND huawei-csi cert-1 backend-1 Run the following command to update the certificate of the specified storage backend.\noceanctl update cert -b backend-1 -f /path/to/cert.crt ","categories":"","description":"","excerpt":"Before updating a certificate, prepare a new certificate file and …","ref":"/css-docs/en/docs/storage-backend-management/optional-adding-a-certificate-to-a-storage-backend/updating-a-storage-backend-certificate/","tags":"","title":"Updating a Storage Backend Certificate"},{"body":"Prerequisites You have downloaded the CSI software package of a new version.\nProcedure Uninstall CSI. For details, see Uninstalling Huawei CSI on CCE or CCE Agile. Install CSI of the new version. For details, see Installing Huawei CSI on the CCE or CCE Agile Platform. ","categories":"","description":"","excerpt":"Prerequisites You have downloaded the CSI software package of a new …","ref":"/css-docs/en/docs/installation-and-deployment/upgrading-or-rolling-back-huawei-csi/upgrading-or-rolling-back-huawei-csi-using-helm/upgrading-huawei-csi/upgrading-huawei-csi-on-cce-or-cce-agile/","tags":"","title":"Upgrading Huawei CSI on CCE or CCE Agile"},{"body":"现象描述 创建Pod时，Pod长时间处于ContainerCreating状态，此时查看huawei-csi-node的日志信息（详情请参考如何查看华为CSI日志），huawei-csi-node的日志中无创建Pod的日志记录，执行kubectl get volumeattachment命令后，PV列无该Pod使用的PV名称。在等待较长时间后（超过十分钟），Pod正常创建，Pod状态变为Running状态。\n根因分析 该问题是因为Kubernetes的kube-controller-manager组件服务异常导致。\n解决措施或规避方法 请联系容器平台侧工程师解决。\n","categories":"","description":"","excerpt":"现象描述 创建Pod时，Pod长时间处于ContainerCreating状态，此时查看huawei-csi-node的日志信息（详情请参考 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/pod%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/%E5%88%9B%E5%BB%BApod%E6%97%B6-pod%E7%9A%84%E7%8A%B6%E6%80%81%E9%95%BF%E6%97%B6%E9%97%B4%E5%A4%84%E4%BA%8Econtainercreating%E7%8A%B6%E6%80%81/","tags":"","title":"创建Pod时，Pod的状态长时间处于ContainerCreating状态"},{"body":"现象描述 用户在存储侧修改后端密码之后，该后端账号被锁定。\n根因分析 CSI登录存储时使用存储后端配置的账户和密码，当存储侧修改了该账户密码之后，CSI登录失败后会重试。以OceanStor Dorado存储为例，默认的登录策略是密码校验失败3次后将会锁定账户，因此当CSI重试超过3次之后，该账户就会被锁定。\n解决措施或规避方法 如果后端配置的账户是admin，请执行以下命令，将huawei-csi-controller服务副本数置为0，如果使用的是非admin账户，忽略此步骤。\nkubectl scale deployment huawei-csi-controller -n huawei-csi --replicas=0 使用admin账户登录存储，修改登录策略。以OceanStor Dorado存储为例，在DeviceManager管理界面，选择“设置 \u003e 用户与安全 \u003e 安全策略 \u003e登录策略 \u003e修改\u003e密码锁定”，取消密码锁定。\n如果如果后端配置的账户是admin，执行以下命令，通过“–replicas=*”恢复CSI Controller的副本数，下例为恢复至1个，请根据实际情况修改。如果使用的是非admin账户，忽略此步骤。\nkubectl scale deployment huawei-csi-controller -n huawei-csi --replicas=1 使用oceanctl工具修改存储后端密码，修改后端密码请参考更新存储后端章节。\n使用admin账户登录存储，修改登录策略，以OceanStor Dorado存储为例，在DeviceManager管理界面，选择“设置 \u003e 用户与安全 \u003e 安全策略 \u003e登录策略 \u003e修改\u003e密码锁定”，恢复密码锁定。\n","categories":"","description":"","excerpt":"现象描述 用户在存储侧修改后端密码之后，该后端账号被锁定。\n根因分析 CSI登录存储时使用存储后端配置的账户和密码，当存储侧修改了该账户密码 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/%E5%AD%98%E5%82%A8%E4%BE%A7%E6%9B%B4%E6%96%B0%E5%AF%86%E7%A0%81%E5%90%8E%E8%B4%A6%E6%88%B7%E8%A2%AB%E9%94%81%E5%AE%9A/","tags":"","title":"存储侧更新密码后账户被锁定"},{"body":"在完成配置StorageClass以后，就可以用该StorageClass来配置PVC。PVC的配置模板请参考华为CSI软件包中的examples目录下的pvc*.yaml文件示例。\n表 1 pvc*.yaml文件示例参数说明\n参数\n说明\n必选参数\n默认值\n备注\nmetadata.name\n自定义的PVC对象名称。\n是\n-\n以Kubernetes v1.22.1为例，支持数字、小写字母、中划线（-）和点（.）的组合，并且必须以字母数字开头和结尾。\nspec.volumeMode\n卷模式。可选参数。 当使用LUN类型的卷时，支持配置以下类型：\nFilesystem：本地文件系统。Block：裸设备。 否\nFilesystem\n该参数在挂载PV时生效，默认为Filesystem。\nFilesystem表示在容器通过一个本地文件系统访问PV，本地文件系统类型为指定StorageClass中的fsType字段指定, Dtree类型存储也使用此参数进行描述。Block表示使用裸卷的方式访问访问PV。 spec.storageClassName\nStorageClass对象名称。\n是\n-\n业务需要的StorageClass对象名称。\nspec.resources.requests.storage\n指定待创建卷大小，格式为***Gi，单位为GiB。需要满足大小为512字节的整数倍。\n是\n10Gi\nPVC容量的规格取决于存储规格限制和主机规格限制。以OceanStor Dorado 6.1.2/OceanStor Pacific系列 8.1.0对接CentOS 7为例，当使用的是ext4文件系统时，容量限制见表 ext4容量的规格；当使用的是XFS文件系统时，容量限制见表 XFS容量的规格。如果使用的是NFS或者裸设备，容量需满足使用的华为存储设备型号和版本所要求的规格约束。\n如果PVC容量不在规格范围内，可能会由于存储规格限制或主机文件系统规格限制导致创建PVC或Pod失败。\nspec.accessModes\n指定卷访问模式。\nRWO（ReadWriteOnce）：卷可以被一个节点以读写方式挂载。 该模式也允许运行在同一节点上的多个 Pod 访问卷。ROX（ReadOnlyMany）：卷可以被多个节点以只读方式挂载。RWX（ReadWriteMany）：卷可以被多个节点以读写方式挂载。RWOP（ReadWriteOncePod）：卷只能被单个 Pod 以读写方式挂载。该特性需要 Kubernetes 1.22 以上版本。 是\nReadWriteOnce\nRWO/ROX/RWOP：所有类型卷均支持，RWOP需Kubernetes 1.22版本以上支持。请参考开启ReadWriteOncePod功能门章节，检查您的Kubernetes集群是否开启该特性。RWX支持情况如下：NAS存储：所有卷均支持。SAN存储：仅volumeMode设置为Block的卷支持。 表 2 ext4容量的规格\n存储类型\n存储规格限制\next4规格限制\nCSI规格限制\nOceanStor Dorado 6.1.2\n512Ki~256Ti\n50Ti\n512Ki~50Ti\nOceanStor Pacific系列 8.1.0\n64Mi~512Ti\n50Ti\n64Mi~50Ti\n表 3 XFS容量的规格\n存储类型\n存储规格限制\nXFS规格限制\nCSI规格限制\nOceanStor Dorado 6.1.2\n512Ki~256Ti\n500Ti\n512Ki~500Ti\nOceanStor Pacific系列 8.1.0\n64Mi~512Ti\n500Ti\n64Mi~500Ti\n","categories":"","description":"","excerpt":"在完成配置StorageClass以后，就可以用该StorageClass来配置PVC。PVC的配置模板请参考华为CSI软件包中 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/pvc%E7%AE%A1%E7%90%86/%E5%88%9B%E5%BB%BApvc/%E5%8A%A8%E6%80%81%E5%8D%B7%E4%BE%9B%E5%BA%94/%E5%8A%A8%E6%80%81%E5%8D%B7%E4%BE%9B%E5%BA%94pvc%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E/","tags":"","title":"动态卷供应PVC参数说明"},{"body":"例1.配置文件如下：\nparameters: ALUA: \"*\": switchoverMode: Enable_alua pathType: optimal_path node1: switchoverMode: Enable_alua pathType: non_optimal_path 对于主机名为“node1”，上述ALUA配置段都能用于配置启动器。根据配置分布式存储后端的ALUA参数中的配置策略规则，优先级顺序为第2条配置段（HostName为\"node1\"）高于第1条配置段（HostName为\"*\"）。\n例2.配置文件如下：\nparameters: ALUA: node[0-9]: switchoverMode: Enable_alua pathType: optimal_path node[5-7]: switchoverMode: Enable_alua pathType: non_optimal_path 对于主机名为“node6”的主机，上述ALUA配置段都能用于配置启动器。根据配置分布式存储后端的ALUA参数中的配置策略规则，选择第一条ALUA配置段来配置启动器。\n例3.配置文件如下：\nparameters: ALUA: node1$: switchoverMode: Enable_alua pathType: optimal_path node10$: switchoverMode: Enable_alua pathType: non_optimal_path 根据配置分布式存储后端的ALUA参数中的配置策略规则，对于主机名为“node1”的主机，选择第一条ALUA配置段来配置启动器；对于主机名为“node10”的主机，选择第二条ALUA配置段来配置启动器。^表示匹配字符串的开头，$表示匹配字符串的结尾。\n","categories":"","description":"","excerpt":"例1.配置文件如下：\nparameters: ALUA: \"*\": switchoverMode: Enable_alua …","ref":"/css-docs/docs/%E9%99%84%E5%BD%95/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8alua%E7%89%B9%E6%80%A7%E9%85%8D%E7%BD%AE%E7%AD%96%E7%95%A5%E6%A0%B7%E4%BE%8B/","tags":"","title":"分布式存储ALUA特性配置策略样例"},{"body":" 当前使用oceanctl更新存储后端信息时，仅支持更新存储后端密码。 若在存储侧更新了后端的账号密码，CSI插件会因登录失败而重试，可能会导致账号被锁定。如果账号被锁定，请参考存储侧更新密码后账户被锁定章节修改。 ","categories":"","description":"","excerpt":" 当前使用oceanctl更新存储后端信息时，仅支持更新存储后端密码。 若在存储侧更新了后端的账号密码，CSI插件会因登录失败而重试，可能会 …","ref":"/css-docs/docs/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%AE%A1%E7%90%86/%E7%AE%A1%E7%90%86%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/%E6%9B%B4%E6%96%B0%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/","tags":"","title":"更新存储后端"},{"body":"更新证书前请准备好新的证书文件，并参考本章节更新存储后端证书。如果不再使用证书，请参考删除存储后端证书章节移除存储后端上的证书。\n更新证书步骤 执行以下命令获取存储后端。\noceanctl get backend 命令结果示例如下。\nNAMESPACE NAME PROTOCOL STORAGETYPE SN STATUS ONLINE URL huawei-csi backend-1 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.157:8088 huawei-csi backend-2 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.158:8088 执行以下命令查看指定存储后端是否存在证书。\noceanctl get cert -b backend-1 命令结果示例如下。\nNAMESPACE NAME BOUNDBACKEND huawei-csi cert-1 backend-1 执行以下命令更新指定存储后端的证书。\noceanctl update cert -b backend-1 -f /path/to/cert.crt ","categories":"","description":"","excerpt":"更新证书前请准备好新的证书文件，并参考本章节更新存储后端证书。如果不再使用证书，请参考删除存储后端证书章节移除存储后端上的证书。\n更新证书步 …","ref":"/css-docs/docs/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%AE%A1%E7%90%86/%E6%96%B0%E5%A2%9E%E8%AF%81%E4%B9%A6%E5%88%B0%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E5%8F%AF%E9%80%89/%E6%9B%B4%E6%96%B0%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E8%AF%81%E4%B9%A6/","tags":"","title":"更新存储后端证书"},{"body":"华为CSI插件兼容华为OceanStor系列的全闪存存储和混合闪存存储，具体支持的存储版本如下表所示：\n表 1 支持的华为企业存储\n存储产品\n版本\nOceanStor V5\nV500R007, V500R007 Kunpeng\nOceanStor Dorado V3\nV300R002\nOceanStor\n6.1.3, 6.1.5, 6.1.6, 6.1.7, 6.1.8\nOceanStor Dorado\n6.1.0, 6.1.2, 6.1.3, 6.1.5, 6.1.6, 6.1.7, 6.1.8\n华为CSI插件针对华为企业存储支持如下特性。\n表 2 华为企业存储支持的特性及约束\n特性\nOceanStor V5\nOceanStor Dorado V3\nOceanStor\nOceanStor Dorado\nStatic Provisioning\nSAN：FC/iSCSI2\nNAS：NFS 3\nSAN：FC/iSCSI2\nSAN：FC/iSCSI/NVMe over RoCE/NVMe over FC3\nNAS：NFS 3/4.0/4.1/4.2\nSAN：FC/iSCSI/NVMe over RoCE/NVMe over FC3\nNAS：NFS 3/4.0/4.1/4.24\nDynamic Provisioning\nManage Provisioning1\nExpand Persistent Volume5\n支持使用Dynamic Provisioning，Manage Provisioning方式创建的卷\nCreate VolumeSnapshot\n支持使用Dynamic Provisioning，Manage Provisioning方式创建的卷\nDelete VolumeSnapshot\n支持\n支持\n支持\n支持\nRestore VolumeSnapshot\n支持\n支持\nSAN：支持\nNAS：仅6.1.5及其之后版本支持\nSAN：支持\nNAS：仅6.1.5及其之后版本支持\nClone Persistent Volume\n支持使用Dynamic Provisioning，Manage Provisioning方式创建的非双活卷\nSAN：支持使用Dynamic Provisioning，Manage Provisioning方式创建的非双活卷\nNAS：仅6.1.5及其之后版本支持使用Dynamic Provisioning，Manage Provisioning方式创建的卷\nRaw Block Volume\n仅支持SAN类型的卷\n仅支持SAN类型的卷\n仅支持SAN类型的卷\n仅支持SAN类型的卷\nTopology\n支持\n支持\n支持\n支持\nGeneric Ephemeral Volumes\n支持\n支持\n支持\n支持\nAccess Mode\nRWO/ROX/RWOP：所有类型卷均支持，RWOP需Kubernetes 1.22版本以上支持。\nRWX：仅Raw Block卷和NFS类型的卷支持\nQoS\n支持6\n支持\n支持\n支持\n应用类型\n不涉及\n不涉及\n支持\n支持\n卷双活7\n不支持\n不涉及\n仅支持NAS类型的卷\n存储多租户\n仅支持NAS类型的卷\n不涉及\n仅支持NAS类型的卷8\n注释1 Manage Provisioning是华为CSI自定义的纳管卷特性，该特性支持将已有存储资源纳管至Kubernetes。不允许将一个存储资源纳管多次和针对同一个存储资源进行并发删除/创建操作。 注释2 若用户的容器平台部署在虚拟化环境中，则仅支持iSCSI组网。 注释3 使用NVMe over RoCE或NVMe over FC时，worker节点nvme-cli工具版本不低于1.9，查询命令为：nvme version。 注释4 仅OceanStor Dorado 6.1.0及以后版本支持NFS。仅OceanStor Dorado 6.1.3及以后版本支持NFS 4.1，OceanStor Dorado 6.1.7及以后版本支持NFS over RDMA，仅OceanStor Dorado 6.1.8及以后版本支持NFS 4.2。 注释5 发放的volumeType为lun且accessModes为ReadOnlyMany的PVC不支持扩容。 注释6 仅系统用户支持配置QoS。 注释7 仅支持AA双活。 注释8 仅OceanStor Dorado 6.1.3及以后版本支持多租户。 华为CSI插件针对华为企业存储Dtree特性支持如下表所示。\n表 3 Dtree支持的特性\n特性\n支持情况\nStatic Provisioning\n√\nDynamic Provisioning\n√\nExpand Persistent Volume\n√\nAccess Mode\n√ （RWX/RWO/ROX/RWOP：RWOP需Kubernetes 1.22版本以上支持。）\n多租户\n√\nCreate VolumeSnapshot\nX\nDelete VolumeSnapshot\nX\nRestore VolumeSnapshot\nX\nClone Persistent Volume\nX\nQoS\nX\n卷双活\nX\n应用类型\nX\n表 4 Dtree支持的华为存储版本\n存储产品\n版本\nOceanStor Dorado\n6.1.0, 6.1.2, 6.1.3, 6.1.5, 6.1.6, 6.1.7, 6.1.8\n","categories":"","description":"","excerpt":"华为CSI插件兼容华为OceanStor系列的全闪存存储和混合闪存存储，具体支持的存储版本如下表所示：\n表 1 …","ref":"/css-docs/docs/%E5%85%BC%E5%AE%B9%E6%80%A7%E5%92%8C%E7%89%B9%E6%80%A7/%E5%8D%8E%E4%B8%BA%E4%BC%81%E4%B8%9A%E5%AD%98%E5%82%A8%E5%85%BC%E5%AE%B9%E6%80%A7/","tags":"","title":"华为企业存储兼容性"},{"body":"当华为存储接入容器平台后，华为CSI需要在华为存储上根据业务要求，管理存储资源，如创建卷、映射卷等操作。此时，华为CSI需要使用华为存储上已经创建的用户和华为存储进行通信。针对不同存储设备所需要的用户信息如下表所示。\n表 1 存储对接CSI时使用的用户要求\n存储类型\n用户类型\n角色\n级别\n类型\nOceanStor V5\n系统用户\n管理员\n管理员\n本地用户\n租户用户\n租户管理员\n管理员\n本地用户\nOceanStor Dorado V3\n系统用户\n管理员\n管理员\n本地用户\nOceanStor 6.1.3, 6.1.5, 6.1.6, 6.1.7, 6.1.8\n系统用户\n管理员/自定义角色1\nN/A\n本地用户\nOceanStor Dorado 6.1.0, 6.1.2, 6.1.3, 6.1.5, 6.1.6, 6.1.7, 6.1.8\n系统用户\n管理员/自定义角色1\nN/A\n本地用户\n租户用户\n租户管理员\nN/A\n本地用户\nOceanStor Pacific系列\n系统用户\n管理员\nN/A\n本地用户\n注释1 使用自定义角色，需要给角色配置权限，最小权限请参考配置自定义权限章节配置。 不推荐使用“超级管理员”角色下的用户。\n","categories":"","description":"","excerpt":"当华为存储接入容器平台后，华为CSI需要在华为存储上根据业务要求，管理存储资源，如创建卷、映射卷等操作。此时，华为CSI需要使用华为存储上已 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%AE%89%E8%A3%85%E5%89%8D%E5%87%86%E5%A4%87/%E6%A3%80%E6%9F%A5%E5%8D%8E%E4%B8%BA%E5%AD%98%E5%82%A8%E4%B8%8A%E7%9A%84%E7%94%A8%E6%88%B7%E9%85%8D%E7%BD%AE/","tags":"","title":"检查华为存储上的用户配置"},{"body":"静态卷供应（Static Volume Provisioning）允许管理员使用已经在存储侧创建的资源做为PV，供集群中的容器使用。\n为了完成静态卷供应，需要完成如下两步：\n配置PV 配置PVC 前提条件 存储侧已经存在待创建PV所需要的存储资源，如LUN或者文件系统。如果存储资源是文件系统，还需要创建文件系统的共享和客户端信息。\n配置PV 准备PV配置文件mypv.yaml，示例如下，其他配置参数请参考静态卷供应PV参数说明。\nkind: PersistentVolume apiVersion: v1 metadata: name: mypv spec: volumeMode: Filesystem storageClassName: \"\" # 必须配置为\"\" accessModes: - ReadWriteOnce csi: driver: csi.huawei.com # csi驱动名称 volumeHandle: iscsi-dorado-181.lun0001 # 卷名称 fsType: xfs # 文件系统类型 capacity: storage: 100Gi 静态卷供应的配置文件中，storageClassName参数必须配置为‘“”’，如果不配置，Kubernetes会使用系统默认的StorageClass。\n执行以下命令，基于准备好的yaml文件创建PV。\nkubectl create -f mypv.yaml 等待一段时间后，执行以下命令，查看已经创建的PV信息。\nkubectl get pv 命令结果示例如下，当PV状态为“Available”时，表明PV创建成功。\nNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE mypv 100Gi RWO Retain Available 4s 配置PVC 当PV以静态卷供应的方式创建完成后，可以基于该PV创建PVC，从而供容器使用。\n首先准备PVC配置文件。如下示例是一个使用静态卷供应的PVC配置文件。\nkind: PersistentVolumeClaim apiVersion: v1 metadata: name: mypvc spec: storageClassName: \"\" accessModes: - ReadWriteOnce volumeMode: Filesystem resources: requests: storage: 100Gi volumeName: mypv # 对应PV名称 执行以下命令，基于已配置的yaml文件创建PVC。\nkubectl create -f mypvc.yaml 等待一段时间后，执行以下命令，查看已经创建的PVC信息。\nkubectl get pvc 命令结果示例如下，当PVC状态为“Bound“时，表明PVC创建成功。\nNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE mypvc Bound pvc-840054d3-1d5b-4153-b73f-826f980abf9e 100Gi RWO 12s 完成创建PVC操作后，如果长时间后（如一分钟后）PVC的状态是Pending，请参考创建PVC时， PVC的状态为Pending。 建议每批次最多批量创建/删除100个PVC。 使用PVC 与动态卷供应使用PVC方式相同。\n","categories":"","description":"","excerpt":"静态卷供应（Static Volume Provisioning）允许管理员使用已经在存储侧创建的资源做为PV，供集群中的容器使用。\n为了完 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/pvc%E7%AE%A1%E7%90%86/%E5%88%9B%E5%BB%BApvc/%E9%9D%99%E6%80%81%E5%8D%B7%E4%BE%9B%E5%BA%94/","tags":"","title":"静态卷供应"},{"body":"本章节描述如何克隆PVC。\n在克隆PVC时，需要指定数据源。如下示例是一个简单的克隆PVC示例，在该示例中，使用“mypvc”作为数据源，新创建了一个名叫“myclone”的PVC。\nkind: PersistentVolumeClaim apiVersion: v1 metadata: name: myclone spec: storageClassName: mysc dataSource: name: mypvc kind: PersistentVolumeClaim volumeMode: Filesystem accessModes: - ReadWriteOnce resources: requests: storage: 2Gi 指定的storageClassName必须和dataSource中的源卷的StorageClass需一致。 克隆卷的容量必须不小于源卷容量，建议和源卷容量保持一致。 前提条件 系统中已经存在源PVC，且源PVC所在的backend存在支持克隆。支持克隆的存储请参考表 华为企业存储支持的特性及约束和表 华为分布式存储支持的特性及约束，支持克隆的Kubernetes版本请参考Kubernetes特性矩阵。\n操作步骤 执行以下命令，基于克隆卷的配置文件创建PVC。\nkubectl create -f myclone.yaml ","categories":"","description":"","excerpt":"本章节描述如何克隆PVC。\n在克隆PVC时，需要指定数据源。如下示例是一个简单的克隆PVC示例，在该示例中，使用“mypvc”作为数据源，新 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/pvc%E7%AE%A1%E7%90%86/%E5%85%8B%E9%9A%86pvc/","tags":"","title":"克隆PVC"},{"body":"本章节说明如何快速上手安装并使用华为CSI管理PVC。\n华为CSI使用流程概览 图 1 CSI安装及使用流程图\n兼容性和特性 使用前请先了解对接的华为存储、容器平台和主机操作系统相关的兼容性以及支持的特性。\n兼容性和特性\n安装前准备 安装华为CSI前，需要对容器平台、主机等环境做相关配置准备。\n安装前准备\n安装部署 华为CSI提供了Helm和手动安装两种安装方式，并适用于包含Kubernetes、OpenShift等不同的容器平台。\n安装部署\n创建存储后端 在使用华为CSI前，需要先创建存储后端资源。\n创建存储后端\n使用华为CSI 现在，您可以开始使用华为CSI进行PVC管理了。\n使用华为CSI\n","categories":"","description":"","excerpt":"本章节说明如何快速上手安装并使用华为CSI管理PVC。\n华为CSI使用流程概览 图 1 CSI安装及使用流程图\n兼容性和特性 使用前请先了解 …","ref":"/css-docs/docs/%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/","tags":"","title":"快速开始"},{"body":"在完成配置StorageClass以后，就可以用该StorageClass来配置PVC。PVC的配置模板请参考华为CSI软件包中的examples目录下的pvc-manager.yaml文件示例。\n表 1 pvc-manager.yaml文件示例参数说明\n参数\n说明\n必选参数\n默认值\n备注\nmetadata.annotations\nPVC对象的注释。配置以下参数：\n驱动名称/manageVolumeName：卷在存储侧的名称。驱动名称/manageBackendName：卷所属后端的名称。 是\ncsi.huawei.com/manageVolumeName: * csi.huawei.com/manageBackendName: *\n驱动名称获取请参考表4。驱动名称/manageVolumeName：为存储上已有卷的名称，除英文字符外，其他国家字符不支持。驱动名称/manageBackendName：CSI中存储后端的名称。 可执行oceanctl get backend -n huawei-csi命令获取后端名称。\nmetadata.labels\nPVC对象的标签。\n否\n-\n格式：provisioner: 安装时指定的驱动名称。\n例如 provisioner: csi.huawei.com。\n该参数在创建PVC时生效，用于监听PVC资源，获取metadata.annotations信息。\nmetadata.name\n自定义的PVC对象名称。\n是\n-\n以Kubernetes v1.22.1为例，支持数字、小写字母、中划线（-）和点（.）的组合，并且必须以字母数字开头和结尾。\nspec.volumeMode\n卷模式。可选参数。 当使用LUN类型的卷时，支持配置以下类型：\nFilesystem：本地文件系统。Block：裸设备。 说明： 该参数在挂载PV时生效，需要与纳管卷的使用方式保持一致。\n如果卷纳管之前是以裸卷方式使用，volumeMode必须配置为Block。如果卷纳管之前是以ext2/ext3/ext4方式使用，volumeMode必须配置为Filesystem，且StorageClass中fsType必须指定为ext2/ext3/ext4。如果卷纳管之前是以XFS方式使用，volumeMode必须配置为Filesystem，且StorageClass中fsType必须指定为xfs。 否\nFilesystem\n该参数在挂载PV时生效。\nFilesystem表示在容器通过一个本地文件系统访问PV，本地文件系统类型为指定StorageClass中的fsType字段指定。Block表示使用裸卷的方式访问访问PV。 spec.storageClassName\nStorageClass对象名称。\n是\n-\nStorageClass的配置需要与纳管卷的配置保持一致。\nspec.resources.requests.storage\n指定待创建卷大小，格式为***Gi，单位为GiB。需要满足大小为512字节的整数倍。\n是\n-\nPVC容量的规格取决于存储规格限制和主机规格限制。以OceanStor Dorado 6.1.2/OceanStor Pacific系列 8.1.0对接CentOS 7为例，当使用的是ext4文件系统时，容量限制见表2；当使用的是XFS文件系统时，容量限制见表3。如果使用的是NFS或者裸设备，容量需满足使用的华为存储设备型号和版本所要求的规格约束。\n如果PVC容量不在规格范围内，可能会由于存储规格限制或主机文件系统规格限制导致创建PVC或Pod失败。\nspec.accessModes\n指定卷访问模式。\nRWO（ReadWriteOnce）：卷可以被一个节点以读写方式挂载。 该模式也允许运行在同一节点上的多个 Pod 访问卷。ROX（ReadOnlyMany）：卷可以被多个节点以只读方式挂载。RWX（ReadWriteMany）：卷可以被多个节点以读写方式挂载。RWOP（ReadWriteOncePod）：卷只能被单个 Pod 以读写方式挂载。该特性需要 Kubernetes 1.22 以上版本。 是\nReadWriteOnce\nRWO/ROX/RWOP：所有类型卷均支持，RWOP需Kubernetes 1.22版本以上支持。请参考开启ReadWriteOncePod功能门章节，检查您的Kubernetes集群是否开启该特性。RWX支持情况如下：NAS存储：所有卷均支持。SAN存储：仅volumeMode设置为Block的卷支持。 表 2 ext4容量的规格\n存储类型\n存储规格限制\next4规格限制\nCSI规格限制\nOceanStor Dorado 6.1.2\n512Ki~256Ti\n50Ti\n512Ki~50Ti\nOceanStor Pacific系列 8.1.0\n64Mi~512Ti\n50Ti\n64Mi~50Ti\n表 3 XFS容量的规格\n存储类型\n存储规格限制\nXFS规格限制\nCSI规格限制\nOceanStor Dorado 6.1.2\n512Ki~256Ti\n500Ti\n512Ki~500Ti\nOceanStor Pacific系列 8.1.0\n64Mi~512Ti\n500Ti\n64Mi~500Ti\n","categories":"","description":"","excerpt":"在完成配置StorageClass以后，就可以用该StorageClass来配置PVC。PVC的配置模板请参考华为CSI软件包中 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/pvc%E7%AE%A1%E7%90%86/%E5%88%9B%E5%BB%BApvc/%E7%BA%B3%E7%AE%A1%E5%8D%B7%E4%BE%9B%E5%BA%94/%E7%BA%B3%E7%AE%A1%E5%8D%B7%E4%BE%9B%E5%BA%94pvc%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E/","tags":"","title":"纳管卷供应PVC参数说明"},{"body":"VolumeSnapshot可以通过两种方式进行制备：预制备或动态制备。华为CSI当前仅支持动态制备。本章节将说明如何使用华为CSI动态制备VolumeSnapshot。\nVolumeSnapshot的配置文件示例如下：\n如果您的环境中api-versions支持v1，请使用以下示例：\napiVersion: snapshot.storage.k8s.io/v1 kind: VolumeSnapshot metadata: name: mysnapshot spec: volumeSnapshotClassName: mysnapclass source: persistentVolumeClaimName: mypvc 如果您的环境中api-versions支持v1beta1，请使用以下示例：\napiVersion: snapshot.storage.k8s.io/v1beta1 kind: VolumeSnapshot metadata: name: mysnapshot spec: volumeSnapshotClassName: mysnapclass source: persistentVolumeClaimName: mypvc VolumeSnapshot中api-versions信息，请和创建VolumeSnapshotClass使用的版本保持一致。\n实际参数可以参考表 VolumeSnapshot参数说明中的说明修改。\n表 1 VolumeSnapshot参数说明\n参数\n说明\n备注\nmetadata.name\n自定义的VolumeSnapshot对象名称。\n以Kubernetes v1.22.1为例，支持数字、小写字母、中划线（-）和点（.）的组合，并且必须以字母数字字符开头和结尾。\nspec.volumeSnapshotClassName\nVolumeSnapshotClass对象名称。\n--\nspec.source.persistentVolumeClaimName\n源PVC对象名称。\n快照源PVC对应的名称\n前提条件 源PVC存在，且PVC所在的backend存在支持创建VolumeSnapshot。支持创建VolumeSnapshot的存储请参考表 华为企业存储支持的特性及约束和表 华为分布式存储支持的特性及约束，支持创建VolumeSnapshot的Kubernetes版本请参考表 Kubernetes版本与支持的特性。 华为CSI运行所依赖的卷快照组件CRD已经安装。具体信息请参考检查卷快照依赖组件章节说明。 系统中已经存在使用华为CSI的VolumeSnapshotClass。 操作步骤 执行以下命令，使用已经创建的VolumeSnapshot配置文件创建VolumeSnapshot。\nkubectl create -f mysnapshot.yaml 执行以下命令，查看已创建的VolumeSnapshot信息。\nkubectl get volumesnapshot 命令结果示例如下：\nNAME READYTOUSE SOURCEPVC SOURCESNAPSHOTCONTENT RESTORESIZE SNAPSHOTCLASS SNAPSHOTCONTENT CREATIONTIME AGE mysnapshot true mypvc 100Gi mysnapclass snapcontent-1009af0a-24c2-4435-861c-516224503f2d \u003cinvalid\u003e 78s ","categories":"","description":"","excerpt":"VolumeSnapshot可以通过两种方式进行制备：预制备或动态制备。华为CSI当前仅支持动态制备。本章节将说明如何使用华为CSI动态制 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/%E5%88%9B%E5%BB%BAvolumesnapshot/%E9%85%8D%E7%BD%AEvolumesnapshot/","tags":"","title":"配置VolumeSnapshot"},{"body":"现象描述 启动huawei-csi时，无法启动huawei-csi服务（huawei-csi-controller服务或者huawei-csi-node服务），使用kubectl get pod -A | grep huawei命令查看，显示状态为InvalidImageName\nkubectl get pod -A | grep huawei 命令结果示例如下。\nhuawei-csi huawei-csi-controller-fd5f97768-qlldc 6/9 InvalidImageName 0 16s huawei-csi huawei-csi-node-25txd 2/3 InvalidImageName 0 15s 根因分析 controller和node的yaml配置文件中，配置Huawei CSI的镜像版本号错误。例如：\n... - name: huawei-csi-driver image: huawei-csi:4.5.0 ... 解决措施或规避方法 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令，修改huawei-csi-node服务的配置文件。按I或Insert进入编辑状态，修改相关参数。修改完成后，按Esc，并输入 :wq! ，保存修改。\nkubectl edit daemonset huawei-csi-node -o yaml -n=huawei-csi 示例yaml文件中huawei-csi-driver的参数image配置项，修改华为CSI镜像huawei-csi:4.5.0。 containers: ... - name: huawei-csi-driver image: huawei-csi:4.5.0 执行以下命令，修改huawei-csi-controller服务的配置文件。按I或Insert进入编辑状态，修改相关参数。修改完成后，按Esc，并输入 :wq! ，保存修改。\nkubectl edit deployment huawei-csi-controller -o yaml -n=huawei-csi 示例yaml文件中huawei-csi-driver的参数image配置项，修改华为CSI镜像huawei-csi:4.5.0。 containers: ... - name: huawei-csi-driver image: huawei-csi:4.5.0 等待huawei-csi-node和huawei-csi-controller服务启动。\n执行以下命令，查看huawei csi服务是否启动。\nkubectl get pod -A | grep huawei 命令结果示例如下。Pod状态为“Running“说明服务启动成功。\nhuawei-csi huawei-csi-controller-58799449cf-zvhmv 9/9 Running 0 2m29s huawei-csi huawei-csi-node-7fxh6 3/3 Running 0 12m ","categories":"","description":"","excerpt":"现象描述 启动huawei-csi时，无法启动huawei-csi服务（huawei-csi-controller服务或 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%8D%8E%E4%B8%BAcsi%E6%9C%8D%E5%8A%A1%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/%E5%90%AF%E5%8A%A8huawei-csi%E6%9C%8D%E5%8A%A1%E6%97%B6-%E6%9C%8D%E5%8A%A1%E5%90%AF%E5%8A%A8%E5%BC%82%E5%B8%B8-%E7%8A%B6%E6%80%81%E6%98%BE%E7%A4%BAinvalidimagename/","tags":"","title":"启动huawei-csi服务时，服务启动异常， 状态显示InvalidImageName"},{"body":"前置检查 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群内有oceanctl工具的节点。\n执行以下命令，显示版本号为v4.5.0。\noceanctl version 命令结果示例如下：\nOceanctl Version: v4.5.0 执行oceanctl collect logs –help命令，返回信息如下。\n$ oceanctl collect logs --help Collect logs of one or more nodes in specified namespace in Kubernetes Usage: oceanctl collect logs [flags] Examples: # Collect logs of all nodes in specified namespace oceanctl collect logs -n \u003cnamespace\u003e # Collect logs of specified node in specified namespace oceanctl collect logs -n \u003cnamespace\u003e -N \u003cnode\u003e # Collect logs of all nodes in specified namespace oceanctl collect logs -n \u003cnamespace\u003e -a # Collect logs of all nodes in specified namespace with a maximum of 50 nodes collected at the same time oceanctl collect logs -n \u003cnamespace\u003e -a --threads-max=50 # Collect logs of specified node in specified namespace oceanctl collect logs -n \u003cnamespace\u003e -N \u003cnode\u003e -a Flags: -a, --all Collect all nodes messages -h, --help help for logs -n, --namespace string namespace of resources -N, --nodename string Specify the node for which information is to be collected. --threads-max int set maximum number[1~1000] of threads for nodes to be collected. (default 50) Global Flags: --log-dir string Specify the directory for printing log files. (default \"/var/log/huawei\") 执行以下命令，检查Pod是否正常启动，其中，huawei-csi为CSI安装的命名空间。\nkubectl get deployment -n huawei-csi 命令结果示例如下：\nNAME READY UP-TO-DATE AVAILABLE AGE huawei-csi-controller 1/1 1 1 21h 使用oceanctl收集CSI命名空间下所有日志 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录前置检查章节中检查的节点。\n执行oceanctl collect logs -n \u003cnamespace\u003e -a –threads-max=\u003cmax_node_processing_num\u003e命令，收集集群内所有CSI容器所在节点的CSI日志，其中threads-max参数指定了同时收集日志的最大节点数量，默认为50，可以根据主机性能与负载情况配置。\noceanctl collect logs -n huawei-csi -a --threads-max=10 检查/tmp目录下生成的日志压缩包，可以使用unzip \u003czip_name\u003e -d collect_logs解压日志压缩包，其中\u003czip_name\u003e为压缩包的名字。\n# date Wed Sep 20 02:49:24 EDT 2023 # ls huawei-csi-2023-09-20-02:48:22-all.zip 使用oceanctl收集CSI单个节点日志 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录前置检查章节中检查的节点。\n执行oceanctl collect logs -n \u003cnamespace\u003e -N \u003cnodeName\u003e命令，收集集群内所有CSI容器所在节点的CSI日志。\noceanctl collect logs -n huawei-csi -N node-1 检查/tmp目录下生成的日志压缩包，可以使用unzip \u003czip_name\u003e -d collect_logs解压日志压缩包，其中\u003czip_name\u003e为压缩包的名字。\n# date Thu Sep 21 04:08:47 EDT 2023 # ls huawei-csi-2023-09-21-04:05:15-node-1.zip ","categories":"","description":"","excerpt":"前置检查 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群内有oceanctl工具的节点。\n执行以下命 …","ref":"/css-docs/docs/%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86/%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/","tags":"","title":"日志收集"},{"body":" 当VolumeModifyClaim的STATUS值为Creating时，删除VolumeModifyClaim资源，将会在存储侧删除此次变更创建的资源，然后移除集群资源。在删除后，如果继续使用原有的StorageClass进行PVC管理，需要将关联的存储后端恢复为非双活存储后端。 当VolumeModifyClaim的STATUS值为Pending或Completed时，删除VolumeModifyClaim资源，仅会移除集群资源，不会和存储交互，即不会在存储侧删除变更创建的资源。 VolumeModifyContent被VolumeModifyClaim管理，请勿手动管理VolumeModifyContent资源。 若待变更PVC中已有部分PVC满足变更要求，当批量变更失败时，会移除掉所有PVC的变更，导致已满足变更条件的PVC不再满足。 若待变更PVC已经在存储侧被手动管理，则可能导致变更失败。使用变更特性时，请勿手动管理存储卷。 当前章节介绍如何使用kubectl删除PVC变更，基于步骤如下。\n操作步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令，删除PVC变更。其中 vmc-name 为VolumeModifyClaim资源名称。\nkubectl delete volumemodifyclaims \u003cvmc-name\u003e 参考创建PVC变更资源查询删除结果。\n","categories":"","description":"","excerpt":" 当VolumeModifyClaim的STATUS值为Creating时，删除VolumeModifyClaim资源，将会在存储侧删除此次 …","ref":"/css-docs/docs/%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/pvc%E5%8F%98%E6%9B%B4/%E9%85%8D%E7%BD%AEpvc%E5%8F%98%E6%9B%B4/%E5%88%A0%E9%99%A4pvc%E5%8F%98%E6%9B%B4/","tags":"","title":"删除PVC变更"},{"body":"现象描述 在Kubernetes版本低于1.25环境中，对LUN类型的通用临时卷扩容失败，显示PV已经扩容，但PVC未成功更新容量。\n根因分析 该问题是由Kubernetes的bug导致，Kubernetes在1.25版本中修复了该问题。\n","categories":"","description":"","excerpt":"现象描述 在Kubernetes版本低于1.25环境中，对LUN类型的通用临时卷扩容失败，显示PV已经扩容，但PVC未成功更新容量。\n根因分 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/pvc%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/%E9%80%9A%E7%94%A8%E4%B8%B4%E6%97%B6%E5%8D%B7%E6%89%A9%E5%AE%B9%E5%A4%B1%E8%B4%A5/","tags":"","title":"通用临时卷扩容失败"},{"body":"使用containerd下载容器镜像 执行以下命令，下载镜像到本地。其中 image:tag 表示需要拉取的镜像及其标签。\nctr image pull \u003cimage\u003e:\u003ctag\u003e 执行以下命令，导出镜像到文件。其中 image:tag 表示需要导出的镜像，file 表示镜像导出后的文件名称。\nctr image export \u003cfile\u003e.tar \u003cimage\u003e:\u003ctag\u003e 使用Docker下载容器镜像 执行以下命令，下载镜像到本地。其中 image:tag 表示需要拉取的镜像及其标签。\ndocker pull \u003cimage\u003e:\u003ctag\u003e 执行以下命令，导出镜像到文件。其中 image:tag 表示需要导出的镜像，file 表示镜像导出后的文件名称。\ndocker save \u003cimage\u003e:\u003ctag\u003e -o \u003cfile\u003e.tar 使用Podman下载容器镜像 执行以下命令，下载镜像到本地。其中 image:tag 表示需要拉取的镜像及其标签。\npodman pull \u003cimage\u003e:\u003ctag\u003e 执行以下命令，导出镜像到文件。其中 image:tag 表示需要导出的镜像，file 表示镜像导出后的文件名称。\npodman save \u003cimage\u003e:\u003ctag\u003e -o \u003cfile\u003e.tar ","categories":"","description":"","excerpt":"使用containerd下载容器镜像 执行以下命令，下载镜像到本地。其中 image:tag 表示需要拉取的镜像及其标签。\nctr …","ref":"/css-docs/docs/%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/%E4%B8%8B%E8%BD%BD%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F/","tags":"","title":"下载容器镜像"},{"body":"本章节介绍如何卸载CSI依赖组件服务。\n卸载huawei-csi-host-info对象 名称为huawei-csi-host-info的Secret对象中保存着集群中各个节点的启动器信息，例如iSCSI启动器。使用helm uninstall命令时不会卸载该资源，若需卸载该资源，请参考以下步骤：\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令卸载Secret对象，其中huawei-csi-host-info是Secret对象的名称，huawei-csi是Secret对象所在的命名空间。\nkubectl delete secret huawei-csi-host-info -n huawei-csi 执行以下命令检查Secret对象是否卸载成功。\nkubectl get secret huawei-csi-host-info -n huawei-csi 命令结果示例如下，如果命令回显提示“NotFound”表示huawei-csi-host-info对象已成功卸载。\nError from server (NotFound): secrets \"huawei-csi-host-info\" not found 卸载Webhook资源 名称为storage-backend-controller.xuanwu.huawei.io的webhook资源用于校验Backend的秘钥信息和与存储的连通性，使用helm uninstall命令时不会卸载该资源，若需卸载该资源，请参考以下步骤：\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令，查询webhook依赖组件服务。\nkubectl get validatingwebhookconfigurations.admissionregistration.k8s.io storage-backend-controller.xuanwu.huawei.io 命令结果如下。\nNAME WEBHOOKS AGE storage-backend-controller.xuanwu.huawei.io 1 12d 执行以下命令，卸载webhook依赖组件服务。\nkubectl delete validatingwebhookconfigurations.admissionregistration.k8s.io storage-backend-controller.xuanwu.huawei.io 执行以下命令，检查服务是否已成功卸载。如果结果为空，表示已成功卸载。\nkubectl get validatingwebhookconfigurations.admissionregistration.k8s.io storage-backend-controller.xuanwu.huawei.io 卸载Snapshot依赖组件服务 请勿在存在快照时卸载Snapshot依赖组件服务，否则Kubernetes会自动删除所有的用户快照且无法恢复，请谨慎操作。详细说明请参见删除 CustomResourceDefinition。 请勿在CSI升级时卸载Snapshot依赖组件服务。 场景说明\n当前华为CSI使用了快照特性。 当前Kubernetes集群仅存在华为CSI，且不再使用华为CSI。 在卸载前请确保在Kubernetes集群中已经没有华为CSI管理的VolumeSnapshot资源。 操作步骤\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令，卸载Snapshot依赖组件服务。\nkubectl delete crd volumesnapshotclasses.snapshot.storage.k8s.io volumesnapshotcontents.snapshot.storage.k8s.io volumesnapshots.snapshot.storage.k8s.io 执行以下命令，检查服务是否已成功卸载。如果结果为空，表示已成功卸载。\nkubectl get crd | grep snapshot.storage.k8s.io 卸载Lease资源 values.yaml文件中controller.controllerCount配置项的值大于1时，huawei-csi-controller将使用多副本部署，huawei-csi-controller服务的多副本使用Kubernetes的LeaderElection机制实现，该机制会创建Lease对象用于保存当前Holder信息。使用helm uninstall命令时不会卸载该资源，若需卸载该资源，请参考以下步骤，若controller.controllerCount配置项的值等于1是时，可跳过本步骤。配置项描述可参考表 controller配置项说明。\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令，查询Lease信息。\nkubectl get lease -n huawei-csi 命令结果示例如下。\nNAME HOLDER AGE csi-huawei-com node-1 24d external-attacher-leader-csi-huawei-com node-1 24d external-resizer-csi-huawei-com node-1 24d external-snapshotter-leader-csi-huawei-com node-1 24d snapshot-controller-leader node-1 24d storage-backend-controller node-1 24d huawei-csi-extender node-1 24d 执行以下命令，卸载Lease资源。\nkubectl delete lease -n huawei-csi csi-huawei-com external-attacher-leader-csi-huawei-com external-resizer-csi-huawei-com external-snapshotter-leader-csi- 执行以下命令，检查是否已成功卸载。\nkubectl get lease -n huawei-csi 命令结果示例如下，如果结果为空，表示已成功卸载。\nNo resources found in huawei-csi namespace. ","categories":"","description":"","excerpt":"本章节介绍如何卸载CSI依赖组件服务。\n卸载huawei-csi-host-info对象 名称为huawei-csi-host-info …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%B8%E8%BD%BD%E5%8D%8E%E4%B8%BAcsi/helm%E5%8D%B8%E8%BD%BD%E5%8D%8E%E4%B8%BAcsi/%E5%8D%B8%E8%BD%BDcsi%E4%BE%9D%E8%B5%96%E7%BB%84%E4%BB%B6%E6%9C%8D%E5%8A%A1/","tags":"","title":"卸载CSI依赖组件服务"},{"body":"本章节介绍如何卸载华为CSI。根据您安装时的方式，请使用不同的方式进行卸载。\n如果您不是出于升级的目的卸载华为CSI，请确保卸载华为CSI前已经在您的容器平台中将华为CSI发放的资源（PV、PVC、快照、存储后端等）全部清理。否则一旦您卸载华为CSI后，这些资源将无法被自动调度、管理或者清理。\n","categories":"","description":"","excerpt":"本章节介绍如何卸载华为CSI。根据您安装时的方式，请使用不同的方式进行卸载。\n如果您不是出于升级的目的卸载华为CSI，请确保卸载华为CSI前 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%B8%E8%BD%BD%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"卸载华为CSI"},{"body":"现象描述 huawei-csi-controller组件中livenessprobe容器一直重启。\n根因分析 huawei-csi-controller的livenessprobe容器的默认端口（9808）与已有的Tanzu的vSphere CSI端口冲突。\n解决措施或规避方法 将livenessprobe容器的默认端口修改为未占用端口。\n进入“helm/esdk”目录，执行vi values.yaml命令打开配置文件。\nvi values.yaml 将controller.livenessProbePort默认值9808修改为其他未占用端口，例如改为9809。\ncontroller: livenessProbePort: 9809 使用Helm更新华为CSI，具体信息请参考升级华为CSI。\n","categories":"","description":"","excerpt":"现象描述 huawei-csi-controller组件中livenessprobe容器一直重启。 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%AF%B9%E6%8E%A5tanzu-kubernetes%E9%9B%86%E7%BE%A4%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/%E4%BF%AE%E6%94%B9livenessprobe%E5%AE%B9%E5%99%A8%E7%9A%84%E9%BB%98%E8%AE%A4%E7%AB%AF%E5%8F%A3/","tags":"","title":"修改livenessprobe容器的默认端口"},{"body":"Symptom When a Pod is being created, the Pod keeps in the ContainerCreating status. In this case, check the log information of huawei-csi-node (for details, see Viewing Huawei CSI Logs). The log shows that the execution of the mount command times out.\nRoot Cause Analysis Cause 1: The configured service IP address is disconnected. As a result, the mount command execution times out and fails.\nCause 2: For some operating systems, such as Kylin V10 SP1 and SP2, it takes a long time to run the mount command in a container using NFSv3. As a result, the mount command may time out and error message “error: exit status 255” is displayed. The possible cause is that the value of LimitNOFILE of container runtime containerd is too large (over 1 billion).\nCause 3: The mounting may fail due to network problems. The default mounting timeout period of CSI is 30 seconds. If the mounting still fails after 30 seconds, logs show that the execution of the mount command times out.\nSolution or Workaround Run the ping command to check whether the service IP network is connected. If the ping fails, the fault is caused by cause 1. In this case, configure an available service IP address. If the ping succeeds, go to 2.\nGo to any container where the mount command can be executed and use NFSv3 to run the mount command. If the command times out, the fault may be caused by cause 2. Run the systemctl status containerd.service command to check the configuration file path, and then run the **cat **/xxx/containerd.service command to check the configuration file. If the file contains LimitNOFILE=infinity or the value of LimitNOFILE is 1 billion, go to 3. Otherwise, contact Huawei technical support engineers.\nFor cause 2, perform the following operations:\nTry using NFSv4.0. Change the value of LimitNOFILE to a proper one by referring to change solution provided by the community. This solution will restart the container runtime. Evaluate the impact on services. Manually mount the file system on the host machine where the mounting fails. If the required time exceeds 30 seconds, check whether the network between the host machine and the storage node is normal. An example of the mount command is as follows.\nRun the following command to create a test directory.\nmkdir /tmp/test_mount Run the mount command to mount the file system and observe the time consumed. The value of ip:nfs_share_path can be obtained from the huawei-csi-node log. For details, see Viewing Huawei CSI Logs.\ntime mount ip:nfs_share_path /tmp/test_mount After the test is complete, run the following command to unmount the file system.\numount /tmp/test_mount ","categories":"","description":"","excerpt":"Symptom When a Pod is being created, the Pod keeps in the …","ref":"/css-docs/en/docs/troubleshooting/pod-issues/a-pod-fails-to-be-created-and-the-log-shows-that-the-execution-of-the-mount-command-times-out/","tags":"","title":"A Pod Fails to Be Created and the Log Shows That the Execution of the mount Command Times Out"},{"body":"This section describes how to check the volume snapshot-dependent components in the cluster.\nKubernetes earlier than v1.17.0 does not support the snapshot function. If the snapshot CRD is deployed, the cluster may be faulty. Therefore, if Huawei CSI is deployed on Kubernetes earlier than v1.17.0, perform the check according to Kubernetes Earlier Than v1.17.0.\nKubernetes Earlier Than v1.17.0 If the Kubernetes version is earlier than v1.17.0, the cluster may be faulty during snapshot deployment. Perform the following steps to delete the snapshot CRD installation file.\nRun the following command to check the Kubernetes version. In the following example, the Kubernetes version is v1.16.0.\nkubectl get node The following is an example of the command output.\nNAME STATUS ROLES AGE VERSION test-master Ready master 311d v1.16.0 test-node Ready \u003cnone\u003e 311d v1.16.0 Go to the /helm/esdk/crds/snapshot-crds directory and run the following command to delete the snapshot CRD installation file. For details about the component package path, see Table 1.\nrm -rf ./huawei-csi-snapshot-crd-v1.yaml ","categories":"","description":"","excerpt":"This section describes how to check the volume snapshot-dependent …","ref":"/css-docs/en/docs/installation-and-deployment/installation-preparations/checking-volume-snapshot-dependent-components/","tags":"","title":"Checking Volume Snapshot-Dependent Components"},{"body":"\nSource Device\nHost where CSI controller is located\nHost where CSI controller is located\nHost where CSI node is located\nKubernetes master node\nSource IP Address\nIP address of the source device\nIP address of the source device\nIP address of the source device\nIP address of the source device\nSource Port\n1024 to 65536\n1024 to 65536\n1024 to 65536\n1024 to 65536\nDestination Device\nStorage device\nHost where CSI controller is located\nHost where CSI node is located\nHost where CSI controller is located\nDestination IP Address\nManagement IP address of the storage device\nIP address of the destination device\nIP address of the destination device\nIP address of the destination device\nDestination Port (for Listening)\n8088\n9808\n9800\n4433\nProtocol\nTCP\nTCP\nTCP\nTCP\nPort Description\nUsed to create, manage, and delete volumes\nUsed by Kubernetes to check the health status of CSI controller\nUsed by Kubernetes to check the health status of CSI node\nUsed to invoke webhook verification\nListening Port Configurable\nNo\nNo\nNo\nYes\nAuthentication Mode\nUser name and password\nCertificate\nCertificate\nCertificate\nEncryption Mode\nTLS 1.3/TLS 1.2\nTLS 1.3/TLS 1.2\nTLS 1.3/TLS 1.2\nTLS 1.3/TLS 1.2\nPlane\nOM\nO\u0026M plane\nO\u0026M plane\nO\u0026M plane\nSpecial Scenario\nNone\nNone\nNone\nNone\nRemarks\nEnable some source ports.\n      For details about how to change the webhook port, see the CSI user guide.\n","categories":"","description":"","excerpt":"\nSource Device\nHost where CSI controller is located\nHost where CSI …","ref":"/css-docs/en/docs/appendix/communication-matrix/","tags":"","title":"Communication Matrix"},{"body":"This chapter describes the container management platforms, operating systems (OSs), and multipathing software supported by Huawei CSI plug-in, as well as the features and functions provided by the CSI plug-in when working with Huawei storage.\n","categories":"","description":"","excerpt":"This chapter describes the container management platforms, operating …","ref":"/css-docs/en/docs/compatibility-and-features/","tags":"","title":"Compatibility and Features"},{"body":"Huawei CSI plug-in is compatible with Huawei OceanStor series distributed storage systems. The following table lists the supported storage versions.\nTable 1 Supported Huawei distributed storage\nStorage Product\nVersion\nFusionStorage Block\n8.0.1\nOceanStor Pacific series\n8.1.0, 8.1.1, 8.1.2, 8.1.3, 8.1.5, 8.2.0\nHuawei CSI plug-in supports the following features for Huawei distributed storage.\nTable 2 Features supported by Huawei distributed storage and constraints\nFeature\nFusionStorage Block\nOceanStor Pacific Series\nStatic Provisioning\nSAN: iSCSI/SCSI\nSAN: iSCSI/SCSI\nNAS: DPC2/NFS 3/4.13\nDynamic Provisioning\nManage Provisioning1\nExpand Persistent Volume4\nVolumes created in Dynamic Provisioning or Manage Provisioning mode are supported.\nCreate VolumeSnapshot\nSAN volumes created in Dynamic Provisioning or Manage Provisioning mode are supported.\nDelete VolumeSnapshot\nSupported\nOnly SAN volume snapshots are supported.\nRestore VolumeSnapshot\nSupported\nOnly SAN volume snapshots are supported.\nClone Persistent Volume\nSAN volumes created in Dynamic Provisioning or Manage Provisioning mode are supported.\nRaw Block Volume\nOnly SAN volumes are supported.\nOnly SAN volumes are supported.\nTopology\nSupported\nSupported\nGeneric Ephemeral Inline Volumes\nSupported\nSupported\nAccess Mode\nRWO/ROX/RWOP: supported by all types of volumes. RWOP is supported only by Kubernetes 1.22 and later versions.\nRWX: supported only by Raw Block volumes and NFS volumes.\nQoS\nSupported\nSupported\nSoft and hard quotas\nNot supported\nOnly NAS volumes are supported.\nStorage multi-tenant\nNot supported\nOnly NAS volumes are supported.\nNote 1: Manage Provisioning is a volume management feature customized by Huawei CSI. This feature allows existing storage resources to be managed by Kubernetes. You are not allowed to manage a storage resource for multiple times and concurrently delete or create a storage resource. Note 2: Only OceanStor Pacific series 8.1.2 and later versions support DPC. For details about whether the OSs supported by Huawei CSI support DPC, see the compatibility document of the corresponding product version. Note 3: Only OceanStor Pacific series 8.1.2 and later versions support NFS 4.1. Note 4: The provisioned PVC whose volumeType is lun and accessModes is ReadOnlyMany does not support capacity expansion. ","categories":"","description":"","excerpt":"Huawei CSI plug-in is compatible with Huawei OceanStor series …","ref":"/css-docs/en/docs/compatibility-and-features/compatibility-with-huawei-distributed-storage/","tags":"","title":"Compatibility with Huawei Distributed Storage"},{"body":"This section describes how to create a PVC using a snapshot.\nWhen creating a PVC, you need to specify the data source. The following is a simple example of creating a PVC using a snapshot. In this example, mysnapshot is used as the data source and a PVC named myrestore is created.\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: myrestore spec: storageClassName: mysc dataSource: name: mysnapshot kind: VolumeSnapshot apiGroup: snapshot.storage.k8s.io volumeMode: Filesystem accessModes: - ReadWriteOnce resources: requests: storage: 100Gi The specified storageClassName must be the same as the StorageClass of the snapshot source volume in dataSource. The capacity of the clone volume must be greater than or equal to that of the snapshot. Equal capacity is recommended. Prerequisites A snapshot already exists in the system, and the backend where the snapshot resides supports cloning. For details about the storage devices that support PVC creation using a snapshot, see Table 2 and Table 2. For details about the Kubernetes versions that support PVC creation using a snapshot, see Kubernetes Feature Matrix.\nProcedure Run the following command to create a PVC based on the configuration file for creating a volume using a snapshot.\nkubectl create -f myrestore.yaml ","categories":"","description":"","excerpt":"This section describes how to create a PVC using a snapshot.\nWhen …","ref":"/css-docs/en/docs/using-huawei-csi/managing-a-pvc/creating-a-pvc-using-a-snapshot/","tags":"","title":"Creating a PVC Using a Snapshot"},{"body":" Do not delete a storage backend when a volume management operation is being performed on it.\nExample of Deleting a Backend Run the following command to obtain information about a storage backend.\noceanctl get backend The following is an example of the command output.\nNAMESPACE NAME PROTOCOL STORAGETYPE SN STATUS ONLINE URL huawei-csi backend-1 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.157:8088 huawei-csi backend-2 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.158:8088 Run the following command to delete the specified storage backend.\noceanctl delete backend backend-1 Run the following command to check the deletion result.\noceanctl get backend backend-1 The following is an example of the command output. If not found is displayed, the deletion is successful.\nError from server (NotFound): backend \"backend-1\" not found ","categories":"","description":"","excerpt":" Do not delete a storage backend when a volume management operation is …","ref":"/css-docs/en/docs/storage-backend-management/managing-storage-backends/deleting-a-storage-backend/","tags":"","title":"Deleting a Storage Backend"},{"body":"Procedure Run the following command to obtain information about a storage backend.\noceanctl get backend The following is an example of the command output.\nNAMESPACE NAME PROTOCOL STORAGETYPE SN STATUS ONLINE URL huawei-csi backend-1 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.157:8088 huawei-csi backend-2 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.158:8088 Run the following command to obtain information about the certificate of the specified storage backend.\noceanctl get cert -b backend-1 The following is an example of the command output.\nNAMESPACE NAME BOUNDBACKEND huawei-csi cert-1 backend-1 Run the following command to delete the certificate of the specified storage backend.\noceanctl delete cert -b backend-1 Check the deletion result.\noceanctl get cert -b backend-1 The following is an example of the command output. If no cert found is displayed, the deletion is successful.\nError from server (NotFound): no cert found on backend backend-1 in huawei-csi namespace ","categories":"","description":"","excerpt":"Procedure Run the following command to obtain information about a …","ref":"/css-docs/en/docs/storage-backend-management/optional-adding-a-certificate-to-a-storage-backend/deleting-a-storage-backend-certificate/","tags":"","title":"Deleting a Storage Backend Certificate"},{"body":"Symptom A generic ephemeral volume fails to be created, and the error message PodSecurityPolicy: unable to admit pod: [spec.volumes[0]: Invalid value: “ephemeral”: ephemeral volumes are not allowed to be used spec.volumes[0] is displayed.\nRoot Cause Analysis The current PSP policy does not contain the permission to use ephemeral volumes.\nSolution or Workaround Add the permission to use ephemeral volumes to the default PSP pks-privileged and pks-restricted. The following is an example of modifying pks-privileged:\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to modify the pks-privileged configuration.\nkubectl edit psp pks-privileged Add ephemeral to spec.volumes. The following is an example.\n# Please edit the object below. Lines beginning with a '#' will be ignored, # and an empty file will abort the edit. If an error occurs while saving this file will be # reopened with the relevant failures. # apiVersion: policy/v1beta1 kind: PodSecurityPolicy metadata: annotations: apparmor.security.beta.kubernetes.io/allowedProfileName: '*' seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*' creationTimestamp: \"2022-10-11T08:07:00Z\" name: pks-privileged resourceVersion: \"1227763\" uid: 2f39c44a-2ce7-49fd-87ca-2c5dc3bfc0c6 spec: allowPrivilegeEscalation: true allowedCapabilities: - '*' supplementalGroups: rule: RunAsAny volumes: - glusterfs - hostPath - iscsi - nfs - persistentVolumeClaim - ephemeral Run the following command to check whether the addition is successful.\nkubectl get psp pks-privileged -o yaml ","categories":"","description":"","excerpt":"Symptom A generic ephemeral volume fails to be created, and the error …","ref":"/css-docs/en/docs/troubleshooting/common-problems-and-solutions-for-interconnecting-with-the-tanzu-kubernetes-cluster/failed-to-create-an-ephemeral-volume/","tags":"","title":"Failed to Create an Ephemeral Volume"},{"body":"Symptom In a Kubernetes environment earlier than 1.23, PVC capacity expansion fails when the target capacity exceeds the storage pool capacity.\nRoot Cause Analysis This is a known issue in the Kubernetes community. For details, see Recovering from Failure when Expanding Volumes.\nSolution or Workaround For details, see Recovering from Failure when Expanding Volumes.\n","categories":"","description":"","excerpt":"Symptom In a Kubernetes environment earlier than 1.23, PVC capacity …","ref":"/css-docs/en/docs/troubleshooting/pvc-issues/failed-to-expand-the-pvc-capacity-because-the-target-capacity-exceeds-the-storage-pool-capacity/","tags":"","title":"Failed to Expand the PVC Capacity Because the Target Capacity Exceeds the Storage Pool Capacity"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/en/docs/troubleshooting/pod-issues/","tags":"","title":"Pod Issues"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/pod%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/","tags":"","title":"Pod相关问题"},{"body":"现象描述 在低于1.23版本的Kubernetes环境中，对PVC进行扩容，当目标容量超过存储池容量时，扩容失败。\n根因分析 Kubernetes社区已知问题，详情请参考处理扩充卷过程中的失败。\n解决措施或规避方法 参考处理扩充卷过程中的失败。\n","categories":"","description":"","excerpt":"现象描述 在低于1.23版本的Kubernetes环境中，对PVC进行扩容，当目标容量超过存储池容量时，扩容失败。 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/pvc%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/pvc%E6%89%A9%E5%AE%B9%E7%9A%84%E7%9B%AE%E6%A0%87%E5%AE%B9%E9%87%8F%E8%B6%85%E8%BF%87%E5%AD%98%E5%82%A8%E6%B1%A0%E5%AE%B9%E9%87%8F%E5%AF%BC%E8%87%B4%E6%89%A9%E5%AE%B9%E5%A4%B1%E8%B4%A5/","tags":"","title":"PVC扩容的目标容量超过存储池容量导致扩容失败"},{"body":"Perform this operation when you need to update the huawei-csi-controller or huawei-csi-node service, for example, changing the number of copies for the huawei-csi-controller service.\nProcedure Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nGo to the /helm/esdk directory and run the following command to obtain the original service configuration file. helm-huawei-csi indicates the Helm chart name specified during the installation of the earlier version, and huawei-csi indicates the Helm chart namespace specified during the installation of the earlier version. For details about the component package path, see Table 1.\nhelm get values helm-huawei-csi -n huawei-csi -a \u003e ./update-values.yaml Run the vi update-values.yaml command to open the file obtained in 2 and modify the configuration items by referring to Parameters in the values.yaml File of Helm. After the modification, press Esc and enter :wq! to save the modification.\nRun the following command to update Huawei CSI services.\nhelm upgrade helm-huawei-csi ./ -n huawei-csi -f ./update-values.yaml ","categories":"","description":"","excerpt":"Perform this operation when you need to update the …","ref":"/css-docs/en/docs/common-operations/updating-the-huawei-csi-controller-or-huawei-csi-node-service/","tags":"","title":"Updating the huawei-csi-controller or huawei-csi-node Service"},{"body":"This section describes how to upgrade or roll back Huawei CSI.\nIn the current version, resource requests and limits are added to Huawei CSI. For details, see Huawei CSI Resource Management.\n","categories":"","description":"","excerpt":"This section describes how to upgrade or roll back Huawei CSI.\nIn the …","ref":"/css-docs/en/docs/installation-and-deployment/upgrading-or-rolling-back-huawei-csi/","tags":"","title":"Upgrading or Rolling Back Huawei CSI"},{"body":"现象描述 创建Pod时，Pod一直处于ContainerCreating状态，此时查看huawei-csi-node的日志信息（详情请参考如何查看华为CSI日志），日志显示执行mount命令超时。\n根因分析 原因1：该问题可能由于配置的业务IP网络不通，导致mount命令执行超时失败。\n原因2：对于部分操作系统，如Kylin V10 SP1和SP2，使用NFSv3从容器内执行mount命令耗时较长，导致mount命令超时并报错“error: exit status 255”，该问题可能由于容器运行时containerd的LimitNOFILE参数值过大（10亿+）。\n原因3：可能由于网络问题导致挂载失败，CSI默认挂载超时时间为30秒，超过30秒仍挂载失败，日志会显示执行mount命令超时。\n解决措施或规避方法 执行ping命令判断业务IP网络是否连通，如果无法ping通，则为原因1，请配置可用的业务IP地址，如果可以ping通，则执行2。\n进入任意可以执行mount命令的容器中，指定使用NFSv3执行mount命令。如果命令超时，则可能是原因2，继续执行systemctl status containerd.service命令查看配置文件路径，然后执行cat _/xxx/containerd.service_命令查看配置文件。文件中如果有LimitNOFILE=infinity或LimitNOFILE的值大小为10亿，请执行3。否则请联系华为工程师处理。\n原因2可参考以下方式处理：\n尝试使用NFSv4.0及以上协议。 参考社区修改方案，将LimitNOFILE参数值修改为合适的值。该方案将会重启容器运行时，请评估对业务的影响。 在挂载失败的宿主机手动挂载该文件系统，如果时间超过30秒，需要用户自行排查该宿主机到存储节点网络是否存在问题。mount命令示例如下\n执行以下命令创建测试目录。\nmkdir /tmp/test_mount 执行mount命令，挂载文件系统，并观察耗时，其中ip:nfs_share_path可以从huawei-csi-node日志中获取，详情请参考如何查看华为CSI日志\ntime mount ip:nfs_share_path /tmp/test_mount 测试结束，执行以下命令解挂载文件系统\numount /tmp/test_mount ","categories":"","description":"","excerpt":"现象描述 创建Pod时，Pod一直处于ContainerCreating状态，此时查看huawei-csi-node的日志信息（详情请参考如 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/pod%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/%E5%88%9B%E5%BB%BApod%E5%A4%B1%E8%B4%A5-%E6%97%A5%E5%BF%97%E6%98%BE%E7%A4%BA%E6%89%A7%E8%A1%8Cmount%E5%91%BD%E4%BB%A4%E8%B6%85%E6%97%B6/","tags":"","title":"创建Pod失败，日志显示执行mount命令超时"},{"body":"现象描述 创建通用临时卷失败，报错PodSecurityPolicy: unable to admit pod: [spec.volumes[0]: Invalid value: “ephemeral”: ephemeral volumes are not allowed to be used spec.volumes[0]\n根因分析 当前使用的PSP策略中没有使用“ephemeral”卷的权限。\n解决措施或规避方法 在默认PSP “pks-privileged\"和\"pks-restricted\"中增加使用“ephemeral”卷的权限，以修改\"pks-privileged\"举例：\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行命令， 修改pks-privileged的配置。\nkubectl edit psp pks-privileged 在spec.volumes中增加“ephemeral”，示例如下：\n# Please edit the object below. Lines beginning with a '#' will be ignored, # and an empty file will abort the edit. If an error occurs while saving this file will be # reopened with the relevant failures. # apiVersion: policy/v1beta1 kind: PodSecurityPolicy metadata: annotations: apparmor.security.beta.kubernetes.io/allowedProfileName: '*' seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*' creationTimestamp: \"2022-10-11T08:07:00Z\" name: pks-privileged resourceVersion: \"1227763\" uid: 2f39c44a-2ce7-49fd-87ca-2c5dc3bfc0c6 spec: allowPrivilegeEscalation: true allowedCapabilities: - '*' supplementalGroups: rule: RunAsAny volumes: - glusterfs - hostPath - iscsi - nfs - persistentVolumeClaim - ephemeral 执行命令，确认是否添加成功。\nkubectl get psp pks-privileged -o yaml ","categories":"","description":"","excerpt":"现象描述 创建通用临时卷失败，报错PodSecurityPolicy: unable to admit pod: …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%AF%B9%E6%8E%A5tanzu-kubernetes%E9%9B%86%E7%BE%A4%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/%E5%88%9B%E5%BB%BA%E4%B8%B4%E6%97%B6%E5%8D%B7%E5%A4%B1%E8%B4%A5/","tags":"","title":"创建临时卷失败"},{"body":"本章节描述如何从快照创建PVC。\n在创建这个PVC时，需要指定数据源。如下示例是一个简单的从快照创建PVC示例，在该示例中，使用快照“mysnapshot”作为数据源，新创建了一个名叫“myrestore”的PVC。\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: myrestore spec: storageClassName: mysc dataSource: name: mysnapshot kind: VolumeSnapshot apiGroup: snapshot.storage.k8s.io volumeMode: Filesystem accessModes: - ReadWriteOnce resources: requests: storage: 100Gi 指定的storageClassName必须和dataSource中的快照源卷的StorageClass需一致。 克隆卷的容量必须不小于快照容量，建议和快照容量保持一致。 前提条件 系统中已经存在快照，且快照所在的backend存在支持克隆。支持快照创建PVC的存储请参考表 华为企业存储支持的特性及约束和表 华为分布式存储支持的特性及约束，支持快照创建PVC的Kubernetes版本请参考Kubernetes特性矩阵。\n操作步骤 执行以下命令，基于从快照创建卷的配置文件创建PVC。\nkubectl create -f myrestore.yaml ","categories":"","description":"","excerpt":"本章节描述如何从快照创建PVC。\n在创建这个PVC时，需要指定数据源。如下示例是一个简单的从快照创建PVC示例，在该示例中，使用快 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/pvc%E7%AE%A1%E7%90%86/%E4%BB%8E%E5%BF%AB%E7%85%A7%E5%88%9B%E5%BB%BApvc/","tags":"","title":"从快照创建PVC"},{"body":"当您需要更新huawei-csi-controller或huawei-csi-node服务时，例如修改huawei-csi-controller服务的副本数时，执行此操作。\n操作步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n进入/helm/esdk 目录，执行以下命令，获取原有服务配置文件。其中helm-huawei-csi为旧版本安装时指定的Helm Chart名称，huawei-csi为旧版本安装时指定的Helm Chart命名空间。组件包路径请参考表 软件包组件描述。\nhelm get values helm-huawei-csi -n huawei-csi -a \u003e ./update-values.yaml 执行 vi update-values.yaml 命令打开2中获取的文件，参考Helm values.yaml参数说明修改配置项，修改完成后，按Esc，并输入 :wq!，保存修改。\n执行以下命令更新华为CSI服务。\nhelm upgrade helm-huawei-csi ./ -n huawei-csi -f ./update-values.yaml ","categories":"","description":"","excerpt":"当您需要更新huawei-csi-controller或huawei-csi-node服务时，例如修 …","ref":"/css-docs/docs/%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/%E6%9B%B4%E6%96%B0huawei-csi-controller%E6%88%96huawei-csi-node%E6%9C%8D%E5%8A%A1/","tags":"","title":"更新huawei-csi-controller或huawei-csi-node服务"},{"body":"华为CSI插件兼容华为OceanStor系列的分布式存储系统，具体支持的存储版本如下表所示：\n表 1 支持的华为分布式存储\n存储产品\n版本\nFusionStorage Block\n8.0.1\nOceanStor Pacific系列\n8.1.0, 8.1.1, 8.1.2, 8.1.3, 8.1.5, 8.2.0\n华为CSI插件针对华为分布式存储支持如下特性。\n表 2 华为分布式存储支持的特性及约束\n特性\nFusionStorage Block\nOceanStor Pacific系列\nStatic Provisioning\nSAN：iSCSI/SCSI\nSAN：iSCSI/SCSI\nNAS：DPC2/NFS 3/4.13\nDynamic Provisioning\nManage Provisioning1\nExpand Persistent Volume4\n支持使用Dynamic Provisioning，Manage Provisioning方式创建的卷\nCreate VolumeSnapshot\n支持使用Dynamic Provisioning，Manage Provisioning方式创建的SAN类型卷\nDelete VolumeSnapshot\n支持\n仅支持SAN类型的卷快照\nRestore VolumeSnapshot\n支持\n仅支持SAN类型的卷快照\nClone Persistent Volume\n支持使用Dynamic Provisioning，Manage Provisioning方式创建的SAN类型卷\nRaw Block Volume\n仅支持SAN类型的卷\n仅支持SAN类型的卷\nTopology\n支持\n支持\nGeneric Ephemeral Inline Volumes\n支持\n支持\nAccess Mode\nRWO/ROX/RWOP：所有类型卷均支持，RWOP在Kubernetes 1.22及以上版本支持。\nRWX：仅Raw Block卷和NFS类型的卷支持。\nQoS\n支持\n支持\n软硬配额\n不支持\n仅支持NAS类型的卷\n存储多租户\n不支持\n仅支持NAS类型的卷\n注释1 Manage Provisioning是华为CSI自定义的纳管卷特性，该特性支持将已有存储资源纳管至Kubernetes。不允许将一个存储资源纳管多次和针对同一个存储资源进行并发删除/创建操作。 注释2 仅OceanStor Pacific系列 8.1.2及以后版本支持DPC。华为CSI支持的操作系统对DPC的支持请参考对应产品版本兼容性文档。 注释3 仅OceanStor Pacific系列 8.1.2及以后版本支持NFS 4.1。 注释4 发放的volumeType为lun且accessModes为ReadOnlyMany的PVC不支持扩容。 ","categories":"","description":"","excerpt":"华为CSI插件兼容华为OceanStor系列的分布式存储系统，具体支持的存储版本如下表所示：\n表 1 …","ref":"/css-docs/docs/%E5%85%BC%E5%AE%B9%E6%80%A7%E5%92%8C%E7%89%B9%E6%80%A7/%E5%8D%8E%E4%B8%BA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E5%85%BC%E5%AE%B9%E6%80%A7/","tags":"","title":"华为分布式存储兼容性"},{"body":"本章节会详细说明华为CSI插件支持的容器管理平台、操作系统、多路径软件以及CSI插件配合华为存储所提供的特性和功能。\n","categories":"","description":"","excerpt":"本章节会详细说明华为CSI插件支持的容器管理平台、操作系统、多路径软件以及CSI插件配合华为存储所提供的特性和功能。\n","ref":"/css-docs/docs/%E5%85%BC%E5%AE%B9%E6%80%A7%E5%92%8C%E7%89%B9%E6%80%A7/","tags":"","title":"兼容性和特性"},{"body":"本章节介绍如何检查集群中卷快照依赖组件情况。\n由于Kubernetes v1.17.0之前不支持快照功能，如果部署快照CRD可能导致集群出现问题，因此在低于Kubernetes v1.17.0版本上部署华为CSI，请务必按照Kubernetes低于v1.17.0章节检查。\nKubernetes低于v1.17.0 Kubernetes低于v1.17.0时，部署快照时将会导致集群出现问题，请按照以下步骤删除快照CRD安装文件。\n执行以下命令查看Kubernetes版本。如下示例中，Kubernetes版本为v1.16.0。\nkubectl get node 命令结果示例如下：\nNAME STATUS ROLES AGE VERSION test-master Ready master 311d v1.16.0 test-node Ready \u003cnone\u003e 311d v1.16.0 进入/helm/esdk/crds/snapshot-crds目录，执行以下命令，删除快照CRD安装文件。组件包路径请参考表 软件包组件描述。\nrm -rf ./huawei-csi-snapshot-crd-v1.yaml ","categories":"","description":"","excerpt":"本章节介绍如何检查集群中卷快照依赖组件情况。\n由于Kubernetes v1.17.0之前不支持快照功能，如果部署快照CRD可能导致集群出现 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%AE%89%E8%A3%85%E5%89%8D%E5%87%86%E5%A4%87/%E6%A3%80%E6%9F%A5%E5%8D%B7%E5%BF%AB%E7%85%A7%E4%BE%9D%E8%B5%96%E7%BB%84%E4%BB%B6/","tags":"","title":"检查卷快照依赖组件"},{"body":" 正在执行卷管理操作期间，请勿删除存储后端。\n删除后端示例 执行以下命令获取存储后端。\noceanctl get backend 命令结果示例如下：\nNAMESPACE NAME PROTOCOL STORAGETYPE SN STATUS ONLINE URL huawei-csi backend-1 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.157:8088 huawei-csi backend-2 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.158:8088 执行以下命令删除指定存储后端。\noceanctl delete backend backend-1 执行以下命令检查删除结果。\noceanctl get backend backend-1 命令结果示例如下，如果回显为“not found”则删除成功。\nError from server (NotFound): backend \"backend-1\" not found ","categories":"","description":"","excerpt":" 正在执行卷管理操作期间，请勿删除存储后端。\n删除后端示例 执行以下命令获取存储后端。\noceanctl get backend 命令结果示 …","ref":"/css-docs/docs/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%AE%A1%E7%90%86/%E7%AE%A1%E7%90%86%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/%E5%88%A0%E9%99%A4%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF/","tags":"","title":"删除存储后端"},{"body":"删除证书步骤 执行以下命令获取存储后端。\noceanctl get backend 命令结果示例如下。\nNAMESPACE NAME PROTOCOL STORAGETYPE SN STATUS ONLINE URL huawei-csi backend-1 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.157:8088 huawei-csi backend-2 roce oceanstor-san xxxxxxxxxxxxxxxxxxxx Bound true https://192.168.129.158:8088 执行以下命令获取指定存储后端的证书。\noceanctl get cert -b backend-1 命令结果示例如下。\nNAMESPACE NAME BOUNDBACKEND huawei-csi cert-1 backend-1 执行以下命令删除指定存储后端的证书。\noceanctl delete cert -b backend-1 检查删除结果。\noceanctl get cert -b backend-1 命令结果示例如下，如果回显为“no cert found”则删除成功。\nError from server (NotFound): no cert found on backend backend-1 in huawei-csi namespace ","categories":"","description":"","excerpt":"删除证书步骤 执行以下命令获取存储后端。\noceanctl get backend 命令结果示例如下。\nNAMESPACE NAME …","ref":"/css-docs/docs/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%AE%A1%E7%90%86/%E6%96%B0%E5%A2%9E%E8%AF%81%E4%B9%A6%E5%88%B0%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E5%8F%AF%E9%80%89/%E5%88%A0%E9%99%A4%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E8%AF%81%E4%B9%A6/","tags":"","title":"删除存储后端证书"},{"body":"本章节介绍如何升级/回退华为CSI。\n当前版本华为CSI添加了资源请求和限制，具体详情请参考华为CSI资源管理。\n","categories":"","description":"","excerpt":"本章节介绍如何升级/回退华为CSI。\n当前版本华为CSI添加了资源请求和限制，具体详情请参考华为CSI资源管理。\n","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%8D%87%E7%BA%A7-%E5%9B%9E%E9%80%80%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"升级/回退华为CSI"},{"body":"\n源设备\n源IP\n源端口\n目的设备\n目的IP\n目的端口 （监听）\n协议\n端口说明\n监听端口是否可更改\n认证方式\n加密方式\n所属平面\n特殊场景\nCSI controller所在主机\n源设备IP\n1024~65536\n存储设备\n存储阵列管理IP\n8088\nTCP\n用于卷创建/管理/删除等一系列动作\n否\n用户名/密码\nTLS 1.3/TLS 1.2\nOM\n无\nCSI controller所在主机\n源设备IP\n1024~65536\nCSI controller所在主机\n目的设备IP\n9808\nTCP\n用于k8s对CSI controller的健康检查\n否\n证书认证\nTLS 1.3/TLS 1.2\n运维面\n无\nCSI node所在主机\n源设备IP\n1024~65536\nCSI node所在主机\n目的设备IP\n9800\nTCP\n用于k8s对CSI node的健康检查\n否\n证书认证\nTLS 1.3/TLS 1.2\n运维面\n无\nk8s master节点\n源设备IP\n1024~65536\nCSI controller所在主机\n目的设备IP\n4433\nTCP\n用于调用webhook校验\n是\n证书认证\nTLS 1.3/TLS 1.2\n运维面\n无\n","categories":"","description":"","excerpt":"\n源设备\n源IP\n源端口\n目的设备\n目的IP\n目的端口 （监听） …","ref":"/css-docs/docs/%E9%99%84%E5%BD%95/%E9%80%9A%E4%BF%A1%E7%9F%A9%E9%98%B5/","tags":"","title":"通信矩阵"},{"body":"Symptom In NAS scenarios, when a Pod is being created, the Pod keeps in the ContainerCreating status. In this case, check the log information of huawei-csi-node (for details, see Viewing Huawei CSI Logs). The log shows that the mount command fails to be executed.\nRoot Cause Analysis The possible cause is that the NFS 4.0/4.1/4.2 protocol is not enabled on the storage side. After the NFS v4 protocol fails to be used for mounting, the host does not negotiate to use the NFS v3 protocol for mounting.\nSolution or Workaround Enable the NFS 3/4.0/4.1/4.2 protocol on the storage side and retry the default mounting. Specify an available NFS protocol for mounting. For details, see StorageClass Configuration Examples in Typical Dynamic Volume Provisioning Scenarios. ","categories":"","description":"","excerpt":"Symptom In NAS scenarios, when a Pod is being created, the Pod keeps …","ref":"/css-docs/en/docs/troubleshooting/pod-issues/a-pod-fails-to-be-created-and-the-log-shows-that-the-mount-command-fails-to-be-executed/","tags":"","title":"A Pod Fails to Be Created and the Log Shows That the mount Command Fails to Be Executed"},{"body":"If you plan to use the FC/iSCSI/NVMe over RoCE/NVMe over FC protocol to access Huawei storage in a container environment, you are advised to use host multipathing software to enhance the link redundancy and performance of the host and storage. If you do not want to use the software, skip this section.\nFor details about the OSs and multipathing software supported by Huawei CSI, see Table 2.\nIf you want to use the FC/iSCSI protocol to connect to Huawei storage, you are advised to use native DM-Multipath provided by the OS. If you want to use the NVMe over RoCE/NVMe over FC protocol to connect to Huawei storage, you are advised to use Huawei-developed UltraPath-NVMe. If you want to use the SCSI protocol to connect to Huawei storage, disable DM-Multipath provided by the OS. Prerequisites Multipathing software has been correctly installed on a host.\nIf you use native DM-Multipath provided by the OS, contact your host or OS provider to obtain the documents and software packages required for the installation. If you use Huawei-developed UltraPath or UltraPath-NVMe, contact Huawei engineers to obtain the UltraPath or UltraPath-NVMe documents and software packages. For details about the software package versions, see Table 1. Procedure If you use the iSCSI/FC protocol to connect to Huawei enterprise storage, configure and check host multipathing by referring to OceanStor Dorado and OceanStor Host Connectivity Guide for Red Hat.\nIf you use the NVMe over RoCE/NVMe over FC protocol to connect to Huawei enterprise storage, configure and check host multipathing by referring to OceanStor Dorado and OceanStor Host Connectivity Guide for Red Hat.\nIf you use iSCSI to connect to Huawei distributed storage, configure and check host multipathing by referring to Configuring Multipathing for an Application Server in FusionStorage 8.0.1 Block Storage Basic Service Configuration Guide.\nIf you use the native multipathing software provided by the OS, check whether the /etc/multipath.conf file contains the following configuration item.\ndefaults { user_friendly_names yes find_multipaths no } If the configuration item does not exist, add it to the beginning of the /etc/multipath.conf file.\nFor details about the functions of the user_friendly_names and find_multipaths parameters, see dm_multipath/config_file_defaults.\n","categories":"","description":"","excerpt":"If you plan to use the FC/iSCSI/NVMe over RoCE/NVMe over FC protocol …","ref":"/css-docs/en/docs/installation-and-deployment/installation-preparations/checking-the-host-multipathing-configuration/","tags":"","title":"Checking the Host Multipathing Configuration"},{"body":"This section describes the common problems and solutions for interconnecting with the Tanzu Kubernetes cluster. Currently, the following problems occur during interconnection with the Tanzu Kubernetes cluster:\nA Pod cannot be created because the PSP permission is not created. The mount point of the host is different from that of the native Kubernetes. As a result, a volume fails to be mounted. The livenessprobe container port conflicts with the Tanzu vSphere port. As a result, the container restarts repeatedly. ","categories":"","description":"","excerpt":"This section describes the common problems and solutions for …","ref":"/css-docs/en/docs/troubleshooting/common-problems-and-solutions-for-interconnecting-with-the-tanzu-kubernetes-cluster/","tags":"","title":"Common Problems and Solutions for Interconnecting with the Tanzu Kubernetes Cluster"},{"body":"User-defined Role Configurations For different storage resources, refer to the following configurations:\nFor NAS resources, configure the minimum permissions by referring to Table 1. For SAN resources, configure the minimum permissions by referring to Table 2. For details about how to configure permissions for user-defined roles, see OceanStor Dorado 6000, Dorado 18000 Series Product Documentation.\nTable 1 Minimum permissions for NAS resources\nPermission Object\nParent Object\nRead/Write Permission\nFunction\nworkload_type\nfile_storage_service\nRead-only\nQueries the workload type.\nfile_system\nfile_storage_service\nRead and write\nManages file systems.\nfs_snapshot\nfile_storage_service\nRead and write\nManages file system snapshots.\nquota\nfile_storage_service\nRead and write\nManages file system quotas.\nnfs_service\nfile_storage_service\nRead-only\nQueries NFS services.\nshare\nfile_storage_service\nRead and write\nManages NFS shares.\ndtree\nfile_storage_service\nRead and write\nManages dtrees.\nhyper_metro_pair\nhyper_metro\nRead and write\nCreates file system HyperMetro pairs.\nhyper_metro_domain\nhyper_metro\nRead-only\nQueries information about file system HyperMetro domains.\nremote_device\nlocal_data_protection\nRead-only\nQueries remote device information.\nstorage_pool\npool\nRead-only\nQueries storage pool information.\nsmart_qos\nresource_performance_tuning\nRead and write\nManages SmartQoS policies.\nsystem\nsystem\nRead-only\nQueries storage device information (this object needs to be configured only when the owning group is the system group).\nvstore\nvstore\nRead-only\nQueries vStore information.\nport\nnetwork\nRead-only\nQueries logical port information.\nTable 2 Minimum permissions for SAN resources\nPermission Object\nParent Object\nRead/Write Permission\nFunction\nremote_device\nlocal_data_protection\nRead-only\nQueries remote device information.\nhyper_clone\nlocal_data_protection\nRead and write\nManages clone pairs.\nlun_snapshot\nlocal_data_protection\nRead and write\nManages LUN snapshots.\nworkload_type\nlun\nRead-only\nQueries the workload type.\nlun\nlun\nRead and write\nManages LUNs.\nhost\nmapping_view\nRead and write\nManages hosts.\nhost_group\nmapping_view\nRead and write\nManages host groups.\ninitiator\nmapping_view\nRead and write\nManages initiators.\nlun_group\nmapping_view\nRead and write\nManages LUN groups.\nmapping_view\nmapping_view\nRead and write\nManages mapping views.\ntarget\nmapping_view\nRead-only\nQueries iSCSI initiators.\nport\nnetwork\nRead-only\nQueries logical ports.\nstorage_pool\npool\nRead-only\nQueries storage pool information.\nsmart_qos\nresource_performance_tuning\nRead and write\nManages SmartQoS policies.\nsystem\nsystem\nRead-only\nQueries storage device information (this object needs to be configured only when the owning group is the system group).\nvstore\nvstore\nRead-only\nQueries vStore information.\n","categories":"","description":"","excerpt":"User-defined Role Configurations For different storage resources, …","ref":"/css-docs/en/docs/appendix/configuring-custom-permissions/","tags":"","title":"Configuring Custom Permissions"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/en/docs/installation-and-deployment/","tags":"","title":"Installation and Deployment"},{"body":"huawei-csi supports two log output modes: file and console. file indicates that logs are output to the fixed directory (/var/log/huawei), and console indicates that logs are output to the standard directory of the container. You can set the log output mode as required. The default mode is file.\nProcedure Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nGo to the /helm/esdk directory and run the following command to obtain the original service configuration file. helm-huawei-csi indicates the Helm chart name specified during the installation of the earlier version, and huawei-csi indicates the Helm chart namespace specified during the installation of the earlier version. For details about the component package path, see Table 1.\nhelm get values helm-huawei-csi -n huawei-csi -a \u003e ./update-values.yaml Run the vi update-values.yaml command to open the file obtained in 2 and modify the configuration items. After the modification, press Esc and enter :wq! to save the modification.\n# The CSI driver parameter configuration csiDriver: # Driver name, it is strongly recommended not to modify this parameter # The CCE platform needs to modify this parameter, e.g. csi.oceanstor.com driverName: csi.huawei.com # Endpoint, it is strongly recommended not to modify this parameter endpoint: /csi/csi.sock # DR Endpoint, it is strongly recommended not to modify this parameter drEndpoint: /csi/dr-csi.sock # Maximum number of concurrent disk scans or detaches, support 1~10 connectorThreads: 4 # Flag to enable or disable volume multipath access, support [true, false] volumeUseMultipath: true # Multipath software used by fc/iscsi. support [DM-multipath, HW-UltraPath, HW-UltraPath-NVMe] scsiMultipathType: DM-multipath # Multipath software used by roce/fc-nvme. only support [HW-UltraPath-NVMe] nvmeMultipathType: HW-UltraPath-NVMe # Timeout interval for waiting for multipath aggregation when DM-multipath is used on the host. support 1~600 scanVolumeTimeout: 3 # Timeout interval for running command on the host. support 1~600 execCommandTimeout: 30 # check the number of paths for multipath aggregation # Allowed values: # true: the number of paths aggregated by DM-multipath is equal to the number of online paths # false: the number of paths aggregated by DM-multipath is not checked. # Default value: false allPathOnline: false # Interval for updating backend capabilities. support 60~600 backendUpdateInterval: 60 # Huawei-csi-controller log configuration controllerLogging: # Log record type, support [file, console] module: file # Log Level, support [debug, info, warning, error, fatal] level: info # Directory for storing logs fileDir: /var/log/huawei # Size of a single log file fileSize: 20M # Maximum number of log files that can be backed up. maxBackups: 9 # Huawei-csi-node log configuration nodeLogging: # Log record type, support [file, console] module: file # Log Level, support [debug, info, warning, error, fatal] level: info # Directory for storing logs fileDir: /var/log/huawei # Size of a single log file fileSize: 20M # Maximum number of log files that can be backed up. maxBackups: 9 Run the following command to update the log configuration.\nhelm upgrade helm-huawei-csi ./ -n huawei-csi -f ./update-values.yaml ","categories":"","description":"","excerpt":"huawei-csi supports two log output modes: file and console. file …","ref":"/css-docs/en/docs/common-operations/modifying-the-log-output-mode/","tags":"","title":"Modifying the Log Output Mode"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/","tags":"","title":"安装部署"},{"body":"现象描述 NAS场景下，创建Pod时，Pod一直处于ContainerCreating状态，此时查看huawei-csi-node的日志信息（详情请参考如何查看华为CSI日志），日志显示执行mount命令失败。\n根因分析 该问题可能由于存储侧未开启NFS 4.0/4.1/4.2协议，主机在使用NFS v4协议挂载失败后，未进行协商使用NFS v3协议挂载。\n解决措施或规避方法 开启存储侧的NFS 3/4.0/4.1/4.2协议，重新尝试默认挂载。 直接指定可用的NFS协议进行挂载，参考动态卷供应典型场景StorageClass配置示例。 ","categories":"","description":"","excerpt":"现象描述 NAS场景下，创建Pod时，Pod一直处于ContainerCreating状态，此时查看huawei-csi-node的日志信 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/pod%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/%E5%88%9B%E5%BB%BApod%E5%A4%B1%E8%B4%A5-%E6%97%A5%E5%BF%97%E6%98%BE%E7%A4%BA%E6%89%A7%E8%A1%8Cmount%E5%91%BD%E4%BB%A4%E5%A4%B1%E8%B4%A5/","tags":"","title":"创建Pod失败，日志显示执行mount命令失败"},{"body":"本章节用于说明对接Tanzu Kubernetes集群时常见问题及解决办法，目前对接Tanzu Kubernetes集群时主要有以下三个问题：\n未创建PSP权限导致Pod无法创建 主机挂载点与原生Kubernetes不同导致挂载卷失败 livenessprobe容器端口与Tanzu vSphere端口冲突导致容器不断重启 ","categories":"","description":"","excerpt":"本章节用于说明对接Tanzu Kubernetes集群时常见问题及解决办法，目前对接Tanzu Kubernetes集群时主要有以下三个问 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/%E5%AF%B9%E6%8E%A5tanzu-kubernetes%E9%9B%86%E7%BE%A4%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","tags":"","title":"对接Tanzu Kubernetes集群常见问题及解决方法"},{"body":"当您计划在容器环境中使用FC/iSCSI/NVMe over RoCE/NVMe over FC协议对华为存储进行访问时，推荐您使用主机多路径软件增强主机和存储的链路冗余和性能。如果您不准备使用多路径软件，请跳过本章节。\n华为CSI软件支持对接的操作系统和多路径软件请参考表 支持的主机操作系统及多路径软件版本。\n如果您准备使用FC/iSCSI协议对接华为存储时，推荐使用操作系统自带的原生DM-Multipath。 如果您准备使用NVMe over RoCE/NVMe over FC协议对接华为存储时，推荐使用华为自研的UltraPath-NVMe。 如果您使用SCSI协议对接华为存储时，请关闭操作系统自带的DM-Multipath。 前提条件\n主机多路径软件已经被正确的安装在主机上。\n如果您使用的是操作系统自带的原生DM-Multipath，请咨询您的主机或操作系统提供商获取安装所需的资料和软件包。 如果您使用的是华为自研的UltraPath或者UltraPath-NVMe，请联系华为工程师获取UltraPath或者UltraPath-NVMe的资料和软件包。软件包版本请参考表 软件包组件描述。 操作步骤\n如果您使用iSCSI/FC协议对接华为企业存储，请参考OceanStor Dorado \u0026 OceanStor在Red Hat下的主机连通性指南，对主机多路径进行配置和检查。\n如果您使用NVMe over RoCE/NVMe over FC协议对接华为企业存储，请参考OceanStor Dorado \u0026 OceanStor在Red Hat下的主机连通性指南，对主机多路径进行配置和检查。\n如果您使用iSCSI协议对接华为分布式存储，请参考 《FusionStorage 8.0.1 块存储基础业务配置指南》中的“应用服务器配置多路径”章节，对主机多路径进行配置和检查。\n如果您使用了操作系统原生多路径时，需要检查/etc/multipath.conf文件，检查文件是否存在如下配置：\ndefaults { user_friendly_names yes find_multipaths no } 如果配置不存在，请在/etc/multipath.conf文件开始处增加该配置项。\nuser_friendly_names 和find_multipaths 的参数作用请参考：dm_multipath/config_file_defaults\n","categories":"","description":"","excerpt":"当您计划在容器环境中使用FC/iSCSI/NVMe over RoCE/NVMe over FC协议对华为存储进行访问时，推荐您使用主机多路 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%AE%89%E8%A3%85%E5%89%8D%E5%87%86%E5%A4%87/%E6%A3%80%E6%9F%A5%E4%B8%BB%E6%9C%BA%E5%A4%9A%E8%B7%AF%E5%BE%84%E9%85%8D%E7%BD%AE/","tags":"","title":"检查主机多路径配置"},{"body":"自定义角色配置 针对不同的存储资源，请参考以下配置：\nNAS相关资源请参考表 NAS相关资源最小权限说明配置最小权限。 SAN相关资源请参考表 SAN相关资源最小权限说明配置最小权限。 可参考存储文档：《OceanStor Dorado 6000, Dorado 18000系列 产品文档》配置自定义角色权限。\n表 1 NAS相关资源最小权限说明\n权限对象\n父级对象\n读写权限\n功能说明\nworkload_type\nfile_storage_service\n只读\n查询应用类型\nfile_system\nfile_storage_service\n读写\n管理文件系统\nfs_snapshot\nfile_storage_service\n读写\n管理文件系统快照\nquota\nfile_storage_service\n读写\n管理文件系统配额\nnfs_service\nfile_storage_service\n只读\n查询NFS服务\nshare\nfile_storage_service\n读写\n管理NFS共享\ndtree\nfile_storage_service\n读写\n管理dtree\nhyper_metro_pair\nhyper_metro\n读写\n创建文件系统双活Pair\nhyper_metro_domain\nhyper_metro\n只读\n查询文件系统双活域信息\nremote_device\nlocal_data_protection\n只读\n查询远端设备信息\nstorage_pool\npool\n只读\n查询存储池信息\nsmart_qos\nresource_performance_tuning\n读写\n管理SmartQoS策略\nsystem\nsystem\n只读\n查询存储设备信息（仅所属组为系统组时需要配置）\nvstore\nvstore\n只读\n查询租户信息\nport\nnetwork\n只读\n查询逻辑端口信息\n表 2 SAN相关资源最小权限说明\n权限对象\n父级对象\n读写权限\n功能说明\nremote_device\nlocal_data_protection\n只读\n查询远端设备信息\nhyper_clone\nlocal_data_protection\n读写\n管理Clone Pair\nlun_snapshot\nlocal_data_protection\n读写\n管理LUN快照\nworkload_type\nlun\n只读\n查询应用类型\nlun\nlun\n读写\n管理LUN\nhost\nmapping_view\n读写\n管理主机\nhost_group\nmapping_view\n读写\n管理主机组\ninitiator\nmapping_view\n读写\n管理启动器\nlun_group\nmapping_view\n读写\n管理LUN组\nmapping_view\nmapping_view\n读写\n管理映射视图\ntarget\nmapping_view\n只读\n查询iSCSI启动器\nport\nnetwork\n只读\n查询逻辑端口\nstorage_pool\npool\n只读\n查询存储池信息\nsmart_qos\nresource_performance_tuning\n读写\n管理SmartQoS策略\nsystem\nsystem\n只读\n查询存储设备信息（仅所属组为系统组时需要配置）\nvstore\nvstore\n只读\n查询租户信息\n","categories":"","description":"","excerpt":"自定义角色配置 针对不同的存储资源，请参考以下配置：\nNAS相关资源请参考表 NAS相关资源最小权限说明配置最小权限。 SAN相关资源请参考 …","ref":"/css-docs/docs/%E9%99%84%E5%BD%95/%E9%85%8D%E7%BD%AE%E8%87%AA%E5%AE%9A%E4%B9%89%E6%9D%83%E9%99%90/","tags":"","title":"配置自定义权限"},{"body":"huawei-csi支持两种日志输出模式，分别是file和console。file指的是输出到固定的日志目录（例如：/var/log/huawei）；console指的是输出到容器标准目录。用户可以根据自身需求自行设置日志输出模式，默认为file.\n操作步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n进入/helm/esdk 目录，执行以下命令，获取原有服务配置文件。其中helm-huawei-csi为旧版本安装时指定的Helm Chart名称，huawei-csi为旧版本安装时指定的Helm Chart命名空间。组件包路径请参考表 软件包组件描述。\nhelm get values helm-huawei-csi -n huawei-csi -a \u003e ./update-values.yaml 执行vi update-values.yaml命令打开2中获取的文件，修改配置项，修改完成后，按Esc，并输入 :wq!，保存修改。\n# The CSI driver parameter configuration csiDriver: # Driver name, it is strongly recommended not to modify this parameter # The CCE platform needs to modify this parameter, e.g. csi.oceanstor.com driverName: csi.huawei.com # Endpoint, it is strongly recommended not to modify this parameter endpoint: /csi/csi.sock # DR Endpoint, it is strongly recommended not to modify this parameter drEndpoint: /csi/dr-csi.sock # Maximum number of concurrent disk scans or detaches, support 1~10 connectorThreads: 4 # Flag to enable or disable volume multipath access, support [true, false] volumeUseMultipath: true # Multipath software used by fc/iscsi. support [DM-multipath, HW-UltraPath, HW-UltraPath-NVMe] scsiMultipathType: DM-multipath # Multipath software used by roce/fc-nvme. only support [HW-UltraPath-NVMe] nvmeMultipathType: HW-UltraPath-NVMe # Timeout interval for waiting for multipath aggregation when DM-multipath is used on the host. support 1~600 scanVolumeTimeout: 3 # Timeout interval for running command on the host. support 1~600 execCommandTimeout: 30 # check the number of paths for multipath aggregation # Allowed values: # true: the number of paths aggregated by DM-multipath is equal to the number of online paths # false: the number of paths aggregated by DM-multipath is not checked. # Default value: false allPathOnline: false # Interval for updating backend capabilities. support 60~600 backendUpdateInterval: 60 # Huawei-csi-controller log configuration controllerLogging: # Log record type, support [file, console] module: file # Log Level, support [debug, info, warning, error, fatal] level: info # Directory for storing logs fileDir: /var/log/huawei # Size of a single log file fileSize: 20M # Maximum number of log files that can be backed up. maxBackups: 9 # Huawei-csi-node log configuration nodeLogging: # Log record type, support [file, console] module: file # Log Level, support [debug, info, warning, error, fatal] level: info # Directory for storing logs fileDir: /var/log/huawei # Size of a single log file fileSize: 20M # Maximum number of log files that can be backed up. maxBackups: 9 执行以下命令更新日志配置。\nhelm upgrade helm-huawei-csi ./ -n huawei-csi -f ./update-values.yaml ","categories":"","description":"","excerpt":"huawei-csi支持两种日志输出模式，分别是file和console。file指的是输出到固定的日志目录（例 …","ref":"/css-docs/docs/%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/%E4%BF%AE%E6%94%B9%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA%E6%A8%A1%E5%BC%8F/","tags":"","title":"修改日志输出模式"},{"body":"Symptom When a Pod is being created, the Pod keeps in the ContainerCreating state. It is found that the following alarm event is printed for the Pod: rpc error: code = Internal desc = publishInfo doesn’t exist\nRoot Cause Analysis As required by CSI, when a workload needs to use a PV, the Container Orchestration system (CO system, communicating with the CSI plug-in using RPC requests) invokes the ControllerPublishVolume interface (provided by huawei-csi-controller) in the CSI protocol provided by the CSI plug-in to map the PV, and then invokes the NodeStageVolume interface (provided by huawei-csi-node) provided by the CSI plug-in to mount the PV. During a complete mounting operation, only the huawei-csi-node service receives the NodeStageVolume request. Before that, the huawei-csi-controller service does not receive the ControllerPublishVolume request. As a result, the huawei-csi-controller service does not map the PV volume and does not send the mapping information to the huawei-csi-node service. Therefore, error message publishInfo doesn’t exist is reported.\nSolution To solve this problem, Kubernetes needs to invoke the ControllerPublishVolume interface.\nIf this operation is triggered by all workloads created by earlier versions in the cluster, this problem will not occur.\nProcedure Use a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to obtain the information about the node where a workload is located.\nkubectl get pod error-pod -n error-pod-in-namespace -owide The following is an example of the command output.\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES pod-nfs 0/1 ContainerCreating 0 3s \u003cnone\u003e node-1 \u003cnone\u003e \u003cnone\u003e Fail over the workload to another node.\nIf the failover cannot be completed in the cluster, you can delete the workload and create a new one on the original node.\nCheck whether the workload is successfully started. If it fails to be started, contact Huawei technical support engineers.\nChecking Cluster Workloads When Kubernetes invokes the CSI plug-in to complete volume mapping, the VolumeAttachment resource is used to save the mapping information, indicating that a specified volume is attached to or detached from a specified node. This problem occurs because publishInfo does not exist. You can view the VolumeAttachment resource information to check whether this problem is also involved in other workloads in the cluster. The procedure is as follows:\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the following command to obtain the VolumeAttachment information and retain resources whose ATTACHER field is csi.huawei.com. csi.huawei.com indicates the Huawei CSI driver name and can be configured in the values.yaml file. The corresponding configuration item is csiDriver.driverName. For details about the configuration item, see Table 4.\nkubectl get volumeattachments.storage.k8s.io The following is an example of the command output.\nNAME ATTACHER PV NODE ATTACHED AGE csi-47abxx csi.huawei.com pvc-1xx node-1 true 12h Run the following command to view the VolumeAttachment resource details. In the following information, csi-47abxx is the resource name obtained in 2.\nkubectl get volumeattachments.storage.k8s.io csi-47abxx -o yaml The following is an example of the command output.\nkind: VolumeAttachment metadata: annotations: csi.alpha.kubernetes.io/node-id: '{\"HostName\":\"node-1\"}' finalizers: - external-attacher/csi-huawei-com name: csi-47abxxx uid: 0c87fa8a-c3d6-4623-acb8-71d6206d030d spec: attacher: csi.huawei.com nodeName: debian-node source: persistentVolumeName: pvc-1xx status: attached: true attachmentMetadata: publishInfo: '{\u003cPUBLISH-INFO\u003e}' If status.attachmentMetadata.publishInfo exists in the resource obtained in 3, the problem described in this FAQ is not involved in the workloads created using pvc-1xx on the node-1 node. node-1 and pvc-1xx are the query results in 2. If status.attachmentMetadata.publishInfo does not exist, rectify the fault by referring to Solution.\nIf multiple VolumeAttachment resources exist, repeat 3 to 4.\n","categories":"","description":"","excerpt":"Symptom When a Pod is being created, the Pod keeps in the …","ref":"/css-docs/en/docs/troubleshooting/pod-issues/a-pod-fails-to-be-created-and-message-publishinfo-doesn-t-exist-is-displayed-in-the-events-log/","tags":"","title":"A Pod Fails to Be Created and Message publishInfo doesn't exist Is Displayed in the Events Log"},{"body":"This section describes how to check whether the status of host-dependent software on worker nodes in a cluster is normal. In this example, the host OS is CentOS 7.9 x86_64.\nCheck the status of the iSCSI client.\nsystemctl status iscsi iscsid Check the status of the NFS client.\nsystemctl status rpcbind Check the status of DM-Multipath.\nsystemctl status multipathd.socket multipathd Check the status of UltraPath.\nsystemctl status nxup Check the status of UltraPath-NVMe.\nsystemctl status upudev upService_plus ","categories":"","description":"","excerpt":"This section describes how to check whether the status of …","ref":"/css-docs/en/docs/installation-and-deployment/installation-preparations/checking-the-status-of-host-dependent-software/","tags":"","title":"Checking the Status of Host-Dependent Software"},{"body":"The ReadWriteOnce access mode is the fourth access mode introduced by Kubernetes v1.22 for PVs and PVCs. If you create a Pod using a PVC in ReadWriteOncePod access mode, Kubernetes ensures that the Pod is the only Pod in the cluster that can read or write the PVC.\nThe ReadWriteOncePod access mode is an alpha feature in Kubernetes v1.22/1.23/1.24. Therefore, you need to enable the ReadWriteOncePod feature in feature-gates of kube-apiserver, kube-scheduler, and kubelet before using the access mode.\nCurrently, the CCE or CCE Agile platform does not support the ReadWriteOncePod feature gate.\nProcedure Enable the ReadWriteOncePod feature gate for kube-apiserver.\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the vi /etc/kubernetes/manifests/kube-apiserver.yaml command, press I or Insert to enter the insert mode, and add –feature-gates=ReadWriteOncePod=true to the kube-apiserver container. After the modification is complete, press Esc and enter :wq! to save the modification.\n... spec: containers: - command: - kube-apiserver - --feature-gates=ReadWriteOncePod=true ... After the editing is complete, Kubernetes will automatically apply the updates.\nEnable the ReadWriteOncePod feature gate for kube-scheduler.\nUse a remote access tool, such as PuTTY, to log in to any master node in the Kubernetes cluster through the management IP address.\nRun the vi /etc/kubernetes/manifests/kube-scheduler.yaml command, press I or Insert to enter the insert mode, and add –feature-gates=ReadWriteOncePod=true to the kube-scheduler container. After the modification is complete, press Esc and enter :wq! to save the modification.\n... spec: containers: - command: - kube-scheduler - --feature-gates=ReadWriteOncePod=true ... After the editing is complete, Kubernetes will automatically apply the updates.\nEnable the ReadWriteOncePod feature gate for kubelet.\nThe dynamic Kubelet configuration function is not used since v1.22 and deleted in v1.24. Therefore, you need to perform the following operations on kubelet on each worker node in the cluster.\nUse a remote access tool, such as PuTTY, to log in to any worker node in the Kubernetes cluster through the management IP address.\nRun the vi /var/lib/kubelet/config.yaml command, press I or Insert to enter the editing state, and add ReadWriteOncePod: true to the featureGates field of the KubeletConfiguration object. If the featureGates field does not exist, add it at the same time. After the modification is complete, press Esc and enter :wq! to save the modification.\napiVersion: kubelet.config.k8s.io/v1beta1 featureGates: ReadWriteOncePod: true ... The default path of the kubelet configuration file is /var/lib/kubelet/config.yaml. Enter the path based on site requirements.\nAfter the configuration is complete, run the systemctl restart kubelet command to restart kubelet.\n","categories":"","description":"","excerpt":"The ReadWriteOnce access mode is the fourth access mode introduced by …","ref":"/css-docs/en/docs/common-operations/enabling-the-readwriteoncepod-feature-gate/","tags":"","title":"Enabling the ReadWriteOncePod Feature Gate"},{"body":"This section lists the resource requests and limits used by each container of the Huawei CSI plug-in. For details about the unit, see Resource units in Kubernetes.\nTable 1 Container resource requests and limits\nPod Name\nContainer Name\nCPU Request\nCPU Limit\nMemory Request\nMemory Limit\nhuawei-csi-controller\nhuawei-csi-driver\n50m\n500m\n128Mi\n1Gi\nstorage-backend-sidecar\n50m\n300m\n128Mi\n512Mi\nstorage-backend-controller\n50m\n300m\n128Mi\n512Mi\nhuawei-csi-extender\n50m\n300m\n128Mi\n512Mi\ncsi-attacher\n50m\n300m\n128Mi\n512Mi\ncsi-provisioner\n50m\n300m\n128Mi\n512Mi\ncsi-resize\n50m\n300m\n128Mi\n512Mi\ncsi-snapshotter\n50m\n300m\n128Mi\n512Mi\nsnapshot-controller\n50m\n300m\n128Mi\n512Mi\nliveness-probe\n10m\n100m\n128Mi\n128Mi\nhuawei-csi-node\nhuawei-csi-driver\n50m\n500m\n128Mi\n1Gi\ncsi-node-driver-registrar\n50m\n300m\n128Mi\n128Mi\nliveness-probe\n10m\n100m\n128Mi\n128Mi\nModifying Resource Requests and Limits If you need to modify the resource requests and limits of a container, perform the following steps (in the following example, Helm is used to install Huawei CSI):\nIf Helm is used for installation, go to the /helm/esdk/templates directory. For manual deployment, the file to be modified is in the /manual/esdk/deploy directory. For details about the component package path, see Table 1.\nModify the deployment template file.\nIf the Pod name is huawei-csi-controller, modify the huawei-csi-controller.yaml file. If the Pod name is huawei-csi-node, modify the huawei-csi-node.yaml file. For details about Pod names, see Table 1.\nFor example, to modify the resource request of the huawei-csi-driver container in the Pod named huawei-csi-node, run the following command to edit the configuration file and find the container whose spec.template.spec.containes.name is huawei-csi-driver. Modify resource requests and limits as required.\nvi huawei-csi-node.yaml Edit the following content.\ncontainers - name: huawei-csi-driver ... resources: limits: cpu: 500m memory: 1Gi requests: cpu: 50m memory: 128Mi If Huawei CSI is not installed, the modification of resource requests and limits takes effect after Huawei CSI is installed by referring to Installing Huawei CSI on Kubernetes, OpenShift, and Tanzu.\nIf Huawei CSI has been installed, the modification of resource requests and limits takes effect after Huawei CSI is updated by referring to Upgrading Huawei CSI.\n","categories":"","description":"","excerpt":"This section lists the resource requests and limits used by each …","ref":"/css-docs/en/docs/appendix/huawei-csi-resource-management/","tags":"","title":"Huawei CSI Resource Management"},{"body":"Backend is an abstract concept of Huawei storage resources. Each Huawei storage device can abstract multiple backend resources using features such as tenants, storage pools, and protocols. Each backend exists independently and defines Huawei storage information required for providing persistent volumes for Kubernetes clusters.\nThis chapter describes how to use the oceanctl tool to manage storage backends, including creating, querying, updating, and deleting backends.\nDescription of the oceanctl Tool You have obtained the oceanctl tool, copied the oceanctl tool to the environment directory, for example, /usr/local/bin, and obtained the execute permission. The oceanctl tool is stored in /bin/oceanctl of the software package. The oceanctl tool depends on kubectl (for the Kubernetes platform) or oc (for the OpenShift platform) commands. Therefore, you need to run the tool on a node where kubectl or oc commands can be executed. By default, the user who runs oceanctl commands must have the read and write permissions on the /var/log directory. If you do not have the permissions on the directory, run the –log-dir=/path/to/custom command to specify a directory on which you have the permissions as the log file directory. huawei-csi is the default namespace used by oceanctl to create a backend. For details about oceanctl commands, see Description of oceanctl Commands. ","categories":"","description":"","excerpt":"Backend is an abstract concept of Huawei storage resources. Each …","ref":"/css-docs/en/docs/storage-backend-management/","tags":"","title":"Storage Backend Management"},{"body":"现象描述 创建Pod时，Pod一直处于ContainerCreating状态，查看Pod中有打印告警事件：rpc error: code = Internal desc = publishInfo doesn’t exist。\n根因分析 按照CSI协议约定，工作负载要使用一个PV卷时，CO（Container Orchestration system，通过RPC请求与CSI插件通信）会调用CSI插件提供的CSI协议中的“ControllerPublishVolume”接口（huawei-csi-controller服务提供）完成PV卷的映射，然后调用CSI插件提供的“NodeStageVolume”接口（huawei-csi-node服务提供）完成PV卷的挂载。导致出现“publishInfo doesn’t exist”错误的原因是在一次完整的挂载时，仅huawei-csi-node服务收到了“NodeStageVolume”请求，而在此之前huawei-csi-controller服务未收到“ControllerPublishVolume”请求，导致huawei-csi-controller服务未完成PV卷的映射，没有把映射信息传递给huawei-csi-node服务。\n解决措施 解决该问题，需要触发Kubernetes调用“ControllerPublishVolume”接口。\n如果集群中所有旧版本创建的工作负载均触发了该操作，则后续将不会出现该问题。\n操作步骤 使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令，获取工作负载所在节点信息。\nkubectl get pod error-pod -n error-pod-in-namespace -owide 命令结果示例如下。\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES pod-nfs 0/1 ContainerCreating 0 3s \u003cnone\u003e node-1 \u003cnone\u003e \u003cnone\u003e 将该工作负载漂移至其他节点。\n若在集群内无法完成漂移，可在原节点完成工作负载重建，即进行删除-新建操作。\n观察该工作负载是否成功拉起，如果拉起失败请联系华为工程师。\n集群工作负载排查 Kubernetes调用CSI插件完成卷映射时，将使用VolumeAttachment资源保存映射信息，用于表示将指定的卷从指定的节点上附加或分离。由于该问题是由于publishInfo不存在导致，因此可通过查看VolumeAttachment资源信息排查集群中其他工作负载是否存在该问题。具体步骤如下：\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行以下命令，获取VolumeAttachment信息，并保留ATTACHER字段为csi.huawei.com的资源，其中csi.huawei.com为华为CSI驱动名称，可在values.yaml文件中配置，配置项为csiDriver.driverName，配置项详情描述参考表 csiDriver配置项说明。\nkubectl get volumeattachments.storage.k8s.io 命令结果示例如下。\nNAME ATTACHER PV NODE ATTACHED AGE csi-47abxx csi.huawei.com pvc-1xx node-1 true 12h 执行以下命令查看VolumeAttachment资源详情，其中csi-47abxx为2中查询到的资源名称。\nkubectl get volumeattachments.storage.k8s.io csi-47abxx -o yaml 命令结果示例如下。\nkind: VolumeAttachment metadata: annotations: csi.alpha.kubernetes.io/node-id: '{\"HostName\":\"node-1\"}' finalizers: - external-attacher/csi-huawei-com name: csi-47abxxx uid: 0c87fa8a-c3d6-4623-acb8-71d6206d030d spec: attacher: csi.huawei.com nodeName: debian-node source: persistentVolumeName: pvc-1xx status: attached: true attachmentMetadata: publishInfo: '{\u003cPUBLISH-INFO\u003e}' 若3中查询到的资源中存在status.attachmentMetadata.publishInfo，则证明node-1节点上使用pvc-1xx创建的若干工作负载不会存在本FAQ描述的错误，其中node-1和pvc-1xx为2中查询结果。若status.attachmentMetadata.publishInfo不存在，请参考解决措施章节解决。\n存在多个VolumeAttachment资源时，重复执行3~4。\n","categories":"","description":"","excerpt":"现象描述 创建Pod时，Pod一直处于ContainerCreating状态，查看Pod中有打印告警事件：rpc error: code = …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/pod%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/%E5%88%9B%E5%BB%BApod%E5%A4%B1%E8%B4%A5-events%E6%97%A5%E5%BF%97%E6%98%BE%E7%A4%BA-publishinfo-doesn-t-exist/","tags":"","title":"创建Pod失败，Events日志显示“publishInfo doesn't exist”"},{"body":"后端是华为存储资源的抽象概念，每台华为存储设备可以通过租户/存储池/协议等特性抽象出多个后端资源，每个后端独立存在，其中定义了为Kubernetes集群供应持久卷时所需要的华为存储信息。\n本章节用于描述使用oceanctl工具管理存储后端，包括后端的创建/查询/更新/删除操作\noceanctl工具说明 获取oceanctl工具，将oceanctl工具拷贝到环境目录下,例如（/usr/local/bin），且赋予可执行权限，oceanctl工具位于软件包/bin/oceanctl。 oceanctl工具依赖kubectl（Kubernetes平台）或oc（OpenShift平台）命令，因此需要在可执行kubectl或oc命令的节点运行。 默认情况下，执行oceanctl命令的用户需要有/var/log目录的读写权限。如果没有该目录权限，可通过“–log-dir=/path/to/custom”指定有权限目录作为日志文件目录。 oceanctl创建后端的命名空间默认为huawei-csi。 oceanctl命令详细说明请参考oceanctl命令说明。 ","categories":"","description":"","excerpt":"后端是华为存储资源的抽象概念，每台华为存储设备可以通过租户/存储池/协议等特性抽象出多个后端资源，每个后端独立存在，其中定义了 …","ref":"/css-docs/docs/%E5%AD%98%E5%82%A8%E5%90%8E%E7%AB%AF%E7%AE%A1%E7%90%86/","tags":"","title":"存储后端管理"},{"body":"本章节列举了华为CSI插件中每个容器所使用的资源请求和限制。其中单位说明请参考Kubernetes 中的资源单位。\n表 1 容器资源请求和限制\nPod 名称\n容器名称\nCPU 请求\nCPU 限制\nMemory 请求\nMemory 限制\nhuawei-csi-controller\nhuawei-csi-driver\n50m\n500m\n128Mi\n1Gi\nstorage-backend-sidecar\n50m\n300m\n128Mi\n512Mi\nstorage-backend-controller\n50m\n300m\n128Mi\n512Mi\nhuawei-csi-extender\n50m\n300m\n128Mi\n512Mi\ncsi-attacher\n50m\n300m\n128Mi\n512Mi\ncsi-provisioner\n50m\n300m\n128Mi\n512Mi\ncsi-resize\n50m\n300m\n128Mi\n512Mi\ncsi-snapshotter\n50m\n300m\n128Mi\n512Mi\nsnapshot-controller\n50m\n300m\n128Mi\n512Mi\nliveness-probe\n10m\n100m\n128Mi\n128Mi\nhuawei-csi-node\nhuawei-csi-driver\n50m\n500m\n128Mi\n1Gi\ncsi-node-driver-registrar\n50m\n300m\n128Mi\n128Mi\nliveness-probe\n10m\n100m\n128Mi\n128Mi\n修改资源请求和限制 如果需要修改容器的资源请求和限制，以Helm安装华为CSI为例，可参考以下步骤\n使用Helm安装时进入/helm/esdk/templates 目录。手动部署时需要修改的文件在/manual/esdk/deploy目录，其中组件包路径请参考表 软件包组件描述。\n修改部署模板文件。\nPod名称为huawei-csi-controller时，修改huawei-csi-controller.yaml文件。 Pod名称为huawei-csi-node时，修改huawei-csi-node.yaml文件。 Pod名称的分类，请参考表 容器资源请求和限制。\n以修改Pod名称为huawei-csi-node中huawei-csi-driver容器的资源请求为例，执行命令编辑配置文件，找到spec.template.spec.containes.name为huawei-csi-driver的容器。按需修改资源请求和限制。\nvi huawei-csi-node.yaml 编辑如下内容。\ncontainers - name: huawei-csi-driver ... resources: limits: cpu: 500m memory: 1Gi requests: cpu: 50m memory: 128Mi 若华为CSI未安装，则参考Kubernetes、OpenShift、Tanzu安装华为CSI章节安装华为CSI后，资源请求和限制的修改生效。\n若已安装华为CSI，则参考升级华为CSI章节更新华为CSI后，资源请求和限制的修改生效。\n","categories":"","description":"","excerpt":"本章节列举了华为CSI插件中每个容器所使用的资源请求和限制。其中单位说明请参考Kubernetes 中的资源单位。\n表 1 容器资源请求和限 …","ref":"/css-docs/docs/%E9%99%84%E5%BD%95/%E5%8D%8E%E4%B8%BAcsi%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/","tags":"","title":"华为CSI资源管理"},{"body":"本章节介绍如何检查集群中工作节点上主机依赖软件状态是否正常。本例中主机操作系统为CentOS 7.9 x86_64。\n检查iSCSI客户端状态。\nsystemctl status iscsi iscsid 检查NFS客户端状态。\nsystemctl status rpcbind 检查DM-Multipath多路径软件状态。\nsystemctl status multipathd.socket multipathd 检查UltraPath多路径软件状态。\nsystemctl status nxup 检查UltraPath-NVMe多路径软件状态。\nsystemctl status upudev upService_plus ","categories":"","description":"","excerpt":"本章节介绍如何检查集群中工作节点上主机依赖软件状态是否正常。本例中主机操作系统为CentOS 7.9 x86_64。\n检查iSCSI客户端状 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%AE%89%E8%A3%85%E5%89%8D%E5%87%86%E5%A4%87/%E6%A3%80%E6%9F%A5%E4%B8%BB%E6%9C%BA%E4%BE%9D%E8%B5%96%E8%BD%AF%E4%BB%B6%E7%8A%B6%E6%80%81/","tags":"","title":"检查主机依赖软件状态"},{"body":"ReadWriteOnce访问模式是Kubernetes v1.22版本为PV和PVC引入的第四种访问模式。如果您使用ReadWriteOncePod访问模式的PVC创建一个Pod，Kubernetes会确保该Pod是整个集群中唯一可以读取或写入该PVC的Pod。\n由于ReadWriteOncePod访问模式在当前已发布的Kubernetes v1.22/1.23/1.24版本中是alpha特性，需要先在kube-apiserver、kube-scheduler和kubelet的feature-gates中开启ReadWriteOncePod特性才能使用。\nCCE / CCE Agile平台暂时不支持开启ReadWriteOncePod功能门\n操作步骤 为kube-apiserver启用ReadWriteOncePod功能门。\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行vi /etc/kubernetes/manifests/kube-apiserver.yaml命令，按I或Insert进入编辑状态，为 kube-apiserver容器添加参数–feature-gates=ReadWriteOncePod=true。修改完成后，按Esc，并输入 :wq!，保存修改。\n... spec: containers: - command: - kube-apiserver - --feature-gates=ReadWriteOncePod=true ... 在编辑完成后，Kubernetes会自动应用更新，不需要手动更新。\n为kube-scheduler启用ReadWriteOncePod功能门。\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意master节点。\n执行vi /etc/kubernetes/manifests/kube-scheduler.yaml命令，按I或Insert进入编辑状态，为kube-scheduler容器添加参数–feature-gates=ReadWriteOncePod=true。修改完成后，按Esc，并输入 :wq!，保存修改。\n… spec: containers: - command: - kube-scheduler - --feature-gates=ReadWriteOncePod=true ... 在编辑完成后，Kubernetes会自动应用更新，不需要手动更新。\n为kubelet启用ReadWriteOncePod功能门。\n由于动态Kubelet配置功能在v1.22中已弃用，并且在v1.24中删除，因此集群中每个worker节点上的kubelet都需要执行以下操作。\n使用远程访问工具（以PuTTY为例），通过管理IP地址，登录Kubernetes集群的任意worker节点。\n执行vi /var/lib/kubelet/config.yaml命令，按I或Insert进入编辑状态，为KubeletConfiguration对象的featureGates字段添加ReadWriteOncePod: true，如果没有featureGates字段请一并添加。修改完成后，按Esc，并输入 :wq!，保存修改。\napiVersion: kubelet.config.k8s.io/v1beta1 featureGates: ReadWriteOncePod: true ... kubelet配置文件的默认路径为/var/lib/kubelet/config.yaml，请根据实际情况填写。\n在配置完成后，执行systemctl restart kubelet命令重启kubelet。\n","categories":"","description":"","excerpt":"ReadWriteOnce访问模式是Kubernetes v1.22版本为PV和PVC引入的第四种访问模式。如果您使 …","ref":"/css-docs/docs/%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/%E5%BC%80%E5%90%AFreadwriteoncepod%E5%8A%9F%E8%83%BD%E9%97%A8/","tags":"","title":"开启ReadWriteOncePod功能门"},{"body":"Symptom When a Pod is being created, the Pod is always in the ContainerCreating state. Alternatively, after kubelet is restarted, logs show that the mount point already exists. Check the log information of huawei-csi-node (for details, see Viewing Huawei CSI Logs). The error information is: The mount /var/lib/kubelet/pods/xxx/mount is already exist, but the source path is not /var/lib/kubelet/plugins/kubernetes.io/xxx/globalmount\nRoot Cause Analysis The root cause of this problem is that Kubernetes performs repeated mounting operations.\nSolution or Workaround Run the following command to unmount the existing path. In the command, /var/lib/kubelet/pods/xxx/mount indicates the existing mount path displayed in the logs.\numount /var/lib/kubelet/pods/xxx/mount ","categories":"","description":"","excerpt":"Symptom When a Pod is being created, the Pod is always in the …","ref":"/css-docs/en/docs/troubleshooting/pod-issues/after-a-pod-fails-to-be-created-or-kubelet-is-restarted-logs-show-that-the-mount-point-already-exist/","tags":"","title":"After a Pod Fails to Be Created or kubelet Is Restarted, Logs Show That the Mount Point Already Exists"},{"body":"The installation of Huawei CSI depends on the images listed in the following table. If all worker nodes in the cluster have been connected to the Internet and can pull images online, you can skip this section. If nodes in the cluster cannot connect to the Internet, download the corresponding image file based on the Kubernetes version and upload it to the image repository or import it to all worker nodes in the Kubernetes cluster.\nThe huawei-csi-controller service depends on the following sidecar images: livenessprobe, csi-provisioner, csi-attacher, csi-resizer, csi-snapshotter, snapshot-controller, storage-backend-controller, storage-backend-sidecar, huawei-csi-driver, and huawei-csi-extender. The huawei-csi-node service depends on the following sidecar images: livenessprobe, csi-node-driver-registrar, and huawei-csi-driver.\nFor details about the functions and details of each image, see the following table.\nTable 1 Images on which Huawei CSI depends\nContainer Name\nContainer Image\nK8s Version Requirements\nFeature Description\nlivenessprobe\nk8s.gcr.io/sig-storage/livenessprobe:v2.5.0\nv1.16+\nThis image is provided by the Kubernetes community, used to monitor the health status of CSI and report it to Kubernetes so that Kubernetes can automatically detect CSI program problems and restart the Pod to rectify the problems.\ncsi-resizer\nk8s.gcr.io/sig-storage/csi-resizer:v1.4.0\nv1.16+\nThis image is provided by the Kubernetes community, used to call CSI to provide more storage space for a PVC when expanding the capacity of the PVC.\ncsi-node-driver-registrar\nk8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.3.0\nv1.16+\nThis image is provided by the Kubernetes community, used to obtain CSI information and register a node with kubelet using the plug-in registration mechanism of kubelet so that Kubernetes can detect the connection between the node and Huawei storage.\ncsi-snapshotter\nk8s.gcr.io/sig-storage/csi-snapshotter:v4.2.1\nv1.17+\nThis image is provided by the Kubernetes community, used to call CSI to create or delete a snapshot on the storage system when creating or deleting a VolumeSnapshot.\nsnapshot-controller\nk8s.gcr.io/sig-storage/snapshot-controller:v4.2.1\nv1.17+\nThis image is provided by the Kubernetes community, used to listen to the VolumeSnapshot and VolumeSnapshotContent objects in the Kubernetes API and trigger csi-snapshotter to create a snapshot on the storage system when creating or deleting a VolumeSnapshot.\ncsi-provisioner\nk8s.gcr.io/sig-storage/csi-provisioner:v3.0.0\nv1.17+\nThis image is provided by the Kubernetes community, used to create or delete PVCs.\nCalls the huawei-csi-controller service to create a LUN or file system on the storage system as a PV when creating a PVC.Calls the huawei-csi-controller service to delete the LUN or file system corresponding to the PV when deleting a PVC. quay.io/k8scsi/csi-provisioner:v1.4.0\nv1.16.x\ncsi-attacher\nk8s.gcr.io/sig-storage/csi-attacher:v3.4.0\nv1.17+\nCalls the huawei-csi-controller service to perform the \"Publish/Unpublish Volume\" operation when creating or deleting a Pod.\nquay.io/k8scsi/csi-attacher:v1.2.1\nv.1.16.x\nstorage-backend-controller\nstorage-backend-controller:4.5.0\nv1.16+\nThis image is provided by Huawei CSI software package, used to manage storageBackendClaim resources.\nstorage-backend-sidecar\nstorage-backend-sidecar:4.5.0\nv1.16+\nThis image is provided by Huawei CSI software package, used to manage storageBackendContent resources.\nhuawei-csi-driver\nhuawei-csi:4.5.0\nv1.16+\nThis image is provided by Huawei CSI software package, used to provide all features supported by Huawei CSI.\nhuawei-csi-extender\nhuawei-csi-extender:4.5.0\nv1.16+\nThis image is provided by Huawei CSI software package, used to provide extended features of Huawei CSI.\nIf the cluster is not connected to the Internet, manually download the container images and upload them to the cluster. For details, see Downloading a Container Image.\n","categories":"","description":"","excerpt":"The installation of Huawei CSI depends on the images listed in the …","ref":"/css-docs/en/docs/installation-and-deployment/installation-preparations/checking-the-images-on-which-csi-depends/","tags":"","title":"Checking the Images on Which CSI Depends"},{"body":"Procedure Copy the authentication file of the Kubernetes cluster and modify /etc/kubernetes/admin.conf to be the actual authentication file.\nmkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config Change the user and user group of the authentication file.\nsudo chown $(id -u):$(id -g) $HOME/.kube/config Configure the KUBECONFIG environment variable of the current user. The following uses Ubuntu 20.04 as an example.\necho \"export KUBECONFIG=$HOME/.kube/config\" \u003e\u003e ~/.bashrc source ~/.bashrc ","categories":"","description":"","excerpt":"Procedure Copy the authentication file of the Kubernetes cluster and …","ref":"/css-docs/en/docs/common-operations/configuring-access-to-the-kubernetes-cluster-as-a-non-root-user/","tags":"","title":"Configuring Access to the Kubernetes Cluster as a Non-root User"},{"body":"This chapter describes how to use Huawei CSI to manage the lifecycle of PVs and snapshots.\nDo not delete a storage backend when using Huawei CSI to manage volumes. When block volumes are mapped, Huawei CSI automatically creates associated objects, such as hosts, host groups, and LUN groups, as well as mapping views. If these objects are manually created on the storage, the mapping logic of Huawei CSI will be affected. Therefore, ensure that these objects are deleted before mapping volumes using Huawei CSI. ","categories":"","description":"","excerpt":"This chapter describes how to use Huawei CSI to manage the lifecycle …","ref":"/css-docs/en/docs/using-huawei-csi/","tags":"","title":"Using Huawei CSI"},{"body":"现象描述 创建Pod时，Pod一直处于ContainerCreating状态，或者重启kubelet后，日志中显示挂载点已存在。此时查看huawei-csi-node的日志信息（详情请参考如何查看华为CSI日志），日志提示错误为：The mount /var/lib/kubelet/pods/xxx/mount is already exist, but the source path is not /var/lib/kubelet/plugins/kubernetes.io/xxx/globalmount\n根因分析 该问题的根因是Kubernetes进行重复挂载操作。\n解决措施或规避方法 执行以下命令，将已存在的路径解除挂载，其中“/var/lib/kubelet/pods/xxx/mount”为日志中提示的已存在的挂载路径。\numount /var/lib/kubelet/pods/xxx/mount ","categories":"","description":"","excerpt":"现象描述 创建Pod时，Pod一直处于ContainerCreating状态，或者重启kubelet后，日志中显示挂载点已存在。此时查 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/pod%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/%E5%88%9B%E5%BB%BApod%E5%A4%B1%E8%B4%A5%E6%88%96%E9%87%8D%E5%90%AFkubelet%E5%90%8E-%E6%97%A5%E5%BF%97%E6%98%BE%E7%A4%BA%E6%8C%82%E8%BD%BD%E7%82%B9%E5%B7%B2%E5%AD%98%E5%9C%A8/","tags":"","title":"创建Pod失败或重启kubelet后，日志显示挂载点已存在"},{"body":"华为CSI安装过程中需要依赖下表中的镜像，若集群中的所有worker节点已连接互联网且能够在线拉取镜像，则可跳过本章节。若集群中的节点无法连接互联网，则请根据使用的Kubernetes版本，下载对应的镜像文件并上传到镜像仓库中或者导入Kubernetes集群的所有worker节点中。\nhuawei-csi-controller服务依赖的sidecar镜像：livenessprobe、csi-provisioner、csi-attacher、csi-resizer、csi-snapshotter、snapshot-controller、storage-backend-controller、storage-backend-sidecar、huawei-csi-driver和huawei-csi-extender。huawei-csi-node服务依赖的sidecar镜像：livenessprobe、csi-node-driver-registrar和huawei-csi-driver。\n关于每个镜像的功能和详情，请参考下表。\n表 1 Huawei CSI依赖的镜像\n容器名称\n容器镜像\nK8s版本要求\n功能描述\nlivenessprobe\nk8s.gcr.io/sig-storage/livenessprobe:v2.5.0\nv1.16+\nKubernetes社区提供，提供用于监控CSI的健康状态，并上报给Kubernetes，使Kubernetes能够自动检测CSI程序的问题并重启Pod尝试修改该问题。\ncsi-resizer\nk8s.gcr.io/sig-storage/csi-resizer:v1.4.0\nv1.16+\nKubernetes社区提供，在扩容PVC时，调用CSI给PVC提供更多的存储容量空间。\ncsi-node-driver-registrar\nk8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.3.0\nv1.16+\nKubernetes社区提供，用于获取CSI信息，并通过kubelet的插件注册机制将节点注册到kubelet中，从而Kubernetes能够感知该节点与华为存储的对接。\ncsi-snapshotter\nk8s.gcr.io/sig-storage/csi-snapshotter:v4.2.1\nv1.17+\nKubernetes社区提供，在创建/删除VolumeSnapshot时，调用CSI在存储侧完成快照的创建和删除。\nsnapshot-controller\nk8s.gcr.io/sig-storage/snapshot-controller:v4.2.1\nv1.17+\nKubernetes社区提供，在创建/删除VolumeSnapshot时，监听Kubernetes API中关于VolumeSnapshot和VolumeSnapshotContent的对象，并触发csi-snapshotter在存储上完成快照的创建。\ncsi-provisioner\nk8s.gcr.io/sig-storage/csi-provisioner:v3.0.0\nv1.17+\nKubernetes社区提供，用于完成PVC创建/删除。\n在创建PVC时，调用huawei-csi-controller服务在存储上创建LUN/文件系统作为PV。在删除PVC时，调用huawei-csi-controller服务在存储上删除该PV对应的LUN/文件系统。 quay.io/k8scsi/csi-provisioner:v1.4.0\nv1.16.x\ncsi-attacher\nk8s.gcr.io/sig-storage/csi-attacher:v3.4.0\nv1.17+\n在创建/删除Pod时，调用huawei-csi-controller服务执行Publish/Unpublish Volume操作。\nquay.io/k8scsi/csi-attacher:v1.2.1\nv.1.16.x\nstorage-backend-controller\nstorage-backend-controller:4.5.0\nv1.16+\n华为CSI软件包提供、用于管理storageBackendClaim资源。\nstorage-backend-sidecar\nstorage-backend-sidecar:4.5.0\nv1.16+\n华为CSI软件包提供、用于管理storageBackendContent资源。\nhuawei-csi-driver\nhuawei-csi:4.5.0\nv1.16+\n华为CSI软件包提供、用于提供华为CSI支持的所有特性。\nhuawei-csi-extender\nhuawei-csi-extender:4.5.0\nv1.16+\n华为CSI软件包提供、用于提供华为CSI的扩展特性。\n集群若未连接互联网，需要手动下载容器镜像并上传到集群中，具体操作请参考下载容器镜像。\n","categories":"","description":"","excerpt":"华为CSI安装过程中需要依赖下表中的镜像，若集群中的所有worker节点已连接互联网且能够在线拉取镜像，则可跳过本章节。若集群中的节点无法连 …","ref":"/css-docs/docs/%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/%E5%AE%89%E8%A3%85%E5%89%8D%E5%87%86%E5%A4%87/%E6%A3%80%E6%9F%A5csi%E4%BE%9D%E8%B5%96%E7%9A%84%E9%95%9C%E5%83%8F/","tags":"","title":"检查CSI依赖的镜像"},{"body":"操作步骤 拷贝Kubernetes集群的认证文件，/etc/kubernetes/admin.conf修改为实际使用的认证文件。\nmkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config 修改认证文件的用户与用户组。\nsudo chown $(id -u):$(id -g) $HOME/.kube/config 配置当前用户的KUBECONFIG环境变量，以Ubuntu 20.04举例如下。\necho \"export KUBECONFIG=$HOME/.kube/config\" \u003e\u003e ~/.bashrc source ~/.bashrc ","categories":"","description":"","excerpt":"操作步骤 拷贝Kubernetes集群的认证文件，/etc/kubernetes/admin.conf修改为实际使用的认证文件。\nmkdir …","ref":"/css-docs/docs/%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/%E9%85%8D%E7%BD%AE%E9%9D%9Eroot%E7%94%A8%E6%88%B7%E8%AE%BF%E9%97%AEkubernetes%E9%9B%86%E7%BE%A4/","tags":"","title":"配置非root用户访问Kubernetes集群"},{"body":"本章节主要介绍如何使用华为CSI对PV、快照的生命周期进行管理。\n使用华为CSI进行卷管理操作期间，请勿删除存储后端。 在映射block卷时，华为CSI会自动创建创建主机、主机组、LUN组等这些卷映射需要的关联对象，以及映射视图。如果手动在存储上创建了这些对象，会影响华为CSI的映射逻辑，请确保在使用华为CSI映射卷前删除这些对象。 ","categories":"","description":"","excerpt":"本章节主要介绍如何使用华为CSI对PV、快照的生命周期进行管理。\n使用华为CSI进行卷管理操作期间，请勿删除存储后端。 在映射block卷 …","ref":"/css-docs/docs/%E4%BD%BF%E7%94%A8%E5%8D%8E%E4%B8%BAcsi/","tags":"","title":"使用华为CSI"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/en/docs/advanced-features/","tags":"","title":"Advanced Features"},{"body":"Symptom When a Pod reads or writes a mounted volume, message “I/O error” is displayed.\nRoot Cause Analysis When a protocol such as SCSI is used, if the Pod continuously writes data to the mount directory, the storage device will restart. As a result, the link between the device on the host and the storage device is interrupted, triggering an I/O error. When the storage device is restored, the mount directory is still read-only.\nSolution Remount the volume. That is, reconstruct the Pod to trigger re-mounting.\n","categories":"","description":"","excerpt":"Symptom When a Pod reads or writes a mounted volume, message “I/O …","ref":"/css-docs/en/docs/troubleshooting/pod-issues/i-o-error-is-displayed-when-a-volume-directory-is-mounted-to-a-pod/","tags":"","title":"I/O error Is Displayed When a Volume Directory Is Mounted to a Pod"},{"body":"现象描述 Pod对所挂载卷进行读写时，提示I/O error。\n根因分析 使用SCSI等协议时，如果Pod持续往挂载目录写入数据时，存储发生重启，导致主机上设备到存储的链路中断，触发I/O error。存储恢复时，挂载目录仍然为只读。\n解决措施 重新挂载该卷，即通过重建Pod可以触发重新挂载。\n","categories":"","description":"","excerpt":"现象描述 Pod对所挂载卷进行读写时，提示I/O error。\n根因分析 使用SCSI等协议时，如果Pod持续往挂载目录写入数据时，存储发生 …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/pod%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/pod%E6%8C%82%E8%BD%BD%E5%8D%B7%E7%9B%AE%E5%BD%95%E6%8F%90%E7%A4%BAi-o-error/","tags":"","title":"Pod挂载卷目录提示I/O error"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/docs/%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/","tags":"","title":"高级特性"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/en/docs/common-operations/","tags":"","title":"Common Operations"},{"body":"Symptom When you create a Pod, error Cannot connect ISCSI portal *.*.*.*: libkmod: kmod_module_insert_module: could not find module by name=‘iscsi_tcp’ is reported in the /var/log/huawei-csi-node log.\nRoot Cause Analysis The iscsi_tcp service may be stopped after the Kubernetes platform is set up and the iSCSI service is installed. You can run the following command to check whether the service is stopped.\nlsmod | grep iscsi | grep iscsi_tcp The following is an example of the command output.\niscsi_tcp 18333 6 libiscsi_tcp 25146 1 iscsi_tcp libiscsi 57233 2 libiscsi_tcp,iscsi_tcp scsi_transport_iscsi 99909 3 iscsi_tcp,libiscsi Solution or Workaround Run the following command to manually load the iscsi_tcp service.\nmodprobe iscsi_tcp lsmod | grep iscsi | grep iscsi_tcp ","categories":"","description":"","excerpt":"Symptom When you create a Pod, error Cannot connect ISCSI portal …","ref":"/css-docs/en/docs/troubleshooting/pod-issues/failed-to-create-a-pod-because-the-iscsi_tcp-service-is-not-started-properly-when-the-kubernetes-pla/","tags":"","title":"Failed to Create a Pod Because the iscsi tcp Service Is Not Started Properly When the Kubernetes Platform Is Set Up for the First Time"},{"body":"现象描述 创建Pod时报错，在/var/log/huawei-csi-node日志中报错“ Cannot connect ISCSI portal *.*.*.*: libkmod: kmod_module_insert_module: could not find module by name=‘iscsi_tcp’。\n根因分析 搭建Kubernete和安装iSCSI服务后， iscsi_tcp服务可能会被停掉，可通过执行以下命令查看服务是否被停掉。\nlsmod | grep iscsi | grep iscsi_tcp 命令结果示例如下。\niscsi_tcp 18333 6 libiscsi_tcp 25146 1 iscsi_tcp libiscsi 57233 2 libiscsi_tcp,iscsi_tcp scsi_transport_iscsi 99909 3 iscsi_tcp,libiscsi 解决措施或规避方法 执行以下命令，手动加载iscsi_tcp服务。\nmodprobe iscsi_tcp lsmod | grep iscsi | grep iscsi_tcp ","categories":"","description":"","excerpt":"现象描述 创建Pod时报错，在/var/log/huawei-csi-node日志中报错“ Cannot connect ISCSI …","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/pod%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/kubernetes%E5%B9%B3%E5%8F%B0%E7%AC%AC%E4%B8%80%E6%AC%A1%E6%90%AD%E5%BB%BA%E6%97%B6-iscsi_tcp%E6%9C%8D%E5%8A%A1%E6%B2%A1%E6%9C%89%E6%AD%A3%E5%B8%B8%E5%90%AF%E5%8A%A8-%E5%AF%BC%E8%87%B4%E5%88%9B%E5%BB%BApod%E5%A4%B1%E8%B4%A5/","tags":"","title":"Kubernetes平台第一次搭建时， iscsi tcp服务没有正常启动，导致创建Pod失败"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/docs/%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/","tags":"","title":"常用操作"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/en/docs/troubleshooting/","tags":"","title":"Troubleshooting"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/docs/%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86/","tags":"","title":"故障处理"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/en/docs/appendix/","tags":"","title":"Appendix"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/docs/%E9%99%84%E5%BD%95/","tags":"","title":"附录"},{"body":"You can get the PDF version of the user guide from the following link：\nPDF Download Waiting for translationg. ","categories":"","description":"","excerpt":"You can get the PDF version of the user guide from the following link： …","ref":"/css-docs/en/docs/","tags":"","title":"Huawei Container Storage Suite"},{"body":"您可以通过以下链接，获取PDF版用户指南：\nPDF下载 ","categories":"","description":"","excerpt":"您可以通过以下链接，获取PDF版用户指南：\nPDF下载 ","ref":"/css-docs/docs/","tags":"","title":"华为容器存储套件"},{"body":" Huawei Container Storage Suite Learn More Download Welcome to Huawei Container Storage Suite Documentation! ","categories":"","description":"","excerpt":" Huawei Container Storage Suite Learn More Download Welcome to Huawei …","ref":"/css-docs/en/","tags":"","title":"Huawei Container Storage Suite"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/en/search/","tags":"","title":"search result"},{"body":" 华为容器存储套件 阅读文档 下载 欢迎访问华为容器存储套件文档! ","categories":"","description":"","excerpt":" 华为容器存储套件 阅读文档 下载 欢迎访问华为容器存储套件文档! ","ref":"/css-docs/","tags":"","title":"华为容器存储套件"},{"body":"","categories":"","description":"","excerpt":"","ref":"/css-docs/search/","tags":"","title":"搜索结果"}]